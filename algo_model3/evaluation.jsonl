{"text":"We study losses for binary classification and class probability estimation and extend the understanding of them from margin losses to general composite losses which are the composition of a proper loss with a link function.","_input_hash":710153448,"_task_hash":-593455855,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"study","start":3,"end":8,"id":1},{"text":"losses","start":9,"end":15,"id":2},{"text":"for","start":16,"end":19,"id":3},{"text":"binary","start":20,"end":26,"id":4},{"text":"classification","start":27,"end":41,"id":5},{"text":"and","start":42,"end":45,"id":6},{"text":"class","start":46,"end":51,"id":7},{"text":"probability","start":52,"end":63,"id":8},{"text":"estimation","start":64,"end":74,"id":9},{"text":"and","start":75,"end":78,"id":10},{"text":"extend","start":79,"end":85,"id":11},{"text":"the","start":86,"end":89,"id":12},{"text":"understanding","start":90,"end":103,"id":13},{"text":"of","start":104,"end":106,"id":14},{"text":"them","start":107,"end":111,"id":15},{"text":"from","start":112,"end":116,"id":16},{"text":"margin","start":117,"end":123,"id":17},{"text":"losses","start":124,"end":130,"id":18},{"text":"to","start":131,"end":133,"id":19},{"text":"general","start":134,"end":141,"id":20},{"text":"composite","start":142,"end":151,"id":21},{"text":"losses","start":152,"end":158,"id":22},{"text":"which","start":159,"end":164,"id":23},{"text":"are","start":165,"end":168,"id":24},{"text":"the","start":169,"end":172,"id":25},{"text":"composition","start":173,"end":184,"id":26},{"text":"of","start":185,"end":187,"id":27},{"text":"a","start":188,"end":189,"id":28},{"text":"proper","start":190,"end":196,"id":29},{"text":"loss","start":197,"end":201,"id":30},{"text":"with","start":202,"end":206,"id":31},{"text":"a","start":207,"end":208,"id":32},{"text":"link","start":209,"end":213,"id":33},{"text":"function","start":214,"end":222,"id":34},{"text":".","start":222,"end":223,"id":35}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":20,"end":41,"token_start":4,"token_end":5,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"We characterise when margin losses can be proper composite losses, explicitly show how to determine a symmetric loss in full from half of one of its partial losses, introduce an intrinsic parametrisation of composite binary losses and give a complete characterisation of the relationship between proper losses and ``classification calibrated'' losses.","_input_hash":-1876321540,"_task_hash":-1041933555,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"characterise","start":3,"end":15,"id":1},{"text":"when","start":16,"end":20,"id":2},{"text":"margin","start":21,"end":27,"id":3},{"text":"losses","start":28,"end":34,"id":4},{"text":"can","start":35,"end":38,"id":5},{"text":"be","start":39,"end":41,"id":6},{"text":"proper","start":42,"end":48,"id":7},{"text":"composite","start":49,"end":58,"id":8},{"text":"losses","start":59,"end":65,"id":9},{"text":",","start":65,"end":66,"id":10},{"text":"explicitly","start":67,"end":77,"id":11},{"text":"show","start":78,"end":82,"id":12},{"text":"how","start":83,"end":86,"id":13},{"text":"to","start":87,"end":89,"id":14},{"text":"determine","start":90,"end":99,"id":15},{"text":"a","start":100,"end":101,"id":16},{"text":"symmetric","start":102,"end":111,"id":17},{"text":"loss","start":112,"end":116,"id":18},{"text":"in","start":117,"end":119,"id":19},{"text":"full","start":120,"end":124,"id":20},{"text":"from","start":125,"end":129,"id":21},{"text":"half","start":130,"end":134,"id":22},{"text":"of","start":135,"end":137,"id":23},{"text":"one","start":138,"end":141,"id":24},{"text":"of","start":142,"end":144,"id":25},{"text":"its","start":145,"end":148,"id":26},{"text":"partial","start":149,"end":156,"id":27},{"text":"losses","start":157,"end":163,"id":28},{"text":",","start":163,"end":164,"id":29},{"text":"introduce","start":165,"end":174,"id":30},{"text":"an","start":175,"end":177,"id":31},{"text":"intrinsic","start":178,"end":187,"id":32},{"text":"parametrisation","start":188,"end":203,"id":33},{"text":"of","start":204,"end":206,"id":34},{"text":"composite","start":207,"end":216,"id":35},{"text":"binary","start":217,"end":223,"id":36},{"text":"losses","start":224,"end":230,"id":37},{"text":"and","start":231,"end":234,"id":38},{"text":"give","start":235,"end":239,"id":39},{"text":"a","start":240,"end":241,"id":40},{"text":"complete","start":242,"end":250,"id":41},{"text":"characterisation","start":251,"end":267,"id":42},{"text":"of","start":268,"end":270,"id":43},{"text":"the","start":271,"end":274,"id":44},{"text":"relationship","start":275,"end":287,"id":45},{"text":"between","start":288,"end":295,"id":46},{"text":"proper","start":296,"end":302,"id":47},{"text":"losses","start":303,"end":309,"id":48},{"text":"and","start":310,"end":313,"id":49},{"text":"`","start":314,"end":315,"id":50},{"text":"`","start":315,"end":316,"id":51},{"text":"classification","start":316,"end":330,"id":52},{"text":"calibrated","start":331,"end":341,"id":53},{"text":"'","start":341,"end":342,"id":54},{"text":"'","start":342,"end":343,"id":55},{"text":"losses","start":344,"end":350,"id":56},{"text":".","start":350,"end":351,"id":57}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We also consider the question of the ``best'' surrogate binary loss.","_input_hash":-726954419,"_task_hash":1390030707,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"also","start":3,"end":7,"id":1},{"text":"consider","start":8,"end":16,"id":2},{"text":"the","start":17,"end":20,"id":3},{"text":"question","start":21,"end":29,"id":4},{"text":"of","start":30,"end":32,"id":5},{"text":"the","start":33,"end":36,"id":6},{"text":"`","start":37,"end":38,"id":7},{"text":"`","start":38,"end":39,"id":8},{"text":"best","start":39,"end":43,"id":9},{"text":"'","start":43,"end":44,"id":10},{"text":"'","start":44,"end":45,"id":11},{"text":"surrogate","start":46,"end":55,"id":12},{"text":"binary","start":56,"end":62,"id":13},{"text":"loss","start":63,"end":67,"id":14},{"text":".","start":67,"end":68,"id":15}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We introduce a precise notion of ``best'' and show there exist situations where two convex surrogate losses are incommensurable.","_input_hash":-1355809138,"_task_hash":713008655,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"introduce","start":3,"end":12,"id":1},{"text":"a","start":13,"end":14,"id":2},{"text":"precise","start":15,"end":22,"id":3},{"text":"notion","start":23,"end":29,"id":4},{"text":"of","start":30,"end":32,"id":5},{"text":"`","start":33,"end":34,"id":6},{"text":"`","start":34,"end":35,"id":7},{"text":"best","start":35,"end":39,"id":8},{"text":"'","start":39,"end":40,"id":9},{"text":"'","start":40,"end":41,"id":10},{"text":"and","start":42,"end":45,"id":11},{"text":"show","start":46,"end":50,"id":12},{"text":"there","start":51,"end":56,"id":13},{"text":"exist","start":57,"end":62,"id":14},{"text":"situations","start":63,"end":73,"id":15},{"text":"where","start":74,"end":79,"id":16},{"text":"two","start":80,"end":83,"id":17},{"text":"convex","start":84,"end":90,"id":18},{"text":"surrogate","start":91,"end":100,"id":19},{"text":"losses","start":101,"end":107,"id":20},{"text":"are","start":108,"end":111,"id":21},{"text":"incommensurable","start":112,"end":127,"id":22},{"text":".","start":127,"end":128,"id":23}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We provide a complete explicit characterisation of the convexity of composite binary losses in terms of the link function and the weight function associated with the proper loss which make up the composite loss.","_input_hash":1564873780,"_task_hash":-981444873,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"provide","start":3,"end":10,"id":1},{"text":"a","start":11,"end":12,"id":2},{"text":"complete","start":13,"end":21,"id":3},{"text":"explicit","start":22,"end":30,"id":4},{"text":"characterisation","start":31,"end":47,"id":5},{"text":"of","start":48,"end":50,"id":6},{"text":"the","start":51,"end":54,"id":7},{"text":"convexity","start":55,"end":64,"id":8},{"text":"of","start":65,"end":67,"id":9},{"text":"composite","start":68,"end":77,"id":10},{"text":"binary","start":78,"end":84,"id":11},{"text":"losses","start":85,"end":91,"id":12},{"text":"in","start":92,"end":94,"id":13},{"text":"terms","start":95,"end":100,"id":14},{"text":"of","start":101,"end":103,"id":15},{"text":"the","start":104,"end":107,"id":16},{"text":"link","start":108,"end":112,"id":17},{"text":"function","start":113,"end":121,"id":18},{"text":"and","start":122,"end":125,"id":19},{"text":"the","start":126,"end":129,"id":20},{"text":"weight","start":130,"end":136,"id":21},{"text":"function","start":137,"end":145,"id":22},{"text":"associated","start":146,"end":156,"id":23},{"text":"with","start":157,"end":161,"id":24},{"text":"the","start":162,"end":165,"id":25},{"text":"proper","start":166,"end":172,"id":26},{"text":"loss","start":173,"end":177,"id":27},{"text":"which","start":178,"end":183,"id":28},{"text":"make","start":184,"end":188,"id":29},{"text":"up","start":189,"end":191,"id":30},{"text":"the","start":192,"end":195,"id":31},{"text":"composite","start":196,"end":205,"id":32},{"text":"loss","start":206,"end":210,"id":33},{"text":".","start":210,"end":211,"id":34}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"This characterisation suggests new ways of ``surrogate tuning''.","_input_hash":1432929133,"_task_hash":665166806,"tokens":[{"text":"This","start":0,"end":4,"id":0},{"text":"characterisation","start":5,"end":21,"id":1},{"text":"suggests","start":22,"end":30,"id":2},{"text":"new","start":31,"end":34,"id":3},{"text":"ways","start":35,"end":39,"id":4},{"text":"of","start":40,"end":42,"id":5},{"text":"`","start":43,"end":44,"id":6},{"text":"`","start":44,"end":45,"id":7},{"text":"surrogate","start":45,"end":54,"id":8},{"text":"tuning","start":55,"end":61,"id":9},{"text":"'","start":61,"end":62,"id":10},{"text":"'","start":62,"end":63,"id":11},{"text":".","start":63,"end":64,"id":12}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Finally, in an appendix we present some new algorithm-independent results on the relationship between properness, convexity and robustness to misclassification noise for binary losses and show that all convex proper losses are non-robust to misclassification noise.","_input_hash":638507280,"_task_hash":-1270785360,"tokens":[{"text":"Finally","start":0,"end":7,"id":0},{"text":",","start":7,"end":8,"id":1},{"text":"in","start":9,"end":11,"id":2},{"text":"an","start":12,"end":14,"id":3},{"text":"appendix","start":15,"end":23,"id":4},{"text":"we","start":24,"end":26,"id":5},{"text":"present","start":27,"end":34,"id":6},{"text":"some","start":35,"end":39,"id":7},{"text":"new","start":40,"end":43,"id":8},{"text":"algorithm","start":44,"end":53,"id":9},{"text":"-","start":53,"end":54,"id":10},{"text":"independent","start":54,"end":65,"id":11},{"text":"results","start":66,"end":73,"id":12},{"text":"on","start":74,"end":76,"id":13},{"text":"the","start":77,"end":80,"id":14},{"text":"relationship","start":81,"end":93,"id":15},{"text":"between","start":94,"end":101,"id":16},{"text":"properness","start":102,"end":112,"id":17},{"text":",","start":112,"end":113,"id":18},{"text":"convexity","start":114,"end":123,"id":19},{"text":"and","start":124,"end":127,"id":20},{"text":"robustness","start":128,"end":138,"id":21},{"text":"to","start":139,"end":141,"id":22},{"text":"misclassification","start":142,"end":159,"id":23},{"text":"noise","start":160,"end":165,"id":24},{"text":"for","start":166,"end":169,"id":25},{"text":"binary","start":170,"end":176,"id":26},{"text":"losses","start":177,"end":183,"id":27},{"text":"and","start":184,"end":187,"id":28},{"text":"show","start":188,"end":192,"id":29},{"text":"that","start":193,"end":197,"id":30},{"text":"all","start":198,"end":201,"id":31},{"text":"convex","start":202,"end":208,"id":32},{"text":"proper","start":209,"end":215,"id":33},{"text":"losses","start":216,"end":222,"id":34},{"text":"are","start":223,"end":226,"id":35},{"text":"non","start":227,"end":230,"id":36},{"text":"-","start":230,"end":231,"id":37},{"text":"robust","start":231,"end":237,"id":38},{"text":"to","start":238,"end":240,"id":39},{"text":"misclassification","start":241,"end":258,"id":40},{"text":"noise","start":259,"end":264,"id":41},{"text":".","start":264,"end":265,"id":42}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"The group lasso is a penalized regression method, used in regression problems where the covariates are partitioned into groups to promote sparsity at the group level.","_input_hash":-1363626500,"_task_hash":1822347999,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"group","start":4,"end":9,"id":1},{"text":"lasso","start":10,"end":15,"id":2},{"text":"is","start":16,"end":18,"id":3},{"text":"a","start":19,"end":20,"id":4},{"text":"penalized","start":21,"end":30,"id":5},{"text":"regression","start":31,"end":41,"id":6},{"text":"method","start":42,"end":48,"id":7},{"text":",","start":48,"end":49,"id":8},{"text":"used","start":50,"end":54,"id":9},{"text":"in","start":55,"end":57,"id":10},{"text":"regression","start":58,"end":68,"id":11},{"text":"problems","start":69,"end":77,"id":12},{"text":"where","start":78,"end":83,"id":13},{"text":"the","start":84,"end":87,"id":14},{"text":"covariates","start":88,"end":98,"id":15},{"text":"are","start":99,"end":102,"id":16},{"text":"partitioned","start":103,"end":114,"id":17},{"text":"into","start":115,"end":119,"id":18},{"text":"groups","start":120,"end":126,"id":19},{"text":"to","start":127,"end":129,"id":20},{"text":"promote","start":130,"end":137,"id":21},{"text":"sparsity","start":138,"end":146,"id":22},{"text":"at","start":147,"end":149,"id":23},{"text":"the","start":150,"end":153,"id":24},{"text":"group","start":154,"end":159,"id":25},{"text":"level","start":160,"end":165,"id":26},{"text":".","start":165,"end":166,"id":27}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Existing methods for finding the group lasso estimator either use gradient projection methods to update the entire coefficient vector simultaneously at each step, or update one group of coefficients at a time using an inexact line search to approximate the optimal value for the group of coefficients when all other groups' coefficients are fixed.","_input_hash":847640769,"_task_hash":1609291463,"tokens":[{"text":"Existing","start":0,"end":8,"id":0},{"text":"methods","start":9,"end":16,"id":1},{"text":"for","start":17,"end":20,"id":2},{"text":"finding","start":21,"end":28,"id":3},{"text":"the","start":29,"end":32,"id":4},{"text":"group","start":33,"end":38,"id":5},{"text":"lasso","start":39,"end":44,"id":6},{"text":"estimator","start":45,"end":54,"id":7},{"text":"either","start":55,"end":61,"id":8},{"text":"use","start":62,"end":65,"id":9},{"text":"gradient","start":66,"end":74,"id":10},{"text":"projection","start":75,"end":85,"id":11},{"text":"methods","start":86,"end":93,"id":12},{"text":"to","start":94,"end":96,"id":13},{"text":"update","start":97,"end":103,"id":14},{"text":"the","start":104,"end":107,"id":15},{"text":"entire","start":108,"end":114,"id":16},{"text":"coefficient","start":115,"end":126,"id":17},{"text":"vector","start":127,"end":133,"id":18},{"text":"simultaneously","start":134,"end":148,"id":19},{"text":"at","start":149,"end":151,"id":20},{"text":"each","start":152,"end":156,"id":21},{"text":"step","start":157,"end":161,"id":22},{"text":",","start":161,"end":162,"id":23},{"text":"or","start":163,"end":165,"id":24},{"text":"update","start":166,"end":172,"id":25},{"text":"one","start":173,"end":176,"id":26},{"text":"group","start":177,"end":182,"id":27},{"text":"of","start":183,"end":185,"id":28},{"text":"coefficients","start":186,"end":198,"id":29},{"text":"at","start":199,"end":201,"id":30},{"text":"a","start":202,"end":203,"id":31},{"text":"time","start":204,"end":208,"id":32},{"text":"using","start":209,"end":214,"id":33},{"text":"an","start":215,"end":217,"id":34},{"text":"inexact","start":218,"end":225,"id":35},{"text":"line","start":226,"end":230,"id":36},{"text":"search","start":231,"end":237,"id":37},{"text":"to","start":238,"end":240,"id":38},{"text":"approximate","start":241,"end":252,"id":39},{"text":"the","start":253,"end":256,"id":40},{"text":"optimal","start":257,"end":264,"id":41},{"text":"value","start":265,"end":270,"id":42},{"text":"for","start":271,"end":274,"id":43},{"text":"the","start":275,"end":278,"id":44},{"text":"group","start":279,"end":284,"id":45},{"text":"of","start":285,"end":287,"id":46},{"text":"coefficients","start":288,"end":300,"id":47},{"text":"when","start":301,"end":305,"id":48},{"text":"all","start":306,"end":309,"id":49},{"text":"other","start":310,"end":315,"id":50},{"text":"groups","start":316,"end":322,"id":51},{"text":"'","start":322,"end":323,"id":52},{"text":"coefficients","start":324,"end":336,"id":53},{"text":"are","start":337,"end":340,"id":54},{"text":"fixed","start":341,"end":346,"id":55},{"text":".","start":346,"end":347,"id":56}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We present a new method of computation for the group lasso in the linear regression case, the Single Line Search (SLS) algorithm, which operates by computing the exact optimal value for each group (when all other coefficients are fixed) with one univariate line search.","_input_hash":1701680259,"_task_hash":1137345322,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"present","start":3,"end":10,"id":1},{"text":"a","start":11,"end":12,"id":2},{"text":"new","start":13,"end":16,"id":3},{"text":"method","start":17,"end":23,"id":4},{"text":"of","start":24,"end":26,"id":5},{"text":"computation","start":27,"end":38,"id":6},{"text":"for","start":39,"end":42,"id":7},{"text":"the","start":43,"end":46,"id":8},{"text":"group","start":47,"end":52,"id":9},{"text":"lasso","start":53,"end":58,"id":10},{"text":"in","start":59,"end":61,"id":11},{"text":"the","start":62,"end":65,"id":12},{"text":"linear","start":66,"end":72,"id":13},{"text":"regression","start":73,"end":83,"id":14},{"text":"case","start":84,"end":88,"id":15},{"text":",","start":88,"end":89,"id":16},{"text":"the","start":90,"end":93,"id":17},{"text":"Single","start":94,"end":100,"id":18},{"text":"Line","start":101,"end":105,"id":19},{"text":"Search","start":106,"end":112,"id":20},{"text":"(","start":113,"end":114,"id":21},{"text":"SLS","start":114,"end":117,"id":22},{"text":")","start":117,"end":118,"id":23},{"text":"algorithm","start":119,"end":128,"id":24},{"text":",","start":128,"end":129,"id":25},{"text":"which","start":130,"end":135,"id":26},{"text":"operates","start":136,"end":144,"id":27},{"text":"by","start":145,"end":147,"id":28},{"text":"computing","start":148,"end":157,"id":29},{"text":"the","start":158,"end":161,"id":30},{"text":"exact","start":162,"end":167,"id":31},{"text":"optimal","start":168,"end":175,"id":32},{"text":"value","start":176,"end":181,"id":33},{"text":"for","start":182,"end":185,"id":34},{"text":"each","start":186,"end":190,"id":35},{"text":"group","start":191,"end":196,"id":36},{"text":"(","start":197,"end":198,"id":37},{"text":"when","start":198,"end":202,"id":38},{"text":"all","start":203,"end":206,"id":39},{"text":"other","start":207,"end":212,"id":40},{"text":"coefficients","start":213,"end":225,"id":41},{"text":"are","start":226,"end":229,"id":42},{"text":"fixed","start":230,"end":235,"id":43},{"text":")","start":235,"end":236,"id":44},{"text":"with","start":237,"end":241,"id":45},{"text":"one","start":242,"end":245,"id":46},{"text":"univariate","start":246,"end":256,"id":47},{"text":"line","start":257,"end":261,"id":48},{"text":"search","start":262,"end":268,"id":49},{"text":".","start":268,"end":269,"id":50}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":94,"end":112,"token_start":18,"token_end":20,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"We perform simulations demonstrating that the SLS algorithm is often more efficient than existing computational methods.","_input_hash":937001547,"_task_hash":-419266207,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"perform","start":3,"end":10,"id":1},{"text":"simulations","start":11,"end":22,"id":2},{"text":"demonstrating","start":23,"end":36,"id":3},{"text":"that","start":37,"end":41,"id":4},{"text":"the","start":42,"end":45,"id":5},{"text":"SLS","start":46,"end":49,"id":6},{"text":"algorithm","start":50,"end":59,"id":7},{"text":"is","start":60,"end":62,"id":8},{"text":"often","start":63,"end":68,"id":9},{"text":"more","start":69,"end":73,"id":10},{"text":"efficient","start":74,"end":83,"id":11},{"text":"than","start":84,"end":88,"id":12},{"text":"existing","start":89,"end":97,"id":13},{"text":"computational","start":98,"end":111,"id":14},{"text":"methods","start":112,"end":119,"id":15},{"text":".","start":119,"end":120,"id":16}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We also extend the SLS algorithm to the sparse group lasso problem via the Signed Single Line Search (SSLS) algorithm, and give theoretical results to support both algorithms.","_input_hash":-515706185,"_task_hash":-1773472137,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"also","start":3,"end":7,"id":1},{"text":"extend","start":8,"end":14,"id":2},{"text":"the","start":15,"end":18,"id":3},{"text":"SLS","start":19,"end":22,"id":4},{"text":"algorithm","start":23,"end":32,"id":5},{"text":"to","start":33,"end":35,"id":6},{"text":"the","start":36,"end":39,"id":7},{"text":"sparse","start":40,"end":46,"id":8},{"text":"group","start":47,"end":52,"id":9},{"text":"lasso","start":53,"end":58,"id":10},{"text":"problem","start":59,"end":66,"id":11},{"text":"via","start":67,"end":70,"id":12},{"text":"the","start":71,"end":74,"id":13},{"text":"Signed","start":75,"end":81,"id":14},{"text":"Single","start":82,"end":88,"id":15},{"text":"Line","start":89,"end":93,"id":16},{"text":"Search","start":94,"end":100,"id":17},{"text":"(","start":101,"end":102,"id":18},{"text":"SSLS","start":102,"end":106,"id":19},{"text":")","start":106,"end":107,"id":20},{"text":"algorithm","start":108,"end":117,"id":21},{"text":",","start":117,"end":118,"id":22},{"text":"and","start":119,"end":122,"id":23},{"text":"give","start":123,"end":127,"id":24},{"text":"theoretical","start":128,"end":139,"id":25},{"text":"results","start":140,"end":147,"id":26},{"text":"to","start":148,"end":150,"id":27},{"text":"support","start":151,"end":158,"id":28},{"text":"both","start":159,"end":163,"id":29},{"text":"algorithms","start":164,"end":174,"id":30},{"text":".","start":174,"end":175,"id":31}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":75,"end":93,"token_start":14,"token_end":16,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"data_structures|NOUN","word":"data structures","sense":"NOUN","meta":{"score":0.7839000225,"sense":"NOUN"},"_input_hash":794773254,"_task_hash":-366988598,"_session_id":null,"_view_id":"html","answer":"reject","spans":[],"tokens":[{"text":"data_structures|NOUN","start":0,"end":20,"id":0}]}
{"text":"mathematical_concepts|NOUN","word":"mathematical concepts","sense":"NOUN","meta":{"score":0.7839999795,"sense":"NOUN"},"_input_hash":-615610279,"_task_hash":-833331025,"_session_id":null,"_view_id":"html","answer":"reject","spans":[],"tokens":[{"text":"mathematical_concepts|NOUN","start":0,"end":26,"id":0}]}
{"text":"probability_distributions|NOUN","word":"probability distributions","sense":"NOUN","meta":{"score":0.7634999752,"sense":"NOUN"},"_input_hash":-499919643,"_task_hash":-2141792273,"_session_id":null,"_view_id":"html","answer":"reject","spans":[],"tokens":[{"text":"probability_distributions|NOUN","start":0,"end":30,"id":0}]}
{"text":"We analyze the performance of a class of manifold-learning algorithms that find their output by minimizing a quadratic form under some normalization constraints.","_input_hash":1489635198,"_task_hash":584320937,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"analyze","start":3,"end":10,"id":1},{"text":"the","start":11,"end":14,"id":2},{"text":"performance","start":15,"end":26,"id":3},{"text":"of","start":27,"end":29,"id":4},{"text":"a","start":30,"end":31,"id":5},{"text":"class","start":32,"end":37,"id":6},{"text":"of","start":38,"end":40,"id":7},{"text":"manifold","start":41,"end":49,"id":8},{"text":"-","start":49,"end":50,"id":9},{"text":"learning","start":50,"end":58,"id":10},{"text":"algorithms","start":59,"end":69,"id":11},{"text":"that","start":70,"end":74,"id":12},{"text":"find","start":75,"end":79,"id":13},{"text":"their","start":80,"end":85,"id":14},{"text":"output","start":86,"end":92,"id":15},{"text":"by","start":93,"end":95,"id":16},{"text":"minimizing","start":96,"end":106,"id":17},{"text":"a","start":107,"end":108,"id":18},{"text":"quadratic","start":109,"end":118,"id":19},{"text":"form","start":119,"end":123,"id":20},{"text":"under","start":124,"end":129,"id":21},{"text":"some","start":130,"end":134,"id":22},{"text":"normalization","start":135,"end":148,"id":23},{"text":"constraints","start":149,"end":160,"id":24},{"text":".","start":160,"end":161,"id":25}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":41,"end":69,"token_start":8,"token_end":11,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"This class consists of Locally Linear Embedding (LLE), Laplacian Eigenmap, Local Tangent Space Alignment (LTSA), Hessian Eigenmaps (HLLE), and Diffusion maps.","_input_hash":86645528,"_task_hash":-1683778109,"tokens":[{"text":"This","start":0,"end":4,"id":0},{"text":"class","start":5,"end":10,"id":1},{"text":"consists","start":11,"end":19,"id":2},{"text":"of","start":20,"end":22,"id":3},{"text":"Locally","start":23,"end":30,"id":4},{"text":"Linear","start":31,"end":37,"id":5},{"text":"Embedding","start":38,"end":47,"id":6},{"text":"(","start":48,"end":49,"id":7},{"text":"LLE","start":49,"end":52,"id":8},{"text":")","start":52,"end":53,"id":9},{"text":",","start":53,"end":54,"id":10},{"text":"Laplacian","start":55,"end":64,"id":11},{"text":"Eigenmap","start":65,"end":73,"id":12},{"text":",","start":73,"end":74,"id":13},{"text":"Local","start":75,"end":80,"id":14},{"text":"Tangent","start":81,"end":88,"id":15},{"text":"Space","start":89,"end":94,"id":16},{"text":"Alignment","start":95,"end":104,"id":17},{"text":"(","start":105,"end":106,"id":18},{"text":"LTSA","start":106,"end":110,"id":19},{"text":")","start":110,"end":111,"id":20},{"text":",","start":111,"end":112,"id":21},{"text":"Hessian","start":113,"end":120,"id":22},{"text":"Eigenmaps","start":121,"end":130,"id":23},{"text":"(","start":131,"end":132,"id":24},{"text":"HLLE","start":132,"end":136,"id":25},{"text":")","start":136,"end":137,"id":26},{"text":",","start":137,"end":138,"id":27},{"text":"and","start":139,"end":142,"id":28},{"text":"Diffusion","start":143,"end":152,"id":29},{"text":"maps","start":153,"end":157,"id":30},{"text":".","start":157,"end":158,"id":31}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We present and prove conditions on the manifold that are necessary for the success of the algorithms.","_input_hash":-1272831787,"_task_hash":-387941999,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"present","start":3,"end":10,"id":1},{"text":"and","start":11,"end":14,"id":2},{"text":"prove","start":15,"end":20,"id":3},{"text":"conditions","start":21,"end":31,"id":4},{"text":"on","start":32,"end":34,"id":5},{"text":"the","start":35,"end":38,"id":6},{"text":"manifold","start":39,"end":47,"id":7},{"text":"that","start":48,"end":52,"id":8},{"text":"are","start":53,"end":56,"id":9},{"text":"necessary","start":57,"end":66,"id":10},{"text":"for","start":67,"end":70,"id":11},{"text":"the","start":71,"end":74,"id":12},{"text":"success","start":75,"end":82,"id":13},{"text":"of","start":83,"end":85,"id":14},{"text":"the","start":86,"end":89,"id":15},{"text":"algorithms","start":90,"end":100,"id":16},{"text":".","start":100,"end":101,"id":17}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Both the finite sample case and the limit case are analyzed.","_input_hash":-711154741,"_task_hash":-1814561714,"tokens":[{"text":"Both","start":0,"end":4,"id":0},{"text":"the","start":5,"end":8,"id":1},{"text":"finite","start":9,"end":15,"id":2},{"text":"sample","start":16,"end":22,"id":3},{"text":"case","start":23,"end":27,"id":4},{"text":"and","start":28,"end":31,"id":5},{"text":"the","start":32,"end":35,"id":6},{"text":"limit","start":36,"end":41,"id":7},{"text":"case","start":42,"end":46,"id":8},{"text":"are","start":47,"end":50,"id":9},{"text":"analyzed","start":51,"end":59,"id":10},{"text":".","start":59,"end":60,"id":11}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We show that there are simple manifolds in which the necessary conditions are violated, and hence the algorithms cannot recover the underlying manifolds.","_input_hash":-1117391181,"_task_hash":-775241696,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"show","start":3,"end":7,"id":1},{"text":"that","start":8,"end":12,"id":2},{"text":"there","start":13,"end":18,"id":3},{"text":"are","start":19,"end":22,"id":4},{"text":"simple","start":23,"end":29,"id":5},{"text":"manifolds","start":30,"end":39,"id":6},{"text":"in","start":40,"end":42,"id":7},{"text":"which","start":43,"end":48,"id":8},{"text":"the","start":49,"end":52,"id":9},{"text":"necessary","start":53,"end":62,"id":10},{"text":"conditions","start":63,"end":73,"id":11},{"text":"are","start":74,"end":77,"id":12},{"text":"violated","start":78,"end":86,"id":13},{"text":",","start":86,"end":87,"id":14},{"text":"and","start":88,"end":91,"id":15},{"text":"hence","start":92,"end":97,"id":16},{"text":"the","start":98,"end":101,"id":17},{"text":"algorithms","start":102,"end":112,"id":18},{"text":"can","start":113,"end":116,"id":19},{"text":"not","start":116,"end":119,"id":20},{"text":"recover","start":120,"end":127,"id":21},{"text":"the","start":128,"end":131,"id":22},{"text":"underlying","start":132,"end":142,"id":23},{"text":"manifolds","start":143,"end":152,"id":24},{"text":".","start":152,"end":153,"id":25}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Finally, we present numerical results that demonstrate our claims.","_input_hash":896022460,"_task_hash":-851466995,"tokens":[{"text":"Finally","start":0,"end":7,"id":0},{"text":",","start":7,"end":8,"id":1},{"text":"we","start":9,"end":11,"id":2},{"text":"present","start":12,"end":19,"id":3},{"text":"numerical","start":20,"end":29,"id":4},{"text":"results","start":30,"end":37,"id":5},{"text":"that","start":38,"end":42,"id":6},{"text":"demonstrate","start":43,"end":54,"id":7},{"text":"our","start":55,"end":58,"id":8},{"text":"claims","start":59,"end":65,"id":9},{"text":".","start":65,"end":66,"id":10}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We present the first tree-based regressor whose convergence rate depends only on the intrinsic dimension of the data, namely its Assouad dimension.","_input_hash":-1666717225,"_task_hash":-1725889582,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"present","start":3,"end":10,"id":1},{"text":"the","start":11,"end":14,"id":2},{"text":"first","start":15,"end":20,"id":3},{"text":"tree","start":21,"end":25,"id":4},{"text":"-","start":25,"end":26,"id":5},{"text":"based","start":26,"end":31,"id":6},{"text":"regressor","start":32,"end":41,"id":7},{"text":"whose","start":42,"end":47,"id":8},{"text":"convergence","start":48,"end":59,"id":9},{"text":"rate","start":60,"end":64,"id":10},{"text":"depends","start":65,"end":72,"id":11},{"text":"only","start":73,"end":77,"id":12},{"text":"on","start":78,"end":80,"id":13},{"text":"the","start":81,"end":84,"id":14},{"text":"intrinsic","start":85,"end":94,"id":15},{"text":"dimension","start":95,"end":104,"id":16},{"text":"of","start":105,"end":107,"id":17},{"text":"the","start":108,"end":111,"id":18},{"text":"data","start":112,"end":116,"id":19},{"text":",","start":116,"end":117,"id":20},{"text":"namely","start":118,"end":124,"id":21},{"text":"its","start":125,"end":128,"id":22},{"text":"Assouad","start":129,"end":136,"id":23},{"text":"dimension","start":137,"end":146,"id":24},{"text":".","start":146,"end":147,"id":25}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":21,"end":41,"token_start":4,"token_end":7,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"The regressor uses the RPtree partitioning procedure, a simple randomized variant of k-d trees.","_input_hash":641765247,"_task_hash":-1504688713,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"regressor","start":4,"end":13,"id":1},{"text":"uses","start":14,"end":18,"id":2},{"text":"the","start":19,"end":22,"id":3},{"text":"RPtree","start":23,"end":29,"id":4},{"text":"partitioning","start":30,"end":42,"id":5},{"text":"procedure","start":43,"end":52,"id":6},{"text":",","start":52,"end":53,"id":7},{"text":"a","start":54,"end":55,"id":8},{"text":"simple","start":56,"end":62,"id":9},{"text":"randomized","start":63,"end":73,"id":10},{"text":"variant","start":74,"end":81,"id":11},{"text":"of","start":82,"end":84,"id":12},{"text":"k","start":85,"end":86,"id":13},{"text":"-","start":86,"end":87,"id":14},{"text":"d","start":87,"end":88,"id":15},{"text":"trees","start":89,"end":94,"id":16},{"text":".","start":94,"end":95,"id":17}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We improve recently published results about resources of Restricted Boltzmann Machines (RBM) and Deep Belief Networks (DBN) required to make them Universal Approximators.","_input_hash":-2080777763,"_task_hash":1828853774,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"improve","start":3,"end":10,"id":1},{"text":"recently","start":11,"end":19,"id":2},{"text":"published","start":20,"end":29,"id":3},{"text":"results","start":30,"end":37,"id":4},{"text":"about","start":38,"end":43,"id":5},{"text":"resources","start":44,"end":53,"id":6},{"text":"of","start":54,"end":56,"id":7},{"text":"Restricted","start":57,"end":67,"id":8},{"text":"Boltzmann","start":68,"end":77,"id":9},{"text":"Machines","start":78,"end":86,"id":10},{"text":"(","start":87,"end":88,"id":11},{"text":"RBM","start":88,"end":91,"id":12},{"text":")","start":91,"end":92,"id":13},{"text":"and","start":93,"end":96,"id":14},{"text":"Deep","start":97,"end":101,"id":15},{"text":"Belief","start":102,"end":108,"id":16},{"text":"Networks","start":109,"end":117,"id":17},{"text":"(","start":118,"end":119,"id":18},{"text":"DBN","start":119,"end":122,"id":19},{"text":")","start":122,"end":123,"id":20},{"text":"required","start":124,"end":132,"id":21},{"text":"to","start":133,"end":135,"id":22},{"text":"make","start":136,"end":140,"id":23},{"text":"them","start":141,"end":145,"id":24},{"text":"Universal","start":146,"end":155,"id":25},{"text":"Approximators","start":156,"end":169,"id":26},{"text":".","start":169,"end":170,"id":27}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":57,"end":86,"token_start":8,"token_end":10,"label":"ALGO","answer":"accept"},{"start":97,"end":117,"token_start":15,"token_end":17,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"We show that any distribution p on the set of binary vectors of length n can be arbitrarily well approximated by an RBM with k-1 hidden units, where k is the minimal number of pairs of binary vectors differing in only one entry such that their union contains the support set of p. In important cases this number is half of the cardinality of the support set of p. We construct a DBN with 2^n/2(n-b), b ~ log(n), hidden layers of width n that is capable of approximating any distribution on {0,1}^n arbitrarily well.","_input_hash":1763506409,"_task_hash":169123241,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"show","start":3,"end":7,"id":1},{"text":"that","start":8,"end":12,"id":2},{"text":"any","start":13,"end":16,"id":3},{"text":"distribution","start":17,"end":29,"id":4},{"text":"p","start":30,"end":31,"id":5},{"text":"on","start":32,"end":34,"id":6},{"text":"the","start":35,"end":38,"id":7},{"text":"set","start":39,"end":42,"id":8},{"text":"of","start":43,"end":45,"id":9},{"text":"binary","start":46,"end":52,"id":10},{"text":"vectors","start":53,"end":60,"id":11},{"text":"of","start":61,"end":63,"id":12},{"text":"length","start":64,"end":70,"id":13},{"text":"n","start":71,"end":72,"id":14},{"text":"can","start":73,"end":76,"id":15},{"text":"be","start":77,"end":79,"id":16},{"text":"arbitrarily","start":80,"end":91,"id":17},{"text":"well","start":92,"end":96,"id":18},{"text":"approximated","start":97,"end":109,"id":19},{"text":"by","start":110,"end":112,"id":20},{"text":"an","start":113,"end":115,"id":21},{"text":"RBM","start":116,"end":119,"id":22},{"text":"with","start":120,"end":124,"id":23},{"text":"k-1","start":125,"end":128,"id":24},{"text":"hidden","start":129,"end":135,"id":25},{"text":"units","start":136,"end":141,"id":26},{"text":",","start":141,"end":142,"id":27},{"text":"where","start":143,"end":148,"id":28},{"text":"k","start":149,"end":150,"id":29},{"text":"is","start":151,"end":153,"id":30},{"text":"the","start":154,"end":157,"id":31},{"text":"minimal","start":158,"end":165,"id":32},{"text":"number","start":166,"end":172,"id":33},{"text":"of","start":173,"end":175,"id":34},{"text":"pairs","start":176,"end":181,"id":35},{"text":"of","start":182,"end":184,"id":36},{"text":"binary","start":185,"end":191,"id":37},{"text":"vectors","start":192,"end":199,"id":38},{"text":"differing","start":200,"end":209,"id":39},{"text":"in","start":210,"end":212,"id":40},{"text":"only","start":213,"end":217,"id":41},{"text":"one","start":218,"end":221,"id":42},{"text":"entry","start":222,"end":227,"id":43},{"text":"such","start":228,"end":232,"id":44},{"text":"that","start":233,"end":237,"id":45},{"text":"their","start":238,"end":243,"id":46},{"text":"union","start":244,"end":249,"id":47},{"text":"contains","start":250,"end":258,"id":48},{"text":"the","start":259,"end":262,"id":49},{"text":"support","start":263,"end":270,"id":50},{"text":"set","start":271,"end":274,"id":51},{"text":"of","start":275,"end":277,"id":52},{"text":"p.","start":278,"end":280,"id":53},{"text":"In","start":281,"end":283,"id":54},{"text":"important","start":284,"end":293,"id":55},{"text":"cases","start":294,"end":299,"id":56},{"text":"this","start":300,"end":304,"id":57},{"text":"number","start":305,"end":311,"id":58},{"text":"is","start":312,"end":314,"id":59},{"text":"half","start":315,"end":319,"id":60},{"text":"of","start":320,"end":322,"id":61},{"text":"the","start":323,"end":326,"id":62},{"text":"cardinality","start":327,"end":338,"id":63},{"text":"of","start":339,"end":341,"id":64},{"text":"the","start":342,"end":345,"id":65},{"text":"support","start":346,"end":353,"id":66},{"text":"set","start":354,"end":357,"id":67},{"text":"of","start":358,"end":360,"id":68},{"text":"p.","start":361,"end":363,"id":69},{"text":"We","start":364,"end":366,"id":70},{"text":"construct","start":367,"end":376,"id":71},{"text":"a","start":377,"end":378,"id":72},{"text":"DBN","start":379,"end":382,"id":73},{"text":"with","start":383,"end":387,"id":74},{"text":"2^n/2(n","start":388,"end":395,"id":75},{"text":"-","start":395,"end":396,"id":76},{"text":"b","start":396,"end":397,"id":77},{"text":")","start":397,"end":398,"id":78},{"text":",","start":398,"end":399,"id":79},{"text":"b","start":400,"end":401,"id":80},{"text":"~","start":402,"end":403,"id":81},{"text":"log(n","start":404,"end":409,"id":82},{"text":")","start":409,"end":410,"id":83},{"text":",","start":410,"end":411,"id":84},{"text":"hidden","start":412,"end":418,"id":85},{"text":"layers","start":419,"end":425,"id":86},{"text":"of","start":426,"end":428,"id":87},{"text":"width","start":429,"end":434,"id":88},{"text":"n","start":435,"end":436,"id":89},{"text":"that","start":437,"end":441,"id":90},{"text":"is","start":442,"end":444,"id":91},{"text":"capable","start":445,"end":452,"id":92},{"text":"of","start":453,"end":455,"id":93},{"text":"approximating","start":456,"end":469,"id":94},{"text":"any","start":470,"end":473,"id":95},{"text":"distribution","start":474,"end":486,"id":96},{"text":"on","start":487,"end":489,"id":97},{"text":"{","start":490,"end":491,"id":98},{"text":"0,1}^n","start":491,"end":497,"id":99},{"text":"arbitrarily","start":498,"end":509,"id":100},{"text":"well","start":510,"end":514,"id":101},{"text":".","start":514,"end":515,"id":102}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"This confirms a conjecture presented by Le Roux and Bengio 2010.","_input_hash":-75785123,"_task_hash":-204126453,"tokens":[{"text":"This","start":0,"end":4,"id":0},{"text":"confirms","start":5,"end":13,"id":1},{"text":"a","start":14,"end":15,"id":2},{"text":"conjecture","start":16,"end":26,"id":3},{"text":"presented","start":27,"end":36,"id":4},{"text":"by","start":37,"end":39,"id":5},{"text":"Le","start":40,"end":42,"id":6},{"text":"Roux","start":43,"end":47,"id":7},{"text":"and","start":48,"end":51,"id":8},{"text":"Bengio","start":52,"end":58,"id":9},{"text":"2010","start":59,"end":63,"id":10},{"text":".","start":63,"end":64,"id":11}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"can","meta":{"score":0},"_input_hash":1267838506,"_task_hash":1845371291,"_session_id":null,"_view_id":"text","answer":"reject","spans":[],"tokens":[{"text":"can","start":0,"end":3,"id":0}]}
{"text":"many_algorithms|NOUN","word":"many algorithms","sense":"NOUN","meta":{"score":0.7840999961,"sense":"NOUN"},"_input_hash":-2082433538,"_task_hash":-34351924,"_session_id":null,"_view_id":"html","answer":"reject","spans":[],"tokens":[{"text":"many_algorithms|NOUN","start":0,"end":20,"id":0}]}
{"text":"dependent_types|NOUN","word":"dependent types","sense":"NOUN","meta":{"score":0.782400012,"sense":"NOUN"},"_input_hash":-53975985,"_task_hash":1039887310,"_session_id":null,"_view_id":"html","answer":"reject","spans":[],"tokens":[{"text":"dependent_types|NOUN","start":0,"end":20,"id":0}]}
{"text":"Finding sparse solutions of underdetermined systems of linear equations is a fundamental problem in signal processing and statistics which has become a subject of interest in recent years.","_input_hash":1382224868,"_task_hash":1735348654,"tokens":[{"text":"Finding","start":0,"end":7,"id":0},{"text":"sparse","start":8,"end":14,"id":1},{"text":"solutions","start":15,"end":24,"id":2},{"text":"of","start":25,"end":27,"id":3},{"text":"underdetermined","start":28,"end":43,"id":4},{"text":"systems","start":44,"end":51,"id":5},{"text":"of","start":52,"end":54,"id":6},{"text":"linear","start":55,"end":61,"id":7},{"text":"equations","start":62,"end":71,"id":8},{"text":"is","start":72,"end":74,"id":9},{"text":"a","start":75,"end":76,"id":10},{"text":"fundamental","start":77,"end":88,"id":11},{"text":"problem","start":89,"end":96,"id":12},{"text":"in","start":97,"end":99,"id":13},{"text":"signal","start":100,"end":106,"id":14},{"text":"processing","start":107,"end":117,"id":15},{"text":"and","start":118,"end":121,"id":16},{"text":"statistics","start":122,"end":132,"id":17},{"text":"which","start":133,"end":138,"id":18},{"text":"has","start":139,"end":142,"id":19},{"text":"become","start":143,"end":149,"id":20},{"text":"a","start":150,"end":151,"id":21},{"text":"subject","start":152,"end":159,"id":22},{"text":"of","start":160,"end":162,"id":23},{"text":"interest","start":163,"end":171,"id":24},{"text":"in","start":172,"end":174,"id":25},{"text":"recent","start":175,"end":181,"id":26},{"text":"years","start":182,"end":187,"id":27},{"text":".","start":187,"end":188,"id":28}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"In general, these systems have infinitely many solutions.","_input_hash":-339633159,"_task_hash":-345873301,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"general","start":3,"end":10,"id":1},{"text":",","start":10,"end":11,"id":2},{"text":"these","start":12,"end":17,"id":3},{"text":"systems","start":18,"end":25,"id":4},{"text":"have","start":26,"end":30,"id":5},{"text":"infinitely","start":31,"end":41,"id":6},{"text":"many","start":42,"end":46,"id":7},{"text":"solutions","start":47,"end":56,"id":8},{"text":".","start":56,"end":57,"id":9}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"However, it may be shown that sufficiently sparse solutions may be identified uniquely.","_input_hash":-1061976155,"_task_hash":1368849593,"tokens":[{"text":"However","start":0,"end":7,"id":0},{"text":",","start":7,"end":8,"id":1},{"text":"it","start":9,"end":11,"id":2},{"text":"may","start":12,"end":15,"id":3},{"text":"be","start":16,"end":18,"id":4},{"text":"shown","start":19,"end":24,"id":5},{"text":"that","start":25,"end":29,"id":6},{"text":"sufficiently","start":30,"end":42,"id":7},{"text":"sparse","start":43,"end":49,"id":8},{"text":"solutions","start":50,"end":59,"id":9},{"text":"may","start":60,"end":63,"id":10},{"text":"be","start":64,"end":66,"id":11},{"text":"identified","start":67,"end":77,"id":12},{"text":"uniquely","start":78,"end":86,"id":13},{"text":".","start":86,"end":87,"id":14}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"In other words, the corresponding linear transformation will be invertible if we restrict its domain to sufficiently sparse vectors.","_input_hash":-232438733,"_task_hash":-1957509887,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"other","start":3,"end":8,"id":1},{"text":"words","start":9,"end":14,"id":2},{"text":",","start":14,"end":15,"id":3},{"text":"the","start":16,"end":19,"id":4},{"text":"corresponding","start":20,"end":33,"id":5},{"text":"linear","start":34,"end":40,"id":6},{"text":"transformation","start":41,"end":55,"id":7},{"text":"will","start":56,"end":60,"id":8},{"text":"be","start":61,"end":63,"id":9},{"text":"invertible","start":64,"end":74,"id":10},{"text":"if","start":75,"end":77,"id":11},{"text":"we","start":78,"end":80,"id":12},{"text":"restrict","start":81,"end":89,"id":13},{"text":"its","start":90,"end":93,"id":14},{"text":"domain","start":94,"end":100,"id":15},{"text":"to","start":101,"end":103,"id":16},{"text":"sufficiently","start":104,"end":116,"id":17},{"text":"sparse","start":117,"end":123,"id":18},{"text":"vectors","start":124,"end":131,"id":19},{"text":".","start":131,"end":132,"id":20}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"This property may be used, for example, to solve the underdetermined Blind Source Separation (BSS) problem, or to find sparse representation of a signal in an `overcomplete' dictionary of primitive elements (i.e., the so-called atomic decomposition).","_input_hash":-2083551708,"_task_hash":-75038150,"tokens":[{"text":"This","start":0,"end":4,"id":0},{"text":"property","start":5,"end":13,"id":1},{"text":"may","start":14,"end":17,"id":2},{"text":"be","start":18,"end":20,"id":3},{"text":"used","start":21,"end":25,"id":4},{"text":",","start":25,"end":26,"id":5},{"text":"for","start":27,"end":30,"id":6},{"text":"example","start":31,"end":38,"id":7},{"text":",","start":38,"end":39,"id":8},{"text":"to","start":40,"end":42,"id":9},{"text":"solve","start":43,"end":48,"id":10},{"text":"the","start":49,"end":52,"id":11},{"text":"underdetermined","start":53,"end":68,"id":12},{"text":"Blind","start":69,"end":74,"id":13},{"text":"Source","start":75,"end":81,"id":14},{"text":"Separation","start":82,"end":92,"id":15},{"text":"(","start":93,"end":94,"id":16},{"text":"BSS","start":94,"end":97,"id":17},{"text":")","start":97,"end":98,"id":18},{"text":"problem","start":99,"end":106,"id":19},{"text":",","start":106,"end":107,"id":20},{"text":"or","start":108,"end":110,"id":21},{"text":"to","start":111,"end":113,"id":22},{"text":"find","start":114,"end":118,"id":23},{"text":"sparse","start":119,"end":125,"id":24},{"text":"representation","start":126,"end":140,"id":25},{"text":"of","start":141,"end":143,"id":26},{"text":"a","start":144,"end":145,"id":27},{"text":"signal","start":146,"end":152,"id":28},{"text":"in","start":153,"end":155,"id":29},{"text":"an","start":156,"end":158,"id":30},{"text":"`","start":159,"end":160,"id":31},{"text":"overcomplete","start":160,"end":172,"id":32},{"text":"'","start":172,"end":173,"id":33},{"text":"dictionary","start":174,"end":184,"id":34},{"text":"of","start":185,"end":187,"id":35},{"text":"primitive","start":188,"end":197,"id":36},{"text":"elements","start":198,"end":206,"id":37},{"text":"(","start":207,"end":208,"id":38},{"text":"i.e.","start":208,"end":212,"id":39},{"text":",","start":212,"end":213,"id":40},{"text":"the","start":214,"end":217,"id":41},{"text":"so","start":218,"end":220,"id":42},{"text":"-","start":220,"end":221,"id":43},{"text":"called","start":221,"end":227,"id":44},{"text":"atomic","start":228,"end":234,"id":45},{"text":"decomposition","start":235,"end":248,"id":46},{"text":")","start":248,"end":249,"id":47},{"text":".","start":249,"end":250,"id":48}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"The main drawback of current methods of finding sparse solutions is their computational complexity.","_input_hash":1917160618,"_task_hash":-1522427682,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"main","start":4,"end":8,"id":1},{"text":"drawback","start":9,"end":17,"id":2},{"text":"of","start":18,"end":20,"id":3},{"text":"current","start":21,"end":28,"id":4},{"text":"methods","start":29,"end":36,"id":5},{"text":"of","start":37,"end":39,"id":6},{"text":"finding","start":40,"end":47,"id":7},{"text":"sparse","start":48,"end":54,"id":8},{"text":"solutions","start":55,"end":64,"id":9},{"text":"is","start":65,"end":67,"id":10},{"text":"their","start":68,"end":73,"id":11},{"text":"computational","start":74,"end":87,"id":12},{"text":"complexity","start":88,"end":98,"id":13},{"text":".","start":98,"end":99,"id":14}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"In this paper, we will show that by detecting `active' components of the (potential) solution, i.e., those components having a considerable value, a framework for fast solution of the problem may be devised.","_input_hash":1565904891,"_task_hash":-529641857,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"this","start":3,"end":7,"id":1},{"text":"paper","start":8,"end":13,"id":2},{"text":",","start":13,"end":14,"id":3},{"text":"we","start":15,"end":17,"id":4},{"text":"will","start":18,"end":22,"id":5},{"text":"show","start":23,"end":27,"id":6},{"text":"that","start":28,"end":32,"id":7},{"text":"by","start":33,"end":35,"id":8},{"text":"detecting","start":36,"end":45,"id":9},{"text":"`","start":46,"end":47,"id":10},{"text":"active","start":47,"end":53,"id":11},{"text":"'","start":53,"end":54,"id":12},{"text":"components","start":55,"end":65,"id":13},{"text":"of","start":66,"end":68,"id":14},{"text":"the","start":69,"end":72,"id":15},{"text":"(","start":73,"end":74,"id":16},{"text":"potential","start":74,"end":83,"id":17},{"text":")","start":83,"end":84,"id":18},{"text":"solution","start":85,"end":93,"id":19},{"text":",","start":93,"end":94,"id":20},{"text":"i.e.","start":95,"end":99,"id":21},{"text":",","start":99,"end":100,"id":22},{"text":"those","start":101,"end":106,"id":23},{"text":"components","start":107,"end":117,"id":24},{"text":"having","start":118,"end":124,"id":25},{"text":"a","start":125,"end":126,"id":26},{"text":"considerable","start":127,"end":139,"id":27},{"text":"value","start":140,"end":145,"id":28},{"text":",","start":145,"end":146,"id":29},{"text":"a","start":147,"end":148,"id":30},{"text":"framework","start":149,"end":158,"id":31},{"text":"for","start":159,"end":162,"id":32},{"text":"fast","start":163,"end":167,"id":33},{"text":"solution","start":168,"end":176,"id":34},{"text":"of","start":177,"end":179,"id":35},{"text":"the","start":180,"end":183,"id":36},{"text":"problem","start":184,"end":191,"id":37},{"text":"may","start":192,"end":195,"id":38},{"text":"be","start":196,"end":198,"id":39},{"text":"devised","start":199,"end":206,"id":40},{"text":".","start":206,"end":207,"id":41}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"The idea leads to a family of algorithms, called `Iterative Detection-Estimation (IDE)', which converge to the solution by successive detection and estimation of its active part.","_input_hash":415472018,"_task_hash":-1589273072,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"idea","start":4,"end":8,"id":1},{"text":"leads","start":9,"end":14,"id":2},{"text":"to","start":15,"end":17,"id":3},{"text":"a","start":18,"end":19,"id":4},{"text":"family","start":20,"end":26,"id":5},{"text":"of","start":27,"end":29,"id":6},{"text":"algorithms","start":30,"end":40,"id":7},{"text":",","start":40,"end":41,"id":8},{"text":"called","start":42,"end":48,"id":9},{"text":"`","start":49,"end":50,"id":10},{"text":"Iterative","start":50,"end":59,"id":11},{"text":"Detection","start":60,"end":69,"id":12},{"text":"-","start":69,"end":70,"id":13},{"text":"Estimation","start":70,"end":80,"id":14},{"text":"(","start":81,"end":82,"id":15},{"text":"IDE","start":82,"end":85,"id":16},{"text":")","start":85,"end":86,"id":17},{"text":"'","start":86,"end":87,"id":18},{"text":",","start":87,"end":88,"id":19},{"text":"which","start":89,"end":94,"id":20},{"text":"converge","start":95,"end":103,"id":21},{"text":"to","start":104,"end":106,"id":22},{"text":"the","start":107,"end":110,"id":23},{"text":"solution","start":111,"end":119,"id":24},{"text":"by","start":120,"end":122,"id":25},{"text":"successive","start":123,"end":133,"id":26},{"text":"detection","start":134,"end":143,"id":27},{"text":"and","start":144,"end":147,"id":28},{"text":"estimation","start":148,"end":158,"id":29},{"text":"of","start":159,"end":161,"id":30},{"text":"its","start":162,"end":165,"id":31},{"text":"active","start":166,"end":172,"id":32},{"text":"part","start":173,"end":177,"id":33},{"text":".","start":177,"end":178,"id":34}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":50,"end":80,"token_start":11,"token_end":14,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"Comparing the performance of IDE(s) with one of the most successful method to date, which is based on Linear Programming (LP), an improvement in speed of about two to three orders of magnitude is observed.","_input_hash":106666573,"_task_hash":-1969435842,"tokens":[{"text":"Comparing","start":0,"end":9,"id":0},{"text":"the","start":10,"end":13,"id":1},{"text":"performance","start":14,"end":25,"id":2},{"text":"of","start":26,"end":28,"id":3},{"text":"IDE(s","start":29,"end":34,"id":4},{"text":")","start":34,"end":35,"id":5},{"text":"with","start":36,"end":40,"id":6},{"text":"one","start":41,"end":44,"id":7},{"text":"of","start":45,"end":47,"id":8},{"text":"the","start":48,"end":51,"id":9},{"text":"most","start":52,"end":56,"id":10},{"text":"successful","start":57,"end":67,"id":11},{"text":"method","start":68,"end":74,"id":12},{"text":"to","start":75,"end":77,"id":13},{"text":"date","start":78,"end":82,"id":14},{"text":",","start":82,"end":83,"id":15},{"text":"which","start":84,"end":89,"id":16},{"text":"is","start":90,"end":92,"id":17},{"text":"based","start":93,"end":98,"id":18},{"text":"on","start":99,"end":101,"id":19},{"text":"Linear","start":102,"end":108,"id":20},{"text":"Programming","start":109,"end":120,"id":21},{"text":"(","start":121,"end":122,"id":22},{"text":"LP","start":122,"end":124,"id":23},{"text":")","start":124,"end":125,"id":24},{"text":",","start":125,"end":126,"id":25},{"text":"an","start":127,"end":129,"id":26},{"text":"improvement","start":130,"end":141,"id":27},{"text":"in","start":142,"end":144,"id":28},{"text":"speed","start":145,"end":150,"id":29},{"text":"of","start":151,"end":153,"id":30},{"text":"about","start":154,"end":159,"id":31},{"text":"two","start":160,"end":163,"id":32},{"text":"to","start":164,"end":166,"id":33},{"text":"three","start":167,"end":172,"id":34},{"text":"orders","start":173,"end":179,"id":35},{"text":"of","start":180,"end":182,"id":36},{"text":"magnitude","start":183,"end":192,"id":37},{"text":"is","start":193,"end":195,"id":38},{"text":"observed","start":196,"end":204,"id":39},{"text":".","start":204,"end":205,"id":40}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"complex_mathematics|NOUN","word":"complex mathematics","sense":"NOUN","meta":{"score":0.7635999918,"sense":"NOUN"},"_input_hash":-1926206124,"_task_hash":-1511406595,"_session_id":null,"_view_id":"html","answer":"reject","spans":[],"tokens":[{"text":"complex_mathematics|NOUN","start":0,"end":24,"id":0}]}
{"text":"turing_machine|NOUN","word":"turing machine","sense":"NOUN","meta":{"score":0.7728999853,"sense":"NOUN"},"_input_hash":1908578143,"_task_hash":-1771090243,"_session_id":null,"_view_id":"html","answer":"accept","spans":[],"tokens":[{"text":"turing_machine|NOUN","start":0,"end":19,"id":0}]}
{"text":"In this paper we consider sparse and identifiable linear latent variable (factor) and linear Bayesian network models for parsimonious analysis of multivariate data.","_input_hash":835553860,"_task_hash":23734403,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"this","start":3,"end":7,"id":1},{"text":"paper","start":8,"end":13,"id":2},{"text":"we","start":14,"end":16,"id":3},{"text":"consider","start":17,"end":25,"id":4},{"text":"sparse","start":26,"end":32,"id":5},{"text":"and","start":33,"end":36,"id":6},{"text":"identifiable","start":37,"end":49,"id":7},{"text":"linear","start":50,"end":56,"id":8},{"text":"latent","start":57,"end":63,"id":9},{"text":"variable","start":64,"end":72,"id":10},{"text":"(","start":73,"end":74,"id":11},{"text":"factor","start":74,"end":80,"id":12},{"text":")","start":80,"end":81,"id":13},{"text":"and","start":82,"end":85,"id":14},{"text":"linear","start":86,"end":92,"id":15},{"text":"Bayesian","start":93,"end":101,"id":16},{"text":"network","start":102,"end":109,"id":17},{"text":"models","start":110,"end":116,"id":18},{"text":"for","start":117,"end":120,"id":19},{"text":"parsimonious","start":121,"end":133,"id":20},{"text":"analysis","start":134,"end":142,"id":21},{"text":"of","start":143,"end":145,"id":22},{"text":"multivariate","start":146,"end":158,"id":23},{"text":"data","start":159,"end":163,"id":24},{"text":".","start":163,"end":164,"id":25}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":93,"end":116,"token_start":16,"token_end":18,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"We propose a computationally efficient method for joint parameter and model inference, and model comparison.","_input_hash":50858937,"_task_hash":1257563108,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"propose","start":3,"end":10,"id":1},{"text":"a","start":11,"end":12,"id":2},{"text":"computationally","start":13,"end":28,"id":3},{"text":"efficient","start":29,"end":38,"id":4},{"text":"method","start":39,"end":45,"id":5},{"text":"for","start":46,"end":49,"id":6},{"text":"joint","start":50,"end":55,"id":7},{"text":"parameter","start":56,"end":65,"id":8},{"text":"and","start":66,"end":69,"id":9},{"text":"model","start":70,"end":75,"id":10},{"text":"inference","start":76,"end":85,"id":11},{"text":",","start":85,"end":86,"id":12},{"text":"and","start":87,"end":90,"id":13},{"text":"model","start":91,"end":96,"id":14},{"text":"comparison","start":97,"end":107,"id":15},{"text":".","start":107,"end":108,"id":16}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"It consists of a fully Bayesian hierarchy for sparse models using slab and spike priors (two-component delta-function and continuous mixtures), non-Gaussian latent factors and a stochastic search over the ordering of the variables.","_input_hash":603829078,"_task_hash":952221448,"tokens":[{"text":"It","start":0,"end":2,"id":0},{"text":"consists","start":3,"end":11,"id":1},{"text":"of","start":12,"end":14,"id":2},{"text":"a","start":15,"end":16,"id":3},{"text":"fully","start":17,"end":22,"id":4},{"text":"Bayesian","start":23,"end":31,"id":5},{"text":"hierarchy","start":32,"end":41,"id":6},{"text":"for","start":42,"end":45,"id":7},{"text":"sparse","start":46,"end":52,"id":8},{"text":"models","start":53,"end":59,"id":9},{"text":"using","start":60,"end":65,"id":10},{"text":"slab","start":66,"end":70,"id":11},{"text":"and","start":71,"end":74,"id":12},{"text":"spike","start":75,"end":80,"id":13},{"text":"priors","start":81,"end":87,"id":14},{"text":"(","start":88,"end":89,"id":15},{"text":"two","start":89,"end":92,"id":16},{"text":"-","start":92,"end":93,"id":17},{"text":"component","start":93,"end":102,"id":18},{"text":"delta","start":103,"end":108,"id":19},{"text":"-","start":108,"end":109,"id":20},{"text":"function","start":109,"end":117,"id":21},{"text":"and","start":118,"end":121,"id":22},{"text":"continuous","start":122,"end":132,"id":23},{"text":"mixtures","start":133,"end":141,"id":24},{"text":")","start":141,"end":142,"id":25},{"text":",","start":142,"end":143,"id":26},{"text":"non","start":144,"end":147,"id":27},{"text":"-","start":147,"end":148,"id":28},{"text":"Gaussian","start":148,"end":156,"id":29},{"text":"latent","start":157,"end":163,"id":30},{"text":"factors","start":164,"end":171,"id":31},{"text":"and","start":172,"end":175,"id":32},{"text":"a","start":176,"end":177,"id":33},{"text":"stochastic","start":178,"end":188,"id":34},{"text":"search","start":189,"end":195,"id":35},{"text":"over","start":196,"end":200,"id":36},{"text":"the","start":201,"end":204,"id":37},{"text":"ordering","start":205,"end":213,"id":38},{"text":"of","start":214,"end":216,"id":39},{"text":"the","start":217,"end":220,"id":40},{"text":"variables","start":221,"end":230,"id":41},{"text":".","start":230,"end":231,"id":42}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"The framework, which we call SLIM (Sparse Linear Identifiable Multivariate modeling), is validated and bench-marked on artificial and real biological data sets.","_input_hash":-841058220,"_task_hash":879421136,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"framework","start":4,"end":13,"id":1},{"text":",","start":13,"end":14,"id":2},{"text":"which","start":15,"end":20,"id":3},{"text":"we","start":21,"end":23,"id":4},{"text":"call","start":24,"end":28,"id":5},{"text":"SLIM","start":29,"end":33,"id":6},{"text":"(","start":34,"end":35,"id":7},{"text":"Sparse","start":35,"end":41,"id":8},{"text":"Linear","start":42,"end":48,"id":9},{"text":"Identifiable","start":49,"end":61,"id":10},{"text":"Multivariate","start":62,"end":74,"id":11},{"text":"modeling","start":75,"end":83,"id":12},{"text":")","start":83,"end":84,"id":13},{"text":",","start":84,"end":85,"id":14},{"text":"is","start":86,"end":88,"id":15},{"text":"validated","start":89,"end":98,"id":16},{"text":"and","start":99,"end":102,"id":17},{"text":"bench","start":103,"end":108,"id":18},{"text":"-","start":108,"end":109,"id":19},{"text":"marked","start":109,"end":115,"id":20},{"text":"on","start":116,"end":118,"id":21},{"text":"artificial","start":119,"end":129,"id":22},{"text":"and","start":130,"end":133,"id":23},{"text":"real","start":134,"end":138,"id":24},{"text":"biological","start":139,"end":149,"id":25},{"text":"data","start":150,"end":154,"id":26},{"text":"sets","start":155,"end":159,"id":27},{"text":".","start":159,"end":160,"id":28}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"SLIM is closest in spirit to LiNGAM (Shimizu et al.,","_input_hash":-1355154678,"_task_hash":52065872,"tokens":[{"text":"SLIM","start":0,"end":4,"id":0},{"text":"is","start":5,"end":7,"id":1},{"text":"closest","start":8,"end":15,"id":2},{"text":"in","start":16,"end":18,"id":3},{"text":"spirit","start":19,"end":25,"id":4},{"text":"to","start":26,"end":28,"id":5},{"text":"LiNGAM","start":29,"end":35,"id":6},{"text":"(","start":36,"end":37,"id":7},{"text":"Shimizu","start":37,"end":44,"id":8},{"text":"et","start":45,"end":47,"id":9},{"text":"al","start":48,"end":50,"id":10},{"text":".","start":50,"end":51,"id":11},{"text":",","start":51,"end":52,"id":12}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"2006), but differs substantially in inference, Bayesian network structure learning and model comparison.","_input_hash":2064840711,"_task_hash":652101488,"tokens":[{"text":"2006","start":0,"end":4,"id":0},{"text":")","start":4,"end":5,"id":1},{"text":",","start":5,"end":6,"id":2},{"text":"but","start":7,"end":10,"id":3},{"text":"differs","start":11,"end":18,"id":4},{"text":"substantially","start":19,"end":32,"id":5},{"text":"in","start":33,"end":35,"id":6},{"text":"inference","start":36,"end":45,"id":7},{"text":",","start":45,"end":46,"id":8},{"text":"Bayesian","start":47,"end":55,"id":9},{"text":"network","start":56,"end":63,"id":10},{"text":"structure","start":64,"end":73,"id":11},{"text":"learning","start":74,"end":82,"id":12},{"text":"and","start":83,"end":86,"id":13},{"text":"model","start":87,"end":92,"id":14},{"text":"comparison","start":93,"end":103,"id":15},{"text":".","start":103,"end":104,"id":16}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Experimentally, SLIM performs equally well or better than LiNGAM with comparable computational complexity.","_input_hash":-1884239515,"_task_hash":971544879,"tokens":[{"text":"Experimentally","start":0,"end":14,"id":0},{"text":",","start":14,"end":15,"id":1},{"text":"SLIM","start":16,"end":20,"id":2},{"text":"performs","start":21,"end":29,"id":3},{"text":"equally","start":30,"end":37,"id":4},{"text":"well","start":38,"end":42,"id":5},{"text":"or","start":43,"end":45,"id":6},{"text":"better","start":46,"end":52,"id":7},{"text":"than","start":53,"end":57,"id":8},{"text":"LiNGAM","start":58,"end":64,"id":9},{"text":"with","start":65,"end":69,"id":10},{"text":"comparable","start":70,"end":80,"id":11},{"text":"computational","start":81,"end":94,"id":12},{"text":"complexity","start":95,"end":105,"id":13},{"text":".","start":105,"end":106,"id":14}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We attribute this mainly to the stochastic search strategy used, and to parsimony (sparsity and identifiability), which is an explicit part of the model.","_input_hash":-181767219,"_task_hash":-1659760119,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"attribute","start":3,"end":12,"id":1},{"text":"this","start":13,"end":17,"id":2},{"text":"mainly","start":18,"end":24,"id":3},{"text":"to","start":25,"end":27,"id":4},{"text":"the","start":28,"end":31,"id":5},{"text":"stochastic","start":32,"end":42,"id":6},{"text":"search","start":43,"end":49,"id":7},{"text":"strategy","start":50,"end":58,"id":8},{"text":"used","start":59,"end":63,"id":9},{"text":",","start":63,"end":64,"id":10},{"text":"and","start":65,"end":68,"id":11},{"text":"to","start":69,"end":71,"id":12},{"text":"parsimony","start":72,"end":81,"id":13},{"text":"(","start":82,"end":83,"id":14},{"text":"sparsity","start":83,"end":91,"id":15},{"text":"and","start":92,"end":95,"id":16},{"text":"identifiability","start":96,"end":111,"id":17},{"text":")","start":111,"end":112,"id":18},{"text":",","start":112,"end":113,"id":19},{"text":"which","start":114,"end":119,"id":20},{"text":"is","start":120,"end":122,"id":21},{"text":"an","start":123,"end":125,"id":22},{"text":"explicit","start":126,"end":134,"id":23},{"text":"part","start":135,"end":139,"id":24},{"text":"of","start":140,"end":142,"id":25},{"text":"the","start":143,"end":146,"id":26},{"text":"model","start":147,"end":152,"id":27},{"text":".","start":152,"end":153,"id":28}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We propose two extensions to the basic i.i.d.","_input_hash":449260399,"_task_hash":1618475934,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"propose","start":3,"end":10,"id":1},{"text":"two","start":11,"end":14,"id":2},{"text":"extensions","start":15,"end":25,"id":3},{"text":"to","start":26,"end":28,"id":4},{"text":"the","start":29,"end":32,"id":5},{"text":"basic","start":33,"end":38,"id":6},{"text":"i.i.d","start":39,"end":44,"id":7},{"text":".","start":44,"end":45,"id":8}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"linear framework:","_input_hash":1078796544,"_task_hash":1378543152,"tokens":[{"text":"linear","start":0,"end":6,"id":0},{"text":"framework","start":7,"end":16,"id":1},{"text":":","start":16,"end":17,"id":2}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"non-linear dependence on observed variables, called SNIM (Sparse Non-linear Identifiable Multivariate modeling) and allowing for correlations between latent variables, called CSLIM (Correlated SLIM), for the temporal and/or spatial data.","_input_hash":-1646286336,"_task_hash":-601694203,"tokens":[{"text":"non","start":0,"end":3,"id":0},{"text":"-","start":3,"end":4,"id":1},{"text":"linear","start":4,"end":10,"id":2},{"text":"dependence","start":11,"end":21,"id":3},{"text":"on","start":22,"end":24,"id":4},{"text":"observed","start":25,"end":33,"id":5},{"text":"variables","start":34,"end":43,"id":6},{"text":",","start":43,"end":44,"id":7},{"text":"called","start":45,"end":51,"id":8},{"text":"SNIM","start":52,"end":56,"id":9},{"text":"(","start":57,"end":58,"id":10},{"text":"Sparse","start":58,"end":64,"id":11},{"text":"Non","start":65,"end":68,"id":12},{"text":"-","start":68,"end":69,"id":13},{"text":"linear","start":69,"end":75,"id":14},{"text":"Identifiable","start":76,"end":88,"id":15},{"text":"Multivariate","start":89,"end":101,"id":16},{"text":"modeling","start":102,"end":110,"id":17},{"text":")","start":110,"end":111,"id":18},{"text":"and","start":112,"end":115,"id":19},{"text":"allowing","start":116,"end":124,"id":20},{"text":"for","start":125,"end":128,"id":21},{"text":"correlations","start":129,"end":141,"id":22},{"text":"between","start":142,"end":149,"id":23},{"text":"latent","start":150,"end":156,"id":24},{"text":"variables","start":157,"end":166,"id":25},{"text":",","start":166,"end":167,"id":26},{"text":"called","start":168,"end":174,"id":27},{"text":"CSLIM","start":175,"end":180,"id":28},{"text":"(","start":181,"end":182,"id":29},{"text":"Correlated","start":182,"end":192,"id":30},{"text":"SLIM","start":193,"end":197,"id":31},{"text":")","start":197,"end":198,"id":32},{"text":",","start":198,"end":199,"id":33},{"text":"for","start":200,"end":203,"id":34},{"text":"the","start":204,"end":207,"id":35},{"text":"temporal","start":208,"end":216,"id":36},{"text":"and/or","start":217,"end":223,"id":37},{"text":"spatial","start":224,"end":231,"id":38},{"text":"data","start":232,"end":236,"id":39},{"text":".","start":236,"end":237,"id":40}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"The source code and scripts are available from http://cogsys.imm.dtu.dk/slim/.","_input_hash":383922989,"_task_hash":1548251900,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"source","start":4,"end":10,"id":1},{"text":"code","start":11,"end":15,"id":2},{"text":"and","start":16,"end":19,"id":3},{"text":"scripts","start":20,"end":27,"id":4},{"text":"are","start":28,"end":31,"id":5},{"text":"available","start":32,"end":41,"id":6},{"text":"from","start":42,"end":46,"id":7},{"text":"http://cogsys.imm.dtu.dk/slim/.","start":47,"end":78,"id":8}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"must","meta":{"score":0},"_input_hash":484467785,"_task_hash":-959369377,"_session_id":null,"_view_id":"text","answer":"reject","spans":[],"tokens":[{"text":"must","start":0,"end":4,"id":0}]}
{"text":"connectome|NOUN","word":"connectome","sense":"NOUN","meta":{"score":0.7897999883,"sense":"NOUN"},"_input_hash":1300852015,"_task_hash":-1594308140,"_session_id":null,"_view_id":"html","answer":"reject","spans":[],"tokens":[{"text":"connectome|NOUN","start":0,"end":15,"id":0}]}
{"text":"We characterize and study variable importance (VIMP) and pairwise variable associations in binary regression trees.","_input_hash":-1220427477,"_task_hash":-1404360791,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"characterize","start":3,"end":15,"id":1},{"text":"and","start":16,"end":19,"id":2},{"text":"study","start":20,"end":25,"id":3},{"text":"variable","start":26,"end":34,"id":4},{"text":"importance","start":35,"end":45,"id":5},{"text":"(","start":46,"end":47,"id":6},{"text":"VIMP","start":47,"end":51,"id":7},{"text":")","start":51,"end":52,"id":8},{"text":"and","start":53,"end":56,"id":9},{"text":"pairwise","start":57,"end":65,"id":10},{"text":"variable","start":66,"end":74,"id":11},{"text":"associations","start":75,"end":87,"id":12},{"text":"in","start":88,"end":90,"id":13},{"text":"binary","start":91,"end":97,"id":14},{"text":"regression","start":98,"end":108,"id":15},{"text":"trees","start":109,"end":114,"id":16},{"text":".","start":114,"end":115,"id":17}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":91,"end":114,"token_start":14,"token_end":16,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"A key component involves the node mean squared error for a quantity we refer to as a maximal subtree.","_input_hash":-1629405522,"_task_hash":-1010331814,"tokens":[{"text":"A","start":0,"end":1,"id":0},{"text":"key","start":2,"end":5,"id":1},{"text":"component","start":6,"end":15,"id":2},{"text":"involves","start":16,"end":24,"id":3},{"text":"the","start":25,"end":28,"id":4},{"text":"node","start":29,"end":33,"id":5},{"text":"mean","start":34,"end":38,"id":6},{"text":"squared","start":39,"end":46,"id":7},{"text":"error","start":47,"end":52,"id":8},{"text":"for","start":53,"end":56,"id":9},{"text":"a","start":57,"end":58,"id":10},{"text":"quantity","start":59,"end":67,"id":11},{"text":"we","start":68,"end":70,"id":12},{"text":"refer","start":71,"end":76,"id":13},{"text":"to","start":77,"end":79,"id":14},{"text":"as","start":80,"end":82,"id":15},{"text":"a","start":83,"end":84,"id":16},{"text":"maximal","start":85,"end":92,"id":17},{"text":"subtree","start":93,"end":100,"id":18},{"text":".","start":100,"end":101,"id":19}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"The theory naturally extends from single trees to ensembles of trees and applies to methods like random forests.","_input_hash":316397493,"_task_hash":687200591,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"theory","start":4,"end":10,"id":1},{"text":"naturally","start":11,"end":20,"id":2},{"text":"extends","start":21,"end":28,"id":3},{"text":"from","start":29,"end":33,"id":4},{"text":"single","start":34,"end":40,"id":5},{"text":"trees","start":41,"end":46,"id":6},{"text":"to","start":47,"end":49,"id":7},{"text":"ensembles","start":50,"end":59,"id":8},{"text":"of","start":60,"end":62,"id":9},{"text":"trees","start":63,"end":68,"id":10},{"text":"and","start":69,"end":72,"id":11},{"text":"applies","start":73,"end":80,"id":12},{"text":"to","start":81,"end":83,"id":13},{"text":"methods","start":84,"end":91,"id":14},{"text":"like","start":92,"end":96,"id":15},{"text":"random","start":97,"end":103,"id":16},{"text":"forests","start":104,"end":111,"id":17},{"text":".","start":111,"end":112,"id":18}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":97,"end":111,"token_start":16,"token_end":17,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"This is useful because while importance values from random forests are used to screen variables, for example they are used to filter high throughput genomic data in Bioinformatics, very little theory exists about their properties.","_input_hash":1109894544,"_task_hash":-1965616499,"tokens":[{"text":"This","start":0,"end":4,"id":0},{"text":"is","start":5,"end":7,"id":1},{"text":"useful","start":8,"end":14,"id":2},{"text":"because","start":15,"end":22,"id":3},{"text":"while","start":23,"end":28,"id":4},{"text":"importance","start":29,"end":39,"id":5},{"text":"values","start":40,"end":46,"id":6},{"text":"from","start":47,"end":51,"id":7},{"text":"random","start":52,"end":58,"id":8},{"text":"forests","start":59,"end":66,"id":9},{"text":"are","start":67,"end":70,"id":10},{"text":"used","start":71,"end":75,"id":11},{"text":"to","start":76,"end":78,"id":12},{"text":"screen","start":79,"end":85,"id":13},{"text":"variables","start":86,"end":95,"id":14},{"text":",","start":95,"end":96,"id":15},{"text":"for","start":97,"end":100,"id":16},{"text":"example","start":101,"end":108,"id":17},{"text":"they","start":109,"end":113,"id":18},{"text":"are","start":114,"end":117,"id":19},{"text":"used","start":118,"end":122,"id":20},{"text":"to","start":123,"end":125,"id":21},{"text":"filter","start":126,"end":132,"id":22},{"text":"high","start":133,"end":137,"id":23},{"text":"throughput","start":138,"end":148,"id":24},{"text":"genomic","start":149,"end":156,"id":25},{"text":"data","start":157,"end":161,"id":26},{"text":"in","start":162,"end":164,"id":27},{"text":"Bioinformatics","start":165,"end":179,"id":28},{"text":",","start":179,"end":180,"id":29},{"text":"very","start":181,"end":185,"id":30},{"text":"little","start":186,"end":192,"id":31},{"text":"theory","start":193,"end":199,"id":32},{"text":"exists","start":200,"end":206,"id":33},{"text":"about","start":207,"end":212,"id":34},{"text":"their","start":213,"end":218,"id":35},{"text":"properties","start":219,"end":229,"id":36},{"text":".","start":229,"end":230,"id":37}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":52,"end":66,"token_start":8,"token_end":9,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"machine_intelligence|NOUN","word":"machine intelligence","sense":"NOUN","meta":{"score":0.7791000009,"sense":"NOUN"},"_input_hash":-1217445132,"_task_hash":991366875,"_session_id":null,"_view_id":"html","answer":"reject","spans":[],"tokens":[{"text":"machine_intelligence|NOUN","start":0,"end":25,"id":0}]}
{"text":"genetic_algorithms|NOUN","word":"genetic algorithms","sense":"NOUN","meta":{"score":0.8083000183,"sense":"NOUN"},"_input_hash":1573456621,"_task_hash":1717970959,"_session_id":null,"_view_id":"html","answer":"accept","spans":[],"tokens":[{"text":"genetic_algorithms|NOUN","start":0,"end":23,"id":0}]}
{"text":"The class of Schoenberg transformations, embedding Euclidean distances into higher dimensional Euclidean spaces, is presented, and derived from theorems on positive definite and conditionally negative definite matrices.","_input_hash":130472642,"_task_hash":1582280033,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"class","start":4,"end":9,"id":1},{"text":"of","start":10,"end":12,"id":2},{"text":"Schoenberg","start":13,"end":23,"id":3},{"text":"transformations","start":24,"end":39,"id":4},{"text":",","start":39,"end":40,"id":5},{"text":"embedding","start":41,"end":50,"id":6},{"text":"Euclidean","start":51,"end":60,"id":7},{"text":"distances","start":61,"end":70,"id":8},{"text":"into","start":71,"end":75,"id":9},{"text":"higher","start":76,"end":82,"id":10},{"text":"dimensional","start":83,"end":94,"id":11},{"text":"Euclidean","start":95,"end":104,"id":12},{"text":"spaces","start":105,"end":111,"id":13},{"text":",","start":111,"end":112,"id":14},{"text":"is","start":113,"end":115,"id":15},{"text":"presented","start":116,"end":125,"id":16},{"text":",","start":125,"end":126,"id":17},{"text":"and","start":127,"end":130,"id":18},{"text":"derived","start":131,"end":138,"id":19},{"text":"from","start":139,"end":143,"id":20},{"text":"theorems","start":144,"end":152,"id":21},{"text":"on","start":153,"end":155,"id":22},{"text":"positive","start":156,"end":164,"id":23},{"text":"definite","start":165,"end":173,"id":24},{"text":"and","start":174,"end":177,"id":25},{"text":"conditionally","start":178,"end":191,"id":26},{"text":"negative","start":192,"end":200,"id":27},{"text":"definite","start":201,"end":209,"id":28},{"text":"matrices","start":210,"end":218,"id":29},{"text":".","start":218,"end":219,"id":30}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"Original results on the arc lengths, angles and curvature of the transformations are proposed, and visualized on artificial data sets by classical multidimensional scaling.","_input_hash":455801541,"_task_hash":-63490062,"tokens":[{"text":"Original","start":0,"end":8,"id":0},{"text":"results","start":9,"end":16,"id":1},{"text":"on","start":17,"end":19,"id":2},{"text":"the","start":20,"end":23,"id":3},{"text":"arc","start":24,"end":27,"id":4},{"text":"lengths","start":28,"end":35,"id":5},{"text":",","start":35,"end":36,"id":6},{"text":"angles","start":37,"end":43,"id":7},{"text":"and","start":44,"end":47,"id":8},{"text":"curvature","start":48,"end":57,"id":9},{"text":"of","start":58,"end":60,"id":10},{"text":"the","start":61,"end":64,"id":11},{"text":"transformations","start":65,"end":80,"id":12},{"text":"are","start":81,"end":84,"id":13},{"text":"proposed","start":85,"end":93,"id":14},{"text":",","start":93,"end":94,"id":15},{"text":"and","start":95,"end":98,"id":16},{"text":"visualized","start":99,"end":109,"id":17},{"text":"on","start":110,"end":112,"id":18},{"text":"artificial","start":113,"end":123,"id":19},{"text":"data","start":124,"end":128,"id":20},{"text":"sets","start":129,"end":133,"id":21},{"text":"by","start":134,"end":136,"id":22},{"text":"classical","start":137,"end":146,"id":23},{"text":"multidimensional","start":147,"end":163,"id":24},{"text":"scaling","start":164,"end":171,"id":25},{"text":".","start":171,"end":172,"id":26}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"A simple distance-based discriminant algorithm illustrates the theory, intimately connected to the Gaussian kernels of Machine Learning.","_input_hash":-1075725848,"_task_hash":-1462786871,"tokens":[{"text":"A","start":0,"end":1,"id":0},{"text":"simple","start":2,"end":8,"id":1},{"text":"distance","start":9,"end":17,"id":2},{"text":"-","start":17,"end":18,"id":3},{"text":"based","start":18,"end":23,"id":4},{"text":"discriminant","start":24,"end":36,"id":5},{"text":"algorithm","start":37,"end":46,"id":6},{"text":"illustrates","start":47,"end":58,"id":7},{"text":"the","start":59,"end":62,"id":8},{"text":"theory","start":63,"end":69,"id":9},{"text":",","start":69,"end":70,"id":10},{"text":"intimately","start":71,"end":81,"id":11},{"text":"connected","start":82,"end":91,"id":12},{"text":"to","start":92,"end":94,"id":13},{"text":"the","start":95,"end":98,"id":14},{"text":"Gaussian","start":99,"end":107,"id":15},{"text":"kernels","start":108,"end":115,"id":16},{"text":"of","start":116,"end":118,"id":17},{"text":"Machine","start":119,"end":126,"id":18},{"text":"Learning","start":127,"end":135,"id":19},{"text":".","start":135,"end":136,"id":20}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"cellular_automata|NOUN","word":"cellular automata","sense":"NOUN","meta":{"score":0.7760000229,"sense":"NOUN"},"_input_hash":-536851375,"_task_hash":715157365,"_session_id":null,"_view_id":"html","answer":"reject","spans":[],"tokens":[{"text":"cellular_automata|NOUN","start":0,"end":22,"id":0}]}
{"text":"NNs|NOUN","word":"NNs","sense":"NOUN","meta":{"score":0.7695999742,"sense":"NOUN"},"_input_hash":-2056769799,"_task_hash":1545076674,"_session_id":null,"_view_id":"html","answer":"accept","spans":[],"tokens":[{"text":"NNs|NOUN","start":0,"end":8,"id":0}]}
{"text":"physical_system|NOUN","word":"physical system","sense":"NOUN","meta":{"score":0.774600029,"sense":"NOUN"},"_input_hash":538260045,"_task_hash":1762977748,"_session_id":null,"_view_id":"html","answer":"reject","spans":[],"tokens":[{"text":"physical_system|NOUN","start":0,"end":20,"id":0}]}
{"text":"object_recognition|NOUN","word":"object recognition","sense":"NOUN","meta":{"score":0.7795000076,"sense":"NOUN"},"_input_hash":-2131188336,"_task_hash":214018154,"_session_id":null,"_view_id":"html","answer":"reject","spans":[],"tokens":[{"text":"object_recognition|NOUN","start":0,"end":23,"id":0}]}
{"text":"random_forest","answer":"accept","_input_hash":1360454248,"_task_hash":364433353,"spans":[],"tokens":[{"text":"random_forest","start":0,"end":13,"id":0}]}
{"text":"ANNs|NOUN","word":"ANNs","sense":"NOUN","meta":{"score":0.7531999946,"sense":"NOUN"},"_input_hash":309957396,"_task_hash":-925200739,"_session_id":null,"_view_id":"html","answer":"accept","spans":[],"tokens":[{"text":"ANNs|NOUN","start":0,"end":9,"id":0}]}
{"text":"was","meta":{"score":0},"_input_hash":2018911483,"_task_hash":-1993120382,"_session_id":null,"_view_id":"text","answer":"reject","spans":[],"tokens":[{"text":"was","start":0,"end":3,"id":0}]}
{"text":"gon","meta":{"score":0},"_input_hash":-947719476,"_task_hash":-1484834232,"_session_id":null,"_view_id":"text","answer":"reject","spans":[],"tokens":[{"text":"gon","start":0,"end":3,"id":0}]}
{"text":"We propose a novel algorithm for greedy forward feature selection for regularized least-squares (RLS) regression and classification, also known as the least-squares support vector machine or ridge regression.","_input_hash":385711376,"_task_hash":126847048,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"propose","start":3,"end":10,"id":1},{"text":"a","start":11,"end":12,"id":2},{"text":"novel","start":13,"end":18,"id":3},{"text":"algorithm","start":19,"end":28,"id":4},{"text":"for","start":29,"end":32,"id":5},{"text":"greedy","start":33,"end":39,"id":6},{"text":"forward","start":40,"end":47,"id":7},{"text":"feature","start":48,"end":55,"id":8},{"text":"selection","start":56,"end":65,"id":9},{"text":"for","start":66,"end":69,"id":10},{"text":"regularized","start":70,"end":81,"id":11},{"text":"least","start":82,"end":87,"id":12},{"text":"-","start":87,"end":88,"id":13},{"text":"squares","start":88,"end":95,"id":14},{"text":"(","start":96,"end":97,"id":15},{"text":"RLS","start":97,"end":100,"id":16},{"text":")","start":100,"end":101,"id":17},{"text":"regression","start":102,"end":112,"id":18},{"text":"and","start":113,"end":116,"id":19},{"text":"classification","start":117,"end":131,"id":20},{"text":",","start":131,"end":132,"id":21},{"text":"also","start":133,"end":137,"id":22},{"text":"known","start":138,"end":143,"id":23},{"text":"as","start":144,"end":146,"id":24},{"text":"the","start":147,"end":150,"id":25},{"text":"least","start":151,"end":156,"id":26},{"text":"-","start":156,"end":157,"id":27},{"text":"squares","start":157,"end":164,"id":28},{"text":"support","start":165,"end":172,"id":29},{"text":"vector","start":173,"end":179,"id":30},{"text":"machine","start":180,"end":187,"id":31},{"text":"or","start":188,"end":190,"id":32},{"text":"ridge","start":191,"end":196,"id":33},{"text":"regression","start":197,"end":207,"id":34},{"text":".","start":207,"end":208,"id":35}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":151,"end":187,"token_start":26,"token_end":31,"label":"ALGO","answer":"accept"},{"start":191,"end":207,"token_start":33,"token_end":34,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"The algorithm, which we call greedy RLS, starts from the empty feature set, and on each iteration adds the feature whose addition provides the best leave-one-out cross-validation performance.","_input_hash":-432225788,"_task_hash":457100167,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"algorithm","start":4,"end":13,"id":1},{"text":",","start":13,"end":14,"id":2},{"text":"which","start":15,"end":20,"id":3},{"text":"we","start":21,"end":23,"id":4},{"text":"call","start":24,"end":28,"id":5},{"text":"greedy","start":29,"end":35,"id":6},{"text":"RLS","start":36,"end":39,"id":7},{"text":",","start":39,"end":40,"id":8},{"text":"starts","start":41,"end":47,"id":9},{"text":"from","start":48,"end":52,"id":10},{"text":"the","start":53,"end":56,"id":11},{"text":"empty","start":57,"end":62,"id":12},{"text":"feature","start":63,"end":70,"id":13},{"text":"set","start":71,"end":74,"id":14},{"text":",","start":74,"end":75,"id":15},{"text":"and","start":76,"end":79,"id":16},{"text":"on","start":80,"end":82,"id":17},{"text":"each","start":83,"end":87,"id":18},{"text":"iteration","start":88,"end":97,"id":19},{"text":"adds","start":98,"end":102,"id":20},{"text":"the","start":103,"end":106,"id":21},{"text":"feature","start":107,"end":114,"id":22},{"text":"whose","start":115,"end":120,"id":23},{"text":"addition","start":121,"end":129,"id":24},{"text":"provides","start":130,"end":138,"id":25},{"text":"the","start":139,"end":142,"id":26},{"text":"best","start":143,"end":147,"id":27},{"text":"leave","start":148,"end":153,"id":28},{"text":"-","start":153,"end":154,"id":29},{"text":"one","start":154,"end":157,"id":30},{"text":"-","start":157,"end":158,"id":31},{"text":"out","start":158,"end":161,"id":32},{"text":"cross","start":162,"end":167,"id":33},{"text":"-","start":167,"end":168,"id":34},{"text":"validation","start":168,"end":178,"id":35},{"text":"performance","start":179,"end":190,"id":36},{"text":".","start":190,"end":191,"id":37}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Our method is considerably faster than the previously proposed ones, since its time complexity is linear in the number of training examples, the number of features in the original data set, and the desired size of the set of selected features.","_input_hash":-1271852373,"_task_hash":142642813,"tokens":[{"text":"Our","start":0,"end":3,"id":0},{"text":"method","start":4,"end":10,"id":1},{"text":"is","start":11,"end":13,"id":2},{"text":"considerably","start":14,"end":26,"id":3},{"text":"faster","start":27,"end":33,"id":4},{"text":"than","start":34,"end":38,"id":5},{"text":"the","start":39,"end":42,"id":6},{"text":"previously","start":43,"end":53,"id":7},{"text":"proposed","start":54,"end":62,"id":8},{"text":"ones","start":63,"end":67,"id":9},{"text":",","start":67,"end":68,"id":10},{"text":"since","start":69,"end":74,"id":11},{"text":"its","start":75,"end":78,"id":12},{"text":"time","start":79,"end":83,"id":13},{"text":"complexity","start":84,"end":94,"id":14},{"text":"is","start":95,"end":97,"id":15},{"text":"linear","start":98,"end":104,"id":16},{"text":"in","start":105,"end":107,"id":17},{"text":"the","start":108,"end":111,"id":18},{"text":"number","start":112,"end":118,"id":19},{"text":"of","start":119,"end":121,"id":20},{"text":"training","start":122,"end":130,"id":21},{"text":"examples","start":131,"end":139,"id":22},{"text":",","start":139,"end":140,"id":23},{"text":"the","start":141,"end":144,"id":24},{"text":"number","start":145,"end":151,"id":25},{"text":"of","start":152,"end":154,"id":26},{"text":"features","start":155,"end":163,"id":27},{"text":"in","start":164,"end":166,"id":28},{"text":"the","start":167,"end":170,"id":29},{"text":"original","start":171,"end":179,"id":30},{"text":"data","start":180,"end":184,"id":31},{"text":"set","start":185,"end":188,"id":32},{"text":",","start":188,"end":189,"id":33},{"text":"and","start":190,"end":193,"id":34},{"text":"the","start":194,"end":197,"id":35},{"text":"desired","start":198,"end":205,"id":36},{"text":"size","start":206,"end":210,"id":37},{"text":"of","start":211,"end":213,"id":38},{"text":"the","start":214,"end":217,"id":39},{"text":"set","start":218,"end":221,"id":40},{"text":"of","start":222,"end":224,"id":41},{"text":"selected","start":225,"end":233,"id":42},{"text":"features","start":234,"end":242,"id":43},{"text":".","start":242,"end":243,"id":44}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Therefore, as a side effect we obtain a new training algorithm for learning sparse linear RLS predictors which can be used for large scale learning.","_input_hash":1252621343,"_task_hash":-757266465,"tokens":[{"text":"Therefore","start":0,"end":9,"id":0},{"text":",","start":9,"end":10,"id":1},{"text":"as","start":11,"end":13,"id":2},{"text":"a","start":14,"end":15,"id":3},{"text":"side","start":16,"end":20,"id":4},{"text":"effect","start":21,"end":27,"id":5},{"text":"we","start":28,"end":30,"id":6},{"text":"obtain","start":31,"end":37,"id":7},{"text":"a","start":38,"end":39,"id":8},{"text":"new","start":40,"end":43,"id":9},{"text":"training","start":44,"end":52,"id":10},{"text":"algorithm","start":53,"end":62,"id":11},{"text":"for","start":63,"end":66,"id":12},{"text":"learning","start":67,"end":75,"id":13},{"text":"sparse","start":76,"end":82,"id":14},{"text":"linear","start":83,"end":89,"id":15},{"text":"RLS","start":90,"end":93,"id":16},{"text":"predictors","start":94,"end":104,"id":17},{"text":"which","start":105,"end":110,"id":18},{"text":"can","start":111,"end":114,"id":19},{"text":"be","start":115,"end":117,"id":20},{"text":"used","start":118,"end":122,"id":21},{"text":"for","start":123,"end":126,"id":22},{"text":"large","start":127,"end":132,"id":23},{"text":"scale","start":133,"end":138,"id":24},{"text":"learning","start":139,"end":147,"id":25},{"text":".","start":147,"end":148,"id":26}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"This speed is possible due to matrix calculus based short-cuts for leave-one-out and feature addition.","_input_hash":-1995384002,"_task_hash":-2135375111,"tokens":[{"text":"This","start":0,"end":4,"id":0},{"text":"speed","start":5,"end":10,"id":1},{"text":"is","start":11,"end":13,"id":2},{"text":"possible","start":14,"end":22,"id":3},{"text":"due","start":23,"end":26,"id":4},{"text":"to","start":27,"end":29,"id":5},{"text":"matrix","start":30,"end":36,"id":6},{"text":"calculus","start":37,"end":45,"id":7},{"text":"based","start":46,"end":51,"id":8},{"text":"short","start":52,"end":57,"id":9},{"text":"-","start":57,"end":58,"id":10},{"text":"cuts","start":58,"end":62,"id":11},{"text":"for","start":63,"end":66,"id":12},{"text":"leave","start":67,"end":72,"id":13},{"text":"-","start":72,"end":73,"id":14},{"text":"one","start":73,"end":76,"id":15},{"text":"-","start":76,"end":77,"id":16},{"text":"out","start":77,"end":80,"id":17},{"text":"and","start":81,"end":84,"id":18},{"text":"feature","start":85,"end":92,"id":19},{"text":"addition","start":93,"end":101,"id":20},{"text":".","start":101,"end":102,"id":21}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We experimentally demonstrate the scalability of our algorithm and its ability to find good quality feature sets.","_input_hash":960831934,"_task_hash":389523829,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"experimentally","start":3,"end":17,"id":1},{"text":"demonstrate","start":18,"end":29,"id":2},{"text":"the","start":30,"end":33,"id":3},{"text":"scalability","start":34,"end":45,"id":4},{"text":"of","start":46,"end":48,"id":5},{"text":"our","start":49,"end":52,"id":6},{"text":"algorithm","start":53,"end":62,"id":7},{"text":"and","start":63,"end":66,"id":8},{"text":"its","start":67,"end":70,"id":9},{"text":"ability","start":71,"end":78,"id":10},{"text":"to","start":79,"end":81,"id":11},{"text":"find","start":82,"end":86,"id":12},{"text":"good","start":87,"end":91,"id":13},{"text":"quality","start":92,"end":99,"id":14},{"text":"feature","start":100,"end":107,"id":15},{"text":"sets","start":108,"end":112,"id":16},{"text":".","start":112,"end":113,"id":17}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"neural_net|NOUN","word":"neural net","sense":"NOUN","meta":{"score":0.888800025,"sense":"NOUN"},"_input_hash":327667319,"_task_hash":1731996153,"_session_id":null,"_view_id":"html","answer":"accept","spans":[],"tokens":[{"text":"neural_net|NOUN","start":0,"end":15,"id":0}]}
{"text":"complex_analysis|NOUN","word":"complex analysis","sense":"NOUN","meta":{"score":0.78549999,"sense":"NOUN"},"_input_hash":-591567848,"_task_hash":1719780762,"_session_id":null,"_view_id":"html","answer":"reject","spans":[],"tokens":[{"text":"complex_analysis|NOUN","start":0,"end":21,"id":0}]}
{"text":"Inferring the causal structure of a set of random variables from a finite sample of the joint distribution is an important problem in science.","_input_hash":-226428674,"_task_hash":1127368461,"tokens":[{"text":"Inferring","start":0,"end":9,"id":0},{"text":"the","start":10,"end":13,"id":1},{"text":"causal","start":14,"end":20,"id":2},{"text":"structure","start":21,"end":30,"id":3},{"text":"of","start":31,"end":33,"id":4},{"text":"a","start":34,"end":35,"id":5},{"text":"set","start":36,"end":39,"id":6},{"text":"of","start":40,"end":42,"id":7},{"text":"random","start":43,"end":49,"id":8},{"text":"variables","start":50,"end":59,"id":9},{"text":"from","start":60,"end":64,"id":10},{"text":"a","start":65,"end":66,"id":11},{"text":"finite","start":67,"end":73,"id":12},{"text":"sample","start":74,"end":80,"id":13},{"text":"of","start":81,"end":83,"id":14},{"text":"the","start":84,"end":87,"id":15},{"text":"joint","start":88,"end":93,"id":16},{"text":"distribution","start":94,"end":106,"id":17},{"text":"is","start":107,"end":109,"id":18},{"text":"an","start":110,"end":112,"id":19},{"text":"important","start":113,"end":122,"id":20},{"text":"problem","start":123,"end":130,"id":21},{"text":"in","start":131,"end":133,"id":22},{"text":"science","start":134,"end":141,"id":23},{"text":".","start":141,"end":142,"id":24}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"reject"}
{"text":"Recently, methods using additive noise models have been suggested to approach the case of continuous variables.","_input_hash":-1397565243,"_task_hash":887044363,"tokens":[{"text":"Recently","start":0,"end":8,"id":0},{"text":",","start":8,"end":9,"id":1},{"text":"methods","start":10,"end":17,"id":2},{"text":"using","start":18,"end":23,"id":3},{"text":"additive","start":24,"end":32,"id":4},{"text":"noise","start":33,"end":38,"id":5},{"text":"models","start":39,"end":45,"id":6},{"text":"have","start":46,"end":50,"id":7},{"text":"been","start":51,"end":55,"id":8},{"text":"suggested","start":56,"end":65,"id":9},{"text":"to","start":66,"end":68,"id":10},{"text":"approach","start":69,"end":77,"id":11},{"text":"the","start":78,"end":81,"id":12},{"text":"case","start":82,"end":86,"id":13},{"text":"of","start":87,"end":89,"id":14},{"text":"continuous","start":90,"end":100,"id":15},{"text":"variables","start":101,"end":110,"id":16},{"text":".","start":110,"end":111,"id":17}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":10,"end":17,"token_start":2,"token_end":2,"label":"ALGO","answer":"reject"}],"answer":"reject"}
{"text":"In many situations, however, the variables of interest are discrete or even have only finitely many states.","_input_hash":-1501278765,"_task_hash":860137680,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"many","start":3,"end":7,"id":1},{"text":"situations","start":8,"end":18,"id":2},{"text":",","start":18,"end":19,"id":3},{"text":"however","start":20,"end":27,"id":4},{"text":",","start":27,"end":28,"id":5},{"text":"the","start":29,"end":32,"id":6},{"text":"variables","start":33,"end":42,"id":7},{"text":"of","start":43,"end":45,"id":8},{"text":"interest","start":46,"end":54,"id":9},{"text":"are","start":55,"end":58,"id":10},{"text":"discrete","start":59,"end":67,"id":11},{"text":"or","start":68,"end":70,"id":12},{"text":"even","start":71,"end":75,"id":13},{"text":"have","start":76,"end":80,"id":14},{"text":"only","start":81,"end":85,"id":15},{"text":"finitely","start":86,"end":94,"id":16},{"text":"many","start":95,"end":99,"id":17},{"text":"states","start":100,"end":106,"id":18},{"text":".","start":106,"end":107,"id":19}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"reject"}
{"text":"In this work we extend the notion of additive noise models to these cases.","_input_hash":-1949067549,"_task_hash":1345403854,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"this","start":3,"end":7,"id":1},{"text":"work","start":8,"end":12,"id":2},{"text":"we","start":13,"end":15,"id":3},{"text":"extend","start":16,"end":22,"id":4},{"text":"the","start":23,"end":26,"id":5},{"text":"notion","start":27,"end":33,"id":6},{"text":"of","start":34,"end":36,"id":7},{"text":"additive","start":37,"end":45,"id":8},{"text":"noise","start":46,"end":51,"id":9},{"text":"models","start":52,"end":58,"id":10},{"text":"to","start":59,"end":61,"id":11},{"text":"these","start":62,"end":67,"id":12},{"text":"cases","start":68,"end":73,"id":13},{"text":".","start":73,"end":74,"id":14}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"reject"}
{"text":"We prove that whenever the joint distribution $\\prob^{(X,Y)}$ admits such a model in one direction, e.g. $Y=f(X)+N, N \\independent X$, it does not admit the reversed model $X=g(Y)+\\tilde N, \\tilde N \\independent Y$ as long as the model is chosen in a generic way.","_input_hash":-987262579,"_task_hash":1577215954,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"prove","start":3,"end":8,"id":1},{"text":"that","start":9,"end":13,"id":2},{"text":"whenever","start":14,"end":22,"id":3},{"text":"the","start":23,"end":26,"id":4},{"text":"joint","start":27,"end":32,"id":5},{"text":"distribution","start":33,"end":45,"id":6},{"text":"$","start":46,"end":47,"id":7},{"text":"\\prob^{(X","start":47,"end":56,"id":8},{"text":",","start":56,"end":57,"id":9},{"text":"Y)}$","start":57,"end":61,"id":10},{"text":"admits","start":62,"end":68,"id":11},{"text":"such","start":69,"end":73,"id":12},{"text":"a","start":74,"end":75,"id":13},{"text":"model","start":76,"end":81,"id":14},{"text":"in","start":82,"end":84,"id":15},{"text":"one","start":85,"end":88,"id":16},{"text":"direction","start":89,"end":98,"id":17},{"text":",","start":98,"end":99,"id":18},{"text":"e.g.","start":100,"end":104,"id":19},{"text":"$","start":105,"end":106,"id":20},{"text":"Y","start":106,"end":107,"id":21},{"text":"=","start":107,"end":108,"id":22},{"text":"f(X)+N","start":108,"end":114,"id":23},{"text":",","start":114,"end":115,"id":24},{"text":"N","start":116,"end":117,"id":25},{"text":"\\independent","start":118,"end":130,"id":26},{"text":"X$","start":131,"end":133,"id":27},{"text":",","start":133,"end":134,"id":28},{"text":"it","start":135,"end":137,"id":29},{"text":"does","start":138,"end":142,"id":30},{"text":"not","start":143,"end":146,"id":31},{"text":"admit","start":147,"end":152,"id":32},{"text":"the","start":153,"end":156,"id":33},{"text":"reversed","start":157,"end":165,"id":34},{"text":"model","start":166,"end":171,"id":35},{"text":"$","start":172,"end":173,"id":36},{"text":"X","start":173,"end":174,"id":37},{"text":"=","start":174,"end":175,"id":38},{"text":"g(Y)+\\tilde","start":175,"end":186,"id":39},{"text":"N","start":187,"end":188,"id":40},{"text":",","start":188,"end":189,"id":41},{"text":"\\tilde","start":190,"end":196,"id":42},{"text":"N","start":197,"end":198,"id":43},{"text":"\\independent","start":199,"end":211,"id":44},{"text":"Y$","start":212,"end":214,"id":45},{"text":"as","start":215,"end":217,"id":46},{"text":"long","start":218,"end":222,"id":47},{"text":"as","start":223,"end":225,"id":48},{"text":"the","start":226,"end":229,"id":49},{"text":"model","start":230,"end":235,"id":50},{"text":"is","start":236,"end":238,"id":51},{"text":"chosen","start":239,"end":245,"id":52},{"text":"in","start":246,"end":248,"id":53},{"text":"a","start":249,"end":250,"id":54},{"text":"generic","start":251,"end":258,"id":55},{"text":"way","start":259,"end":262,"id":56},{"text":".","start":262,"end":263,"id":57}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":74,"end":81,"token_start":13,"token_end":14,"label":"ALGO","answer":"reject"}],"answer":"reject"}
{"text":"Based on these deliberations we propose an efficient new algorithm that is able to distinguish between cause and effect for a finite sample of discrete variables.","_input_hash":-1203683082,"_task_hash":1950838215,"tokens":[{"text":"Based","start":0,"end":5,"id":0},{"text":"on","start":6,"end":8,"id":1},{"text":"these","start":9,"end":14,"id":2},{"text":"deliberations","start":15,"end":28,"id":3},{"text":"we","start":29,"end":31,"id":4},{"text":"propose","start":32,"end":39,"id":5},{"text":"an","start":40,"end":42,"id":6},{"text":"efficient","start":43,"end":52,"id":7},{"text":"new","start":53,"end":56,"id":8},{"text":"algorithm","start":57,"end":66,"id":9},{"text":"that","start":67,"end":71,"id":10},{"text":"is","start":72,"end":74,"id":11},{"text":"able","start":75,"end":79,"id":12},{"text":"to","start":80,"end":82,"id":13},{"text":"distinguish","start":83,"end":94,"id":14},{"text":"between","start":95,"end":102,"id":15},{"text":"cause","start":103,"end":108,"id":16},{"text":"and","start":109,"end":112,"id":17},{"text":"effect","start":113,"end":119,"id":18},{"text":"for","start":120,"end":123,"id":19},{"text":"a","start":124,"end":125,"id":20},{"text":"finite","start":126,"end":132,"id":21},{"text":"sample","start":133,"end":139,"id":22},{"text":"of","start":140,"end":142,"id":23},{"text":"discrete","start":143,"end":151,"id":24},{"text":"variables","start":152,"end":161,"id":25},{"text":".","start":161,"end":162,"id":26}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":53,"end":66,"token_start":8,"token_end":9,"label":"ALGO","answer":"reject"},{"start":126,"end":139,"token_start":21,"token_end":22,"label":"ALGO","answer":"reject"}],"answer":"reject"}
{"text":"In an extensive experimental study we show that this algorithm works both on synthetic and real data sets.","_input_hash":-2100705351,"_task_hash":-985802119,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"an","start":3,"end":5,"id":1},{"text":"extensive","start":6,"end":15,"id":2},{"text":"experimental","start":16,"end":28,"id":3},{"text":"study","start":29,"end":34,"id":4},{"text":"we","start":35,"end":37,"id":5},{"text":"show","start":38,"end":42,"id":6},{"text":"that","start":43,"end":47,"id":7},{"text":"this","start":48,"end":52,"id":8},{"text":"algorithm","start":53,"end":62,"id":9},{"text":"works","start":63,"end":68,"id":10},{"text":"both","start":69,"end":73,"id":11},{"text":"on","start":74,"end":76,"id":12},{"text":"synthetic","start":77,"end":86,"id":13},{"text":"and","start":87,"end":90,"id":14},{"text":"real","start":91,"end":95,"id":15},{"text":"data","start":96,"end":100,"id":16},{"text":"sets","start":101,"end":105,"id":17},{"text":".","start":105,"end":106,"id":18}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":16,"end":34,"token_start":3,"token_end":4,"label":"ALGO","answer":"reject"},{"start":48,"end":62,"token_start":8,"token_end":9,"label":"ALGO","answer":"reject"}],"answer":"reject"}
{"text":"biological_brains|NOUN","word":"biological brains","sense":"NOUN","meta":{"score":0.8004000187,"sense":"NOUN"},"_input_hash":1759839253,"_task_hash":-1133211243,"_session_id":null,"_view_id":"html","answer":"reject","spans":[],"tokens":[{"text":"biological_brains|NOUN","start":0,"end":22,"id":0}]}
{"text":"algorithmically|ADV","word":"algorithmically","sense":"ADV","meta":{"score":0.7506999969,"sense":"ADV"},"_input_hash":1562091384,"_task_hash":-1423476466,"_session_id":null,"_view_id":"html","answer":"reject","spans":[],"tokens":[{"text":"algorithmically|ADV","start":0,"end":19,"id":0}]}
{"text":"Interest in multioutput kernel methods is increasing, whether under the guise of multitask learning, multisensor networks or structured output data.","_input_hash":2008230764,"_task_hash":-2071957099,"tokens":[{"text":"Interest","start":0,"end":8,"id":0},{"text":"in","start":9,"end":11,"id":1},{"text":"multioutput","start":12,"end":23,"id":2},{"text":"kernel","start":24,"end":30,"id":3},{"text":"methods","start":31,"end":38,"id":4},{"text":"is","start":39,"end":41,"id":5},{"text":"increasing","start":42,"end":52,"id":6},{"text":",","start":52,"end":53,"id":7},{"text":"whether","start":54,"end":61,"id":8},{"text":"under","start":62,"end":67,"id":9},{"text":"the","start":68,"end":71,"id":10},{"text":"guise","start":72,"end":77,"id":11},{"text":"of","start":78,"end":80,"id":12},{"text":"multitask","start":81,"end":90,"id":13},{"text":"learning","start":91,"end":99,"id":14},{"text":",","start":99,"end":100,"id":15},{"text":"multisensor","start":101,"end":112,"id":16},{"text":"networks","start":113,"end":121,"id":17},{"text":"or","start":122,"end":124,"id":18},{"text":"structured","start":125,"end":135,"id":19},{"text":"output","start":136,"end":142,"id":20},{"text":"data","start":143,"end":147,"id":21},{"text":".","start":147,"end":148,"id":22}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"From the Gaussian process perspective a multioutput Mercer kernel is a covariance function over correlated output functions.","_input_hash":-328419593,"_task_hash":-1365972980,"tokens":[{"text":"From","start":0,"end":4,"id":0},{"text":"the","start":5,"end":8,"id":1},{"text":"Gaussian","start":9,"end":17,"id":2},{"text":"process","start":18,"end":25,"id":3},{"text":"perspective","start":26,"end":37,"id":4},{"text":"a","start":38,"end":39,"id":5},{"text":"multioutput","start":40,"end":51,"id":6},{"text":"Mercer","start":52,"end":58,"id":7},{"text":"kernel","start":59,"end":65,"id":8},{"text":"is","start":66,"end":68,"id":9},{"text":"a","start":69,"end":70,"id":10},{"text":"covariance","start":71,"end":81,"id":11},{"text":"function","start":82,"end":90,"id":12},{"text":"over","start":91,"end":95,"id":13},{"text":"correlated","start":96,"end":106,"id":14},{"text":"output","start":107,"end":113,"id":15},{"text":"functions","start":114,"end":123,"id":16},{"text":".","start":123,"end":124,"id":17}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"One way of constructing such kernels is based on convolution processes (CP).","_input_hash":-776527507,"_task_hash":-1702785465,"tokens":[{"text":"One","start":0,"end":3,"id":0},{"text":"way","start":4,"end":7,"id":1},{"text":"of","start":8,"end":10,"id":2},{"text":"constructing","start":11,"end":23,"id":3},{"text":"such","start":24,"end":28,"id":4},{"text":"kernels","start":29,"end":36,"id":5},{"text":"is","start":37,"end":39,"id":6},{"text":"based","start":40,"end":45,"id":7},{"text":"on","start":46,"end":48,"id":8},{"text":"convolution","start":49,"end":60,"id":9},{"text":"processes","start":61,"end":70,"id":10},{"text":"(","start":71,"end":72,"id":11},{"text":"CP","start":72,"end":74,"id":12},{"text":")","start":74,"end":75,"id":13},{"text":".","start":75,"end":76,"id":14}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"A key problem for this approach is efficient inference.","_input_hash":1305790756,"_task_hash":1377693624,"tokens":[{"text":"A","start":0,"end":1,"id":0},{"text":"key","start":2,"end":5,"id":1},{"text":"problem","start":6,"end":13,"id":2},{"text":"for","start":14,"end":17,"id":3},{"text":"this","start":18,"end":22,"id":4},{"text":"approach","start":23,"end":31,"id":5},{"text":"is","start":32,"end":34,"id":6},{"text":"efficient","start":35,"end":44,"id":7},{"text":"inference","start":45,"end":54,"id":8},{"text":".","start":54,"end":55,"id":9}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Alvarez and Lawrence (2009) recently presented a sparse approximation for CPs that enabled efficient inference.","_input_hash":-744215215,"_task_hash":1018736372,"tokens":[{"text":"Alvarez","start":0,"end":7,"id":0},{"text":"and","start":8,"end":11,"id":1},{"text":"Lawrence","start":12,"end":20,"id":2},{"text":"(","start":21,"end":22,"id":3},{"text":"2009","start":22,"end":26,"id":4},{"text":")","start":26,"end":27,"id":5},{"text":"recently","start":28,"end":36,"id":6},{"text":"presented","start":37,"end":46,"id":7},{"text":"a","start":47,"end":48,"id":8},{"text":"sparse","start":49,"end":55,"id":9},{"text":"approximation","start":56,"end":69,"id":10},{"text":"for","start":70,"end":73,"id":11},{"text":"CPs","start":74,"end":77,"id":12},{"text":"that","start":78,"end":82,"id":13},{"text":"enabled","start":83,"end":90,"id":14},{"text":"efficient","start":91,"end":100,"id":15},{"text":"inference","start":101,"end":110,"id":16},{"text":".","start":110,"end":111,"id":17}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"In this paper, we extend this work in two directions:","_input_hash":-1544879125,"_task_hash":-541143668,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"this","start":3,"end":7,"id":1},{"text":"paper","start":8,"end":13,"id":2},{"text":",","start":13,"end":14,"id":3},{"text":"we","start":15,"end":17,"id":4},{"text":"extend","start":18,"end":24,"id":5},{"text":"this","start":25,"end":29,"id":6},{"text":"work","start":30,"end":34,"id":7},{"text":"in","start":35,"end":37,"id":8},{"text":"two","start":38,"end":41,"id":9},{"text":"directions","start":42,"end":52,"id":10},{"text":":","start":52,"end":53,"id":11}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"we introduce the concept of variational inducing functions to handle potential non-smooth functions involved in the kernel CP construction and we consider an alternative approach to approximate inference based on variational methods, extending the work by Titsias (2009) to the multiple output case.","_input_hash":1696454829,"_task_hash":1439149098,"tokens":[{"text":"we","start":0,"end":2,"id":0},{"text":"introduce","start":3,"end":12,"id":1},{"text":"the","start":13,"end":16,"id":2},{"text":"concept","start":17,"end":24,"id":3},{"text":"of","start":25,"end":27,"id":4},{"text":"variational","start":28,"end":39,"id":5},{"text":"inducing","start":40,"end":48,"id":6},{"text":"functions","start":49,"end":58,"id":7},{"text":"to","start":59,"end":61,"id":8},{"text":"handle","start":62,"end":68,"id":9},{"text":"potential","start":69,"end":78,"id":10},{"text":"non","start":79,"end":82,"id":11},{"text":"-","start":82,"end":83,"id":12},{"text":"smooth","start":83,"end":89,"id":13},{"text":"functions","start":90,"end":99,"id":14},{"text":"involved","start":100,"end":108,"id":15},{"text":"in","start":109,"end":111,"id":16},{"text":"the","start":112,"end":115,"id":17},{"text":"kernel","start":116,"end":122,"id":18},{"text":"CP","start":123,"end":125,"id":19},{"text":"construction","start":126,"end":138,"id":20},{"text":"and","start":139,"end":142,"id":21},{"text":"we","start":143,"end":145,"id":22},{"text":"consider","start":146,"end":154,"id":23},{"text":"an","start":155,"end":157,"id":24},{"text":"alternative","start":158,"end":169,"id":25},{"text":"approach","start":170,"end":178,"id":26},{"text":"to","start":179,"end":181,"id":27},{"text":"approximate","start":182,"end":193,"id":28},{"text":"inference","start":194,"end":203,"id":29},{"text":"based","start":204,"end":209,"id":30},{"text":"on","start":210,"end":212,"id":31},{"text":"variational","start":213,"end":224,"id":32},{"text":"methods","start":225,"end":232,"id":33},{"text":",","start":232,"end":233,"id":34},{"text":"extending","start":234,"end":243,"id":35},{"text":"the","start":244,"end":247,"id":36},{"text":"work","start":248,"end":252,"id":37},{"text":"by","start":253,"end":255,"id":38},{"text":"Titsias","start":256,"end":263,"id":39},{"text":"(","start":264,"end":265,"id":40},{"text":"2009","start":265,"end":269,"id":41},{"text":")","start":269,"end":270,"id":42},{"text":"to","start":271,"end":273,"id":43},{"text":"the","start":274,"end":277,"id":44},{"text":"multiple","start":278,"end":286,"id":45},{"text":"output","start":287,"end":293,"id":46},{"text":"case","start":294,"end":298,"id":47},{"text":".","start":298,"end":299,"id":48}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We demonstrate our approaches on prediction of school marks, compiler performance and financial time series.","_input_hash":1100200223,"_task_hash":-1448458530,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"demonstrate","start":3,"end":14,"id":1},{"text":"our","start":15,"end":18,"id":2},{"text":"approaches","start":19,"end":29,"id":3},{"text":"on","start":30,"end":32,"id":4},{"text":"prediction","start":33,"end":43,"id":5},{"text":"of","start":44,"end":46,"id":6},{"text":"school","start":47,"end":53,"id":7},{"text":"marks","start":54,"end":59,"id":8},{"text":",","start":59,"end":60,"id":9},{"text":"compiler","start":61,"end":69,"id":10},{"text":"performance","start":70,"end":81,"id":11},{"text":"and","start":82,"end":85,"id":12},{"text":"financial","start":86,"end":95,"id":13},{"text":"time","start":96,"end":100,"id":14},{"text":"series","start":101,"end":107,"id":15},{"text":".","start":107,"end":108,"id":16}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"human_cognition|NOUN","word":"human cognition","sense":"NOUN","meta":{"score":0.7595000267,"sense":"NOUN"},"_input_hash":-1472026555,"_task_hash":23911419,"_session_id":null,"_view_id":"html","answer":"reject","spans":[],"tokens":[{"text":"human_cognition|NOUN","start":0,"end":20,"id":0}]}
{"text":"large_data_sets|NOUN","word":"large data sets","sense":"NOUN","meta":{"score":0.7886999846,"sense":"NOUN"},"_input_hash":-242871822,"_task_hash":-1380257793,"_session_id":null,"_view_id":"html","answer":"reject","spans":[],"tokens":[{"text":"large_data_sets|NOUN","start":0,"end":20,"id":0}]}
{"text":"logistic_regression|NOUN","word":"logistic regression","sense":"NOUN","meta":{"score":0.8140000105,"sense":"NOUN"},"_input_hash":1642957147,"_task_hash":2066501918,"_session_id":null,"_view_id":"html","answer":"accept","spans":[],"tokens":[{"text":"logistic_regression|NOUN","start":0,"end":24,"id":0}]}
{"text":"Dimensionality reduction is a topic of recent interest.","_input_hash":2135991398,"_task_hash":90492257,"tokens":[{"text":"Dimensionality","start":0,"end":14,"id":0},{"text":"reduction","start":15,"end":24,"id":1},{"text":"is","start":25,"end":27,"id":2},{"text":"a","start":28,"end":29,"id":3},{"text":"topic","start":30,"end":35,"id":4},{"text":"of","start":36,"end":38,"id":5},{"text":"recent","start":39,"end":45,"id":6},{"text":"interest","start":46,"end":54,"id":7},{"text":".","start":54,"end":55,"id":8}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"In this paper, we present the classification constrained dimensionality reduction (CCDR) algorithm to account for label information.","_input_hash":-837527872,"_task_hash":1040060962,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"this","start":3,"end":7,"id":1},{"text":"paper","start":8,"end":13,"id":2},{"text":",","start":13,"end":14,"id":3},{"text":"we","start":15,"end":17,"id":4},{"text":"present","start":18,"end":25,"id":5},{"text":"the","start":26,"end":29,"id":6},{"text":"classification","start":30,"end":44,"id":7},{"text":"constrained","start":45,"end":56,"id":8},{"text":"dimensionality","start":57,"end":71,"id":9},{"text":"reduction","start":72,"end":81,"id":10},{"text":"(","start":82,"end":83,"id":11},{"text":"CCDR","start":83,"end":87,"id":12},{"text":")","start":87,"end":88,"id":13},{"text":"algorithm","start":89,"end":98,"id":14},{"text":"to","start":99,"end":101,"id":15},{"text":"account","start":102,"end":109,"id":16},{"text":"for","start":110,"end":113,"id":17},{"text":"label","start":114,"end":119,"id":18},{"text":"information","start":120,"end":131,"id":19},{"text":".","start":131,"end":132,"id":20}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":30,"end":81,"token_start":7,"token_end":10,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"The algorithm can account for multiple classes as well as the semi-supervised setting.","_input_hash":-1517052669,"_task_hash":-985925882,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"algorithm","start":4,"end":13,"id":1},{"text":"can","start":14,"end":17,"id":2},{"text":"account","start":18,"end":25,"id":3},{"text":"for","start":26,"end":29,"id":4},{"text":"multiple","start":30,"end":38,"id":5},{"text":"classes","start":39,"end":46,"id":6},{"text":"as","start":47,"end":49,"id":7},{"text":"well","start":50,"end":54,"id":8},{"text":"as","start":55,"end":57,"id":9},{"text":"the","start":58,"end":61,"id":10},{"text":"semi","start":62,"end":66,"id":11},{"text":"-","start":66,"end":67,"id":12},{"text":"supervised","start":67,"end":77,"id":13},{"text":"setting","start":78,"end":85,"id":14},{"text":".","start":85,"end":86,"id":15}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We present an out-of-sample expressions for both labeled and unlabeled data.","_input_hash":2024165145,"_task_hash":1186591962,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"present","start":3,"end":10,"id":1},{"text":"an","start":11,"end":13,"id":2},{"text":"out","start":14,"end":17,"id":3},{"text":"-","start":17,"end":18,"id":4},{"text":"of","start":18,"end":20,"id":5},{"text":"-","start":20,"end":21,"id":6},{"text":"sample","start":21,"end":27,"id":7},{"text":"expressions","start":28,"end":39,"id":8},{"text":"for","start":40,"end":43,"id":9},{"text":"both","start":44,"end":48,"id":10},{"text":"labeled","start":49,"end":56,"id":11},{"text":"and","start":57,"end":60,"id":12},{"text":"unlabeled","start":61,"end":70,"id":13},{"text":"data","start":71,"end":75,"id":14},{"text":".","start":75,"end":76,"id":15}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"For unlabeled data, we introduce a method of embedding a new point as preprocessing to a classifier.","_input_hash":1850829439,"_task_hash":963755807,"tokens":[{"text":"For","start":0,"end":3,"id":0},{"text":"unlabeled","start":4,"end":13,"id":1},{"text":"data","start":14,"end":18,"id":2},{"text":",","start":18,"end":19,"id":3},{"text":"we","start":20,"end":22,"id":4},{"text":"introduce","start":23,"end":32,"id":5},{"text":"a","start":33,"end":34,"id":6},{"text":"method","start":35,"end":41,"id":7},{"text":"of","start":42,"end":44,"id":8},{"text":"embedding","start":45,"end":54,"id":9},{"text":"a","start":55,"end":56,"id":10},{"text":"new","start":57,"end":60,"id":11},{"text":"point","start":61,"end":66,"id":12},{"text":"as","start":67,"end":69,"id":13},{"text":"preprocessing","start":70,"end":83,"id":14},{"text":"to","start":84,"end":86,"id":15},{"text":"a","start":87,"end":88,"id":16},{"text":"classifier","start":89,"end":99,"id":17},{"text":".","start":99,"end":100,"id":18}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"For labeled data, we introduce a method that improves the embedding during the training phase using the out-of-sample extension.","_input_hash":1108733217,"_task_hash":992685221,"tokens":[{"text":"For","start":0,"end":3,"id":0},{"text":"labeled","start":4,"end":11,"id":1},{"text":"data","start":12,"end":16,"id":2},{"text":",","start":16,"end":17,"id":3},{"text":"we","start":18,"end":20,"id":4},{"text":"introduce","start":21,"end":30,"id":5},{"text":"a","start":31,"end":32,"id":6},{"text":"method","start":33,"end":39,"id":7},{"text":"that","start":40,"end":44,"id":8},{"text":"improves","start":45,"end":53,"id":9},{"text":"the","start":54,"end":57,"id":10},{"text":"embedding","start":58,"end":67,"id":11},{"text":"during","start":68,"end":74,"id":12},{"text":"the","start":75,"end":78,"id":13},{"text":"training","start":79,"end":87,"id":14},{"text":"phase","start":88,"end":93,"id":15},{"text":"using","start":94,"end":99,"id":16},{"text":"the","start":100,"end":103,"id":17},{"text":"out","start":104,"end":107,"id":18},{"text":"-","start":107,"end":108,"id":19},{"text":"of","start":108,"end":110,"id":20},{"text":"-","start":110,"end":111,"id":21},{"text":"sample","start":111,"end":117,"id":22},{"text":"extension","start":118,"end":127,"id":23},{"text":".","start":127,"end":128,"id":24}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We investigate classification performance using the CCDR algorithm on hyper-spectral satellite imagery data.","_input_hash":-1472662451,"_task_hash":-1313533480,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"investigate","start":3,"end":14,"id":1},{"text":"classification","start":15,"end":29,"id":2},{"text":"performance","start":30,"end":41,"id":3},{"text":"using","start":42,"end":47,"id":4},{"text":"the","start":48,"end":51,"id":5},{"text":"CCDR","start":52,"end":56,"id":6},{"text":"algorithm","start":57,"end":66,"id":7},{"text":"on","start":67,"end":69,"id":8},{"text":"hyper","start":70,"end":75,"id":9},{"text":"-","start":75,"end":76,"id":10},{"text":"spectral","start":76,"end":84,"id":11},{"text":"satellite","start":85,"end":94,"id":12},{"text":"imagery","start":95,"end":102,"id":13},{"text":"data","start":103,"end":107,"id":14},{"text":".","start":107,"end":108,"id":15}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We demonstrate the performance gain for both local and global classifiers and demonstrate a 10% improvement of the $k$-nearest neighbors algorithm performance.","_input_hash":-1173540332,"_task_hash":949256519,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"demonstrate","start":3,"end":14,"id":1},{"text":"the","start":15,"end":18,"id":2},{"text":"performance","start":19,"end":30,"id":3},{"text":"gain","start":31,"end":35,"id":4},{"text":"for","start":36,"end":39,"id":5},{"text":"both","start":40,"end":44,"id":6},{"text":"local","start":45,"end":50,"id":7},{"text":"and","start":51,"end":54,"id":8},{"text":"global","start":55,"end":61,"id":9},{"text":"classifiers","start":62,"end":73,"id":10},{"text":"and","start":74,"end":77,"id":11},{"text":"demonstrate","start":78,"end":89,"id":12},{"text":"a","start":90,"end":91,"id":13},{"text":"10","start":92,"end":94,"id":14},{"text":"%","start":94,"end":95,"id":15},{"text":"improvement","start":96,"end":107,"id":16},{"text":"of","start":108,"end":110,"id":17},{"text":"the","start":111,"end":114,"id":18},{"text":"$","start":115,"end":116,"id":19},{"text":"k$-nearest","start":116,"end":126,"id":20},{"text":"neighbors","start":127,"end":136,"id":21},{"text":"algorithm","start":137,"end":146,"id":22},{"text":"performance","start":147,"end":158,"id":23},{"text":".","start":158,"end":159,"id":24}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":115,"end":136,"token_start":19,"token_end":21,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"We present a connection between intrinsic dimension estimation and the optimal embedding dimension obtained using the CCDR algorithm.","_input_hash":-812107236,"_task_hash":-1554159351,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"present","start":3,"end":10,"id":1},{"text":"a","start":11,"end":12,"id":2},{"text":"connection","start":13,"end":23,"id":3},{"text":"between","start":24,"end":31,"id":4},{"text":"intrinsic","start":32,"end":41,"id":5},{"text":"dimension","start":42,"end":51,"id":6},{"text":"estimation","start":52,"end":62,"id":7},{"text":"and","start":63,"end":66,"id":8},{"text":"the","start":67,"end":70,"id":9},{"text":"optimal","start":71,"end":78,"id":10},{"text":"embedding","start":79,"end":88,"id":11},{"text":"dimension","start":89,"end":98,"id":12},{"text":"obtained","start":99,"end":107,"id":13},{"text":"using","start":108,"end":113,"id":14},{"text":"the","start":114,"end":117,"id":15},{"text":"CCDR","start":118,"end":122,"id":16},{"text":"algorithm","start":123,"end":132,"id":17},{"text":".","start":132,"end":133,"id":18}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"quantum_computation|NOUN","word":"quantum computation","sense":"NOUN","meta":{"score":0.7868000269,"sense":"NOUN"},"_input_hash":1884739246,"_task_hash":-265048370,"_session_id":null,"_view_id":"html","answer":"reject","spans":[],"tokens":[{"text":"quantum_computation|NOUN","start":0,"end":24,"id":0}]}
{"text":"lovin","meta":{"score":0},"_input_hash":142653968,"_task_hash":-2075007546,"_session_id":null,"_view_id":"text","answer":"reject","spans":[],"tokens":[{"text":"lovin","start":0,"end":5,"id":0}]}
{"text":"algorithmic|ADJ","word":"algorithmic","sense":"ADJ","meta":{"score":0.787800014,"sense":"ADJ"},"_input_hash":-1607624112,"_task_hash":73191430,"_session_id":null,"_view_id":"html","answer":"reject","spans":[],"tokens":[{"text":"algorithmic|ADJ","start":0,"end":15,"id":0}]}
{"text":"This thesis responds to the challenges of using a large number, such as thousands, of features in regression and classification problems.","_input_hash":179630665,"_task_hash":-187982617,"tokens":[{"text":"This","start":0,"end":4,"id":0},{"text":"thesis","start":5,"end":11,"id":1},{"text":"responds","start":12,"end":20,"id":2},{"text":"to","start":21,"end":23,"id":3},{"text":"the","start":24,"end":27,"id":4},{"text":"challenges","start":28,"end":38,"id":5},{"text":"of","start":39,"end":41,"id":6},{"text":"using","start":42,"end":47,"id":7},{"text":"a","start":48,"end":49,"id":8},{"text":"large","start":50,"end":55,"id":9},{"text":"number","start":56,"end":62,"id":10},{"text":",","start":62,"end":63,"id":11},{"text":"such","start":64,"end":68,"id":12},{"text":"as","start":69,"end":71,"id":13},{"text":"thousands","start":72,"end":81,"id":14},{"text":",","start":81,"end":82,"id":15},{"text":"of","start":83,"end":85,"id":16},{"text":"features","start":86,"end":94,"id":17},{"text":"in","start":95,"end":97,"id":18},{"text":"regression","start":98,"end":108,"id":19},{"text":"and","start":109,"end":112,"id":20},{"text":"classification","start":113,"end":127,"id":21},{"text":"problems","start":128,"end":136,"id":22},{"text":".","start":136,"end":137,"id":23}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"  There are two situations where such high dimensional features arise.","_input_hash":237257470,"_task_hash":-1881310355,"tokens":[{"text":"  ","start":0,"end":2,"id":0},{"text":"There","start":2,"end":7,"id":1},{"text":"are","start":8,"end":11,"id":2},{"text":"two","start":12,"end":15,"id":3},{"text":"situations","start":16,"end":26,"id":4},{"text":"where","start":27,"end":32,"id":5},{"text":"such","start":33,"end":37,"id":6},{"text":"high","start":38,"end":42,"id":7},{"text":"dimensional","start":43,"end":54,"id":8},{"text":"features","start":55,"end":63,"id":9},{"text":"arise","start":64,"end":69,"id":10},{"text":".","start":69,"end":70,"id":11}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"One is when high dimensional measurements are available, for example, gene expression data produced by microarray techniques.","_input_hash":492717479,"_task_hash":1185154125,"tokens":[{"text":"One","start":0,"end":3,"id":0},{"text":"is","start":4,"end":6,"id":1},{"text":"when","start":7,"end":11,"id":2},{"text":"high","start":12,"end":16,"id":3},{"text":"dimensional","start":17,"end":28,"id":4},{"text":"measurements","start":29,"end":41,"id":5},{"text":"are","start":42,"end":45,"id":6},{"text":"available","start":46,"end":55,"id":7},{"text":",","start":55,"end":56,"id":8},{"text":"for","start":57,"end":60,"id":9},{"text":"example","start":61,"end":68,"id":10},{"text":",","start":68,"end":69,"id":11},{"text":"gene","start":70,"end":74,"id":12},{"text":"expression","start":75,"end":85,"id":13},{"text":"data","start":86,"end":90,"id":14},{"text":"produced","start":91,"end":99,"id":15},{"text":"by","start":100,"end":102,"id":16},{"text":"microarray","start":103,"end":113,"id":17},{"text":"techniques","start":114,"end":124,"id":18},{"text":".","start":124,"end":125,"id":19}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"For computational or other reasons, people may select only a small subset of features when modelling such data, by looking at how relevant the features are to predicting the response, based on some measure such as correlation with the response in the training data.","_input_hash":-901972611,"_task_hash":240848819,"tokens":[{"text":"For","start":0,"end":3,"id":0},{"text":"computational","start":4,"end":17,"id":1},{"text":"or","start":18,"end":20,"id":2},{"text":"other","start":21,"end":26,"id":3},{"text":"reasons","start":27,"end":34,"id":4},{"text":",","start":34,"end":35,"id":5},{"text":"people","start":36,"end":42,"id":6},{"text":"may","start":43,"end":46,"id":7},{"text":"select","start":47,"end":53,"id":8},{"text":"only","start":54,"end":58,"id":9},{"text":"a","start":59,"end":60,"id":10},{"text":"small","start":61,"end":66,"id":11},{"text":"subset","start":67,"end":73,"id":12},{"text":"of","start":74,"end":76,"id":13},{"text":"features","start":77,"end":85,"id":14},{"text":"when","start":86,"end":90,"id":15},{"text":"modelling","start":91,"end":100,"id":16},{"text":"such","start":101,"end":105,"id":17},{"text":"data","start":106,"end":110,"id":18},{"text":",","start":110,"end":111,"id":19},{"text":"by","start":112,"end":114,"id":20},{"text":"looking","start":115,"end":122,"id":21},{"text":"at","start":123,"end":125,"id":22},{"text":"how","start":126,"end":129,"id":23},{"text":"relevant","start":130,"end":138,"id":24},{"text":"the","start":139,"end":142,"id":25},{"text":"features","start":143,"end":151,"id":26},{"text":"are","start":152,"end":155,"id":27},{"text":"to","start":156,"end":158,"id":28},{"text":"predicting","start":159,"end":169,"id":29},{"text":"the","start":170,"end":173,"id":30},{"text":"response","start":174,"end":182,"id":31},{"text":",","start":182,"end":183,"id":32},{"text":"based","start":184,"end":189,"id":33},{"text":"on","start":190,"end":192,"id":34},{"text":"some","start":193,"end":197,"id":35},{"text":"measure","start":198,"end":205,"id":36},{"text":"such","start":206,"end":210,"id":37},{"text":"as","start":211,"end":213,"id":38},{"text":"correlation","start":214,"end":225,"id":39},{"text":"with","start":226,"end":230,"id":40},{"text":"the","start":231,"end":234,"id":41},{"text":"response","start":235,"end":243,"id":42},{"text":"in","start":244,"end":246,"id":43},{"text":"the","start":247,"end":250,"id":44},{"text":"training","start":251,"end":259,"id":45},{"text":"data","start":260,"end":264,"id":46},{"text":".","start":264,"end":265,"id":47}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Although it is used very commonly, this procedure will make the response appear more predictable than it actually is.","_input_hash":2035627713,"_task_hash":-838434883,"tokens":[{"text":"Although","start":0,"end":8,"id":0},{"text":"it","start":9,"end":11,"id":1},{"text":"is","start":12,"end":14,"id":2},{"text":"used","start":15,"end":19,"id":3},{"text":"very","start":20,"end":24,"id":4},{"text":"commonly","start":25,"end":33,"id":5},{"text":",","start":33,"end":34,"id":6},{"text":"this","start":35,"end":39,"id":7},{"text":"procedure","start":40,"end":49,"id":8},{"text":"will","start":50,"end":54,"id":9},{"text":"make","start":55,"end":59,"id":10},{"text":"the","start":60,"end":63,"id":11},{"text":"response","start":64,"end":72,"id":12},{"text":"appear","start":73,"end":79,"id":13},{"text":"more","start":80,"end":84,"id":14},{"text":"predictable","start":85,"end":96,"id":15},{"text":"than","start":97,"end":101,"id":16},{"text":"it","start":102,"end":104,"id":17},{"text":"actually","start":105,"end":113,"id":18},{"text":"is","start":114,"end":116,"id":19},{"text":".","start":116,"end":117,"id":20}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"In Chapter 2, we propose a Bayesian method to avoid this selection bias, with application to naive Bayes models and mixture models.","_input_hash":-134608525,"_task_hash":1376010191,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"Chapter","start":3,"end":10,"id":1},{"text":"2","start":11,"end":12,"id":2},{"text":",","start":12,"end":13,"id":3},{"text":"we","start":14,"end":16,"id":4},{"text":"propose","start":17,"end":24,"id":5},{"text":"a","start":25,"end":26,"id":6},{"text":"Bayesian","start":27,"end":35,"id":7},{"text":"method","start":36,"end":42,"id":8},{"text":"to","start":43,"end":45,"id":9},{"text":"avoid","start":46,"end":51,"id":10},{"text":"this","start":52,"end":56,"id":11},{"text":"selection","start":57,"end":66,"id":12},{"text":"bias","start":67,"end":71,"id":13},{"text":",","start":71,"end":72,"id":14},{"text":"with","start":73,"end":77,"id":15},{"text":"application","start":78,"end":89,"id":16},{"text":"to","start":90,"end":92,"id":17},{"text":"naive","start":93,"end":98,"id":18},{"text":"Bayes","start":99,"end":104,"id":19},{"text":"models","start":105,"end":111,"id":20},{"text":"and","start":112,"end":115,"id":21},{"text":"mixture","start":116,"end":123,"id":22},{"text":"models","start":124,"end":130,"id":23},{"text":".","start":130,"end":131,"id":24}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":93,"end":111,"token_start":18,"token_end":20,"label":"ALGO","answer":"accept"},{"start":116,"end":130,"token_start":22,"token_end":23,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"  High dimensional features also arise when we consider high-order interactions.","_input_hash":-910918860,"_task_hash":852057726,"tokens":[{"text":"  ","start":0,"end":2,"id":0},{"text":"High","start":2,"end":6,"id":1},{"text":"dimensional","start":7,"end":18,"id":2},{"text":"features","start":19,"end":27,"id":3},{"text":"also","start":28,"end":32,"id":4},{"text":"arise","start":33,"end":38,"id":5},{"text":"when","start":39,"end":43,"id":6},{"text":"we","start":44,"end":46,"id":7},{"text":"consider","start":47,"end":55,"id":8},{"text":"high","start":56,"end":60,"id":9},{"text":"-","start":60,"end":61,"id":10},{"text":"order","start":61,"end":66,"id":11},{"text":"interactions","start":67,"end":79,"id":12},{"text":".","start":79,"end":80,"id":13}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"The number of parameters will increase exponentially with the order considered.","_input_hash":539571614,"_task_hash":-552580186,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"number","start":4,"end":10,"id":1},{"text":"of","start":11,"end":13,"id":2},{"text":"parameters","start":14,"end":24,"id":3},{"text":"will","start":25,"end":29,"id":4},{"text":"increase","start":30,"end":38,"id":5},{"text":"exponentially","start":39,"end":52,"id":6},{"text":"with","start":53,"end":57,"id":7},{"text":"the","start":58,"end":61,"id":8},{"text":"order","start":62,"end":67,"id":9},{"text":"considered","start":68,"end":78,"id":10},{"text":".","start":78,"end":79,"id":11}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"In Chapter 3, we propose a method for compressing a group of parameters into a single one, by exploiting the fact that many predictor variables derived from high-order interactions have the same values for all the training cases.","_input_hash":82553369,"_task_hash":-1207129772,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"Chapter","start":3,"end":10,"id":1},{"text":"3","start":11,"end":12,"id":2},{"text":",","start":12,"end":13,"id":3},{"text":"we","start":14,"end":16,"id":4},{"text":"propose","start":17,"end":24,"id":5},{"text":"a","start":25,"end":26,"id":6},{"text":"method","start":27,"end":33,"id":7},{"text":"for","start":34,"end":37,"id":8},{"text":"compressing","start":38,"end":49,"id":9},{"text":"a","start":50,"end":51,"id":10},{"text":"group","start":52,"end":57,"id":11},{"text":"of","start":58,"end":60,"id":12},{"text":"parameters","start":61,"end":71,"id":13},{"text":"into","start":72,"end":76,"id":14},{"text":"a","start":77,"end":78,"id":15},{"text":"single","start":79,"end":85,"id":16},{"text":"one","start":86,"end":89,"id":17},{"text":",","start":89,"end":90,"id":18},{"text":"by","start":91,"end":93,"id":19},{"text":"exploiting","start":94,"end":104,"id":20},{"text":"the","start":105,"end":108,"id":21},{"text":"fact","start":109,"end":113,"id":22},{"text":"that","start":114,"end":118,"id":23},{"text":"many","start":119,"end":123,"id":24},{"text":"predictor","start":124,"end":133,"id":25},{"text":"variables","start":134,"end":143,"id":26},{"text":"derived","start":144,"end":151,"id":27},{"text":"from","start":152,"end":156,"id":28},{"text":"high","start":157,"end":161,"id":29},{"text":"-","start":161,"end":162,"id":30},{"text":"order","start":162,"end":167,"id":31},{"text":"interactions","start":168,"end":180,"id":32},{"text":"have","start":181,"end":185,"id":33},{"text":"the","start":186,"end":189,"id":34},{"text":"same","start":190,"end":194,"id":35},{"text":"values","start":195,"end":201,"id":36},{"text":"for","start":202,"end":205,"id":37},{"text":"all","start":206,"end":209,"id":38},{"text":"the","start":210,"end":213,"id":39},{"text":"training","start":214,"end":222,"id":40},{"text":"cases","start":223,"end":228,"id":41},{"text":".","start":228,"end":229,"id":42}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"The number of compressed parameters may have converged before considering the highest possible order.","_input_hash":291336523,"_task_hash":-1464749194,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"number","start":4,"end":10,"id":1},{"text":"of","start":11,"end":13,"id":2},{"text":"compressed","start":14,"end":24,"id":3},{"text":"parameters","start":25,"end":35,"id":4},{"text":"may","start":36,"end":39,"id":5},{"text":"have","start":40,"end":44,"id":6},{"text":"converged","start":45,"end":54,"id":7},{"text":"before","start":55,"end":61,"id":8},{"text":"considering","start":62,"end":73,"id":9},{"text":"the","start":74,"end":77,"id":10},{"text":"highest","start":78,"end":85,"id":11},{"text":"possible","start":86,"end":94,"id":12},{"text":"order","start":95,"end":100,"id":13},{"text":".","start":100,"end":101,"id":14}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We apply this compression method to logistic sequence prediction models and logistic classification models.","_input_hash":-1491980493,"_task_hash":1790475658,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"apply","start":3,"end":8,"id":1},{"text":"this","start":9,"end":13,"id":2},{"text":"compression","start":14,"end":25,"id":3},{"text":"method","start":26,"end":32,"id":4},{"text":"to","start":33,"end":35,"id":5},{"text":"logistic","start":36,"end":44,"id":6},{"text":"sequence","start":45,"end":53,"id":7},{"text":"prediction","start":54,"end":64,"id":8},{"text":"models","start":65,"end":71,"id":9},{"text":"and","start":72,"end":75,"id":10},{"text":"logistic","start":76,"end":84,"id":11},{"text":"classification","start":85,"end":99,"id":12},{"text":"models","start":100,"end":106,"id":13},{"text":".","start":106,"end":107,"id":14}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":36,"end":71,"token_start":6,"token_end":9,"label":"ALGO","answer":"accept"},{"start":76,"end":106,"token_start":11,"token_end":13,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"  We use both simulated data and real data to test our methods in both chapters.","_input_hash":-389650462,"_task_hash":67022977,"tokens":[{"text":"  ","start":0,"end":2,"id":0},{"text":"We","start":2,"end":4,"id":1},{"text":"use","start":5,"end":8,"id":2},{"text":"both","start":9,"end":13,"id":3},{"text":"simulated","start":14,"end":23,"id":4},{"text":"data","start":24,"end":28,"id":5},{"text":"and","start":29,"end":32,"id":6},{"text":"real","start":33,"end":37,"id":7},{"text":"data","start":38,"end":42,"id":8},{"text":"to","start":43,"end":45,"id":9},{"text":"test","start":46,"end":50,"id":10},{"text":"our","start":51,"end":54,"id":11},{"text":"methods","start":55,"end":62,"id":12},{"text":"in","start":63,"end":65,"id":13},{"text":"both","start":66,"end":70,"id":14},{"text":"chapters","start":71,"end":79,"id":15},{"text":".","start":79,"end":80,"id":16}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"he","meta":{"score":0},"_input_hash":1355608212,"_task_hash":1944635008,"_session_id":null,"_view_id":"text","answer":"reject","spans":[],"tokens":[{"text":"he","start":0,"end":2,"id":0}]}
{"text":"Kernel Induced Random Survival Forests (KIRSF) is a statistical learning algorithm which aims to improve prediction accuracy for survival data.","_input_hash":1699288305,"_task_hash":-1092952878,"tokens":[{"text":"Kernel","start":0,"end":6,"id":0},{"text":"Induced","start":7,"end":14,"id":1},{"text":"Random","start":15,"end":21,"id":2},{"text":"Survival","start":22,"end":30,"id":3},{"text":"Forests","start":31,"end":38,"id":4},{"text":"(","start":39,"end":40,"id":5},{"text":"KIRSF","start":40,"end":45,"id":6},{"text":")","start":45,"end":46,"id":7},{"text":"is","start":47,"end":49,"id":8},{"text":"a","start":50,"end":51,"id":9},{"text":"statistical","start":52,"end":63,"id":10},{"text":"learning","start":64,"end":72,"id":11},{"text":"algorithm","start":73,"end":82,"id":12},{"text":"which","start":83,"end":88,"id":13},{"text":"aims","start":89,"end":93,"id":14},{"text":"to","start":94,"end":96,"id":15},{"text":"improve","start":97,"end":104,"id":16},{"text":"prediction","start":105,"end":115,"id":17},{"text":"accuracy","start":116,"end":124,"id":18},{"text":"for","start":125,"end":128,"id":19},{"text":"survival","start":129,"end":137,"id":20},{"text":"data","start":138,"end":142,"id":21},{"text":".","start":142,"end":143,"id":22}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":0,"end":38,"token_start":0,"token_end":4,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"As in Random Survival Forests (RSF), Cumulative Hazard Function is predicted for each individual in the test set.","_input_hash":-2099253541,"_task_hash":891697865,"tokens":[{"text":"As","start":0,"end":2,"id":0},{"text":"in","start":3,"end":5,"id":1},{"text":"Random","start":6,"end":12,"id":2},{"text":"Survival","start":13,"end":21,"id":3},{"text":"Forests","start":22,"end":29,"id":4},{"text":"(","start":30,"end":31,"id":5},{"text":"RSF","start":31,"end":34,"id":6},{"text":")","start":34,"end":35,"id":7},{"text":",","start":35,"end":36,"id":8},{"text":"Cumulative","start":37,"end":47,"id":9},{"text":"Hazard","start":48,"end":54,"id":10},{"text":"Function","start":55,"end":63,"id":11},{"text":"is","start":64,"end":66,"id":12},{"text":"predicted","start":67,"end":76,"id":13},{"text":"for","start":77,"end":80,"id":14},{"text":"each","start":81,"end":85,"id":15},{"text":"individual","start":86,"end":96,"id":16},{"text":"in","start":97,"end":99,"id":17},{"text":"the","start":100,"end":103,"id":18},{"text":"test","start":104,"end":108,"id":19},{"text":"set","start":109,"end":112,"id":20},{"text":".","start":112,"end":113,"id":21}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":6,"end":29,"token_start":2,"token_end":4,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"Prediction error is estimated using Harrell's concordance index (C index) [Harrell et al. (","_input_hash":853719302,"_task_hash":-1634706227,"tokens":[{"text":"Prediction","start":0,"end":10,"id":0},{"text":"error","start":11,"end":16,"id":1},{"text":"is","start":17,"end":19,"id":2},{"text":"estimated","start":20,"end":29,"id":3},{"text":"using","start":30,"end":35,"id":4},{"text":"Harrell","start":36,"end":43,"id":5},{"text":"'s","start":43,"end":45,"id":6},{"text":"concordance","start":46,"end":57,"id":7},{"text":"index","start":58,"end":63,"id":8},{"text":"(","start":64,"end":65,"id":9},{"text":"C","start":65,"end":66,"id":10},{"text":"index","start":67,"end":72,"id":11},{"text":")","start":72,"end":73,"id":12},{"text":"[","start":74,"end":75,"id":13},{"text":"Harrell","start":75,"end":82,"id":14},{"text":"et","start":83,"end":85,"id":15},{"text":"al","start":86,"end":88,"id":16},{"text":".","start":88,"end":89,"id":17},{"text":"(","start":90,"end":91,"id":18}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"1982)].","_input_hash":-976923240,"_task_hash":1555611612,"tokens":[{"text":"1982","start":0,"end":4,"id":0},{"text":")","start":4,"end":5,"id":1},{"text":"]","start":5,"end":6,"id":2},{"text":".","start":6,"end":7,"id":3}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"The C-index can be interpreted as a misclassification probability and does not depend on a single fixed time for evaluation.","_input_hash":-1594195599,"_task_hash":582997713,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"C","start":4,"end":5,"id":1},{"text":"-","start":5,"end":6,"id":2},{"text":"index","start":6,"end":11,"id":3},{"text":"can","start":12,"end":15,"id":4},{"text":"be","start":16,"end":18,"id":5},{"text":"interpreted","start":19,"end":30,"id":6},{"text":"as","start":31,"end":33,"id":7},{"text":"a","start":34,"end":35,"id":8},{"text":"misclassification","start":36,"end":53,"id":9},{"text":"probability","start":54,"end":65,"id":10},{"text":"and","start":66,"end":69,"id":11},{"text":"does","start":70,"end":74,"id":12},{"text":"not","start":75,"end":78,"id":13},{"text":"depend","start":79,"end":85,"id":14},{"text":"on","start":86,"end":88,"id":15},{"text":"a","start":89,"end":90,"id":16},{"text":"single","start":91,"end":97,"id":17},{"text":"fixed","start":98,"end":103,"id":18},{"text":"time","start":104,"end":108,"id":19},{"text":"for","start":109,"end":112,"id":20},{"text":"evaluation","start":113,"end":123,"id":21},{"text":".","start":123,"end":124,"id":22}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"The C-index also specifically accounts for censoring.","_input_hash":-471066451,"_task_hash":-95155375,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"C","start":4,"end":5,"id":1},{"text":"-","start":5,"end":6,"id":2},{"text":"index","start":6,"end":11,"id":3},{"text":"also","start":12,"end":16,"id":4},{"text":"specifically","start":17,"end":29,"id":5},{"text":"accounts","start":30,"end":38,"id":6},{"text":"for","start":39,"end":42,"id":7},{"text":"censoring","start":43,"end":52,"id":8},{"text":".","start":52,"end":53,"id":9}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"By utilizing kernel functions, KIRSF achieves better results than RSF in many situations.","_input_hash":-748775233,"_task_hash":-825716663,"tokens":[{"text":"By","start":0,"end":2,"id":0},{"text":"utilizing","start":3,"end":12,"id":1},{"text":"kernel","start":13,"end":19,"id":2},{"text":"functions","start":20,"end":29,"id":3},{"text":",","start":29,"end":30,"id":4},{"text":"KIRSF","start":31,"end":36,"id":5},{"text":"achieves","start":37,"end":45,"id":6},{"text":"better","start":46,"end":52,"id":7},{"text":"results","start":53,"end":60,"id":8},{"text":"than","start":61,"end":65,"id":9},{"text":"RSF","start":66,"end":69,"id":10},{"text":"in","start":70,"end":72,"id":11},{"text":"many","start":73,"end":77,"id":12},{"text":"situations","start":78,"end":88,"id":13},{"text":".","start":88,"end":89,"id":14}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"In this report, we show how to incorporate kernel functions into RSF.","_input_hash":-282059572,"_task_hash":2119442806,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"this","start":3,"end":7,"id":1},{"text":"report","start":8,"end":14,"id":2},{"text":",","start":14,"end":15,"id":3},{"text":"we","start":16,"end":18,"id":4},{"text":"show","start":19,"end":23,"id":5},{"text":"how","start":24,"end":27,"id":6},{"text":"to","start":28,"end":30,"id":7},{"text":"incorporate","start":31,"end":42,"id":8},{"text":"kernel","start":43,"end":49,"id":9},{"text":"functions","start":50,"end":59,"id":10},{"text":"into","start":60,"end":64,"id":11},{"text":"RSF","start":65,"end":68,"id":12},{"text":".","start":68,"end":69,"id":13}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We test the performance of KIRSF and compare our method to RSF.","_input_hash":-1089035827,"_task_hash":1589398985,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"test","start":3,"end":7,"id":1},{"text":"the","start":8,"end":11,"id":2},{"text":"performance","start":12,"end":23,"id":3},{"text":"of","start":24,"end":26,"id":4},{"text":"KIRSF","start":27,"end":32,"id":5},{"text":"and","start":33,"end":36,"id":6},{"text":"compare","start":37,"end":44,"id":7},{"text":"our","start":45,"end":48,"id":8},{"text":"method","start":49,"end":55,"id":9},{"text":"to","start":56,"end":58,"id":10},{"text":"RSF","start":59,"end":62,"id":11},{"text":".","start":62,"end":63,"id":12}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We find that the KIRSF's performance is better than RSF in many occasions.","_input_hash":-1291543225,"_task_hash":691437902,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"find","start":3,"end":7,"id":1},{"text":"that","start":8,"end":12,"id":2},{"text":"the","start":13,"end":16,"id":3},{"text":"KIRSF","start":17,"end":22,"id":4},{"text":"'s","start":22,"end":24,"id":5},{"text":"performance","start":25,"end":36,"id":6},{"text":"is","start":37,"end":39,"id":7},{"text":"better","start":40,"end":46,"id":8},{"text":"than","start":47,"end":51,"id":9},{"text":"RSF","start":52,"end":55,"id":10},{"text":"in","start":56,"end":58,"id":11},{"text":"many","start":59,"end":63,"id":12},{"text":"occasions","start":64,"end":73,"id":13},{"text":".","start":73,"end":74,"id":14}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Bayesian_inference|NOUN","word":"Bayesian inference","sense":"NOUN","meta":{"score":0.7667000294,"sense":"NOUN"},"_input_hash":1314646066,"_task_hash":631041291,"_session_id":null,"_view_id":"html","answer":"reject","spans":[],"tokens":[{"text":"Bayesian_inference|NOUN","start":0,"end":23,"id":0}]}
{"text":"Simulated annealing is a popular method for approaching the solution of a global optimization problem.","_input_hash":1054415795,"_task_hash":-184384468,"tokens":[{"text":"Simulated","start":0,"end":9,"id":0},{"text":"annealing","start":10,"end":19,"id":1},{"text":"is","start":20,"end":22,"id":2},{"text":"a","start":23,"end":24,"id":3},{"text":"popular","start":25,"end":32,"id":4},{"text":"method","start":33,"end":39,"id":5},{"text":"for","start":40,"end":43,"id":6},{"text":"approaching","start":44,"end":55,"id":7},{"text":"the","start":56,"end":59,"id":8},{"text":"solution","start":60,"end":68,"id":9},{"text":"of","start":69,"end":71,"id":10},{"text":"a","start":72,"end":73,"id":11},{"text":"global","start":74,"end":80,"id":12},{"text":"optimization","start":81,"end":93,"id":13},{"text":"problem","start":94,"end":101,"id":14},{"text":".","start":101,"end":102,"id":15}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":0,"end":19,"token_start":0,"token_end":1,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"Existing results on its performance apply to discrete combinatorial optimization where the optimization variables can assume only a finite set of possible values.","_input_hash":-1427032138,"_task_hash":36898530,"tokens":[{"text":"Existing","start":0,"end":8,"id":0},{"text":"results","start":9,"end":16,"id":1},{"text":"on","start":17,"end":19,"id":2},{"text":"its","start":20,"end":23,"id":3},{"text":"performance","start":24,"end":35,"id":4},{"text":"apply","start":36,"end":41,"id":5},{"text":"to","start":42,"end":44,"id":6},{"text":"discrete","start":45,"end":53,"id":7},{"text":"combinatorial","start":54,"end":67,"id":8},{"text":"optimization","start":68,"end":80,"id":9},{"text":"where","start":81,"end":86,"id":10},{"text":"the","start":87,"end":90,"id":11},{"text":"optimization","start":91,"end":103,"id":12},{"text":"variables","start":104,"end":113,"id":13},{"text":"can","start":114,"end":117,"id":14},{"text":"assume","start":118,"end":124,"id":15},{"text":"only","start":125,"end":129,"id":16},{"text":"a","start":130,"end":131,"id":17},{"text":"finite","start":132,"end":138,"id":18},{"text":"set","start":139,"end":142,"id":19},{"text":"of","start":143,"end":145,"id":20},{"text":"possible","start":146,"end":154,"id":21},{"text":"values","start":155,"end":161,"id":22},{"text":".","start":161,"end":162,"id":23}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We introduce a new general formulation of simulated annealing which allows one to guarantee finite-time performance in the optimization of functions of continuous variables.","_input_hash":2099441561,"_task_hash":-88008736,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"introduce","start":3,"end":12,"id":1},{"text":"a","start":13,"end":14,"id":2},{"text":"new","start":15,"end":18,"id":3},{"text":"general","start":19,"end":26,"id":4},{"text":"formulation","start":27,"end":38,"id":5},{"text":"of","start":39,"end":41,"id":6},{"text":"simulated","start":42,"end":51,"id":7},{"text":"annealing","start":52,"end":61,"id":8},{"text":"which","start":62,"end":67,"id":9},{"text":"allows","start":68,"end":74,"id":10},{"text":"one","start":75,"end":78,"id":11},{"text":"to","start":79,"end":81,"id":12},{"text":"guarantee","start":82,"end":91,"id":13},{"text":"finite","start":92,"end":98,"id":14},{"text":"-","start":98,"end":99,"id":15},{"text":"time","start":99,"end":103,"id":16},{"text":"performance","start":104,"end":115,"id":17},{"text":"in","start":116,"end":118,"id":18},{"text":"the","start":119,"end":122,"id":19},{"text":"optimization","start":123,"end":135,"id":20},{"text":"of","start":136,"end":138,"id":21},{"text":"functions","start":139,"end":148,"id":22},{"text":"of","start":149,"end":151,"id":23},{"text":"continuous","start":152,"end":162,"id":24},{"text":"variables","start":163,"end":172,"id":25},{"text":".","start":172,"end":173,"id":26}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":42,"end":61,"token_start":7,"token_end":8,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"The results hold universally for any optimization problem on a bounded domain and establish a connection between simulated annealing and up-to-date theory of convergence of Markov chain Monte Carlo methods on continuous domains.","_input_hash":-1859510931,"_task_hash":331383655,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"results","start":4,"end":11,"id":1},{"text":"hold","start":12,"end":16,"id":2},{"text":"universally","start":17,"end":28,"id":3},{"text":"for","start":29,"end":32,"id":4},{"text":"any","start":33,"end":36,"id":5},{"text":"optimization","start":37,"end":49,"id":6},{"text":"problem","start":50,"end":57,"id":7},{"text":"on","start":58,"end":60,"id":8},{"text":"a","start":61,"end":62,"id":9},{"text":"bounded","start":63,"end":70,"id":10},{"text":"domain","start":71,"end":77,"id":11},{"text":"and","start":78,"end":81,"id":12},{"text":"establish","start":82,"end":91,"id":13},{"text":"a","start":92,"end":93,"id":14},{"text":"connection","start":94,"end":104,"id":15},{"text":"between","start":105,"end":112,"id":16},{"text":"simulated","start":113,"end":122,"id":17},{"text":"annealing","start":123,"end":132,"id":18},{"text":"and","start":133,"end":136,"id":19},{"text":"up","start":137,"end":139,"id":20},{"text":"-","start":139,"end":140,"id":21},{"text":"to","start":140,"end":142,"id":22},{"text":"-","start":142,"end":143,"id":23},{"text":"date","start":143,"end":147,"id":24},{"text":"theory","start":148,"end":154,"id":25},{"text":"of","start":155,"end":157,"id":26},{"text":"convergence","start":158,"end":169,"id":27},{"text":"of","start":170,"end":172,"id":28},{"text":"Markov","start":173,"end":179,"id":29},{"text":"chain","start":180,"end":185,"id":30},{"text":"Monte","start":186,"end":191,"id":31},{"text":"Carlo","start":192,"end":197,"id":32},{"text":"methods","start":198,"end":205,"id":33},{"text":"on","start":206,"end":208,"id":34},{"text":"continuous","start":209,"end":219,"id":35},{"text":"domains","start":220,"end":227,"id":36},{"text":".","start":227,"end":228,"id":37}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":113,"end":132,"token_start":17,"token_end":18,"label":"ALGO","answer":"accept"},{"start":173,"end":197,"token_start":29,"token_end":32,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"This work is inspired by the concept of finite-time learning with known accuracy and confidence developed in statistical learning theory.","_input_hash":-619534829,"_task_hash":1297335163,"tokens":[{"text":"This","start":0,"end":4,"id":0},{"text":"work","start":5,"end":9,"id":1},{"text":"is","start":10,"end":12,"id":2},{"text":"inspired","start":13,"end":21,"id":3},{"text":"by","start":22,"end":24,"id":4},{"text":"the","start":25,"end":28,"id":5},{"text":"concept","start":29,"end":36,"id":6},{"text":"of","start":37,"end":39,"id":7},{"text":"finite","start":40,"end":46,"id":8},{"text":"-","start":46,"end":47,"id":9},{"text":"time","start":47,"end":51,"id":10},{"text":"learning","start":52,"end":60,"id":11},{"text":"with","start":61,"end":65,"id":12},{"text":"known","start":66,"end":71,"id":13},{"text":"accuracy","start":72,"end":80,"id":14},{"text":"and","start":81,"end":84,"id":15},{"text":"confidence","start":85,"end":95,"id":16},{"text":"developed","start":96,"end":105,"id":17},{"text":"in","start":106,"end":108,"id":18},{"text":"statistical","start":109,"end":120,"id":19},{"text":"learning","start":121,"end":129,"id":20},{"text":"theory","start":130,"end":136,"id":21},{"text":".","start":136,"end":137,"id":22}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"mathematical_framework|NOUN","word":"mathematical framework","sense":"NOUN","meta":{"score":0.7634999752,"sense":"NOUN"},"_input_hash":-409064999,"_task_hash":-1262828682,"_session_id":null,"_view_id":"html","answer":"reject","spans":[],"tokens":[{"text":"mathematical_framework|NOUN","start":0,"end":27,"id":0}]}
{"text":"narrow_AI|NOUN","word":"narrow AI","sense":"NOUN","meta":{"score":0.763800025,"sense":"NOUN"},"_input_hash":-1139544865,"_task_hash":2054708507,"_session_id":null,"_view_id":"html","answer":"reject","spans":[],"tokens":[{"text":"narrow_AI|NOUN","start":0,"end":14,"id":0}]}
{"text":"deterministically|ADV","word":"deterministically","sense":"ADV","meta":{"score":0.7536000013,"sense":"ADV"},"_input_hash":-1061259057,"_task_hash":-704574847,"_session_id":null,"_view_id":"html","answer":"reject","spans":[],"tokens":[{"text":"deterministically|ADV","start":0,"end":21,"id":0}]}
{"text":"distributed_computing|NOUN","word":"distributed computing","sense":"NOUN","meta":{"score":0.7699000239,"sense":"NOUN"},"_input_hash":-14894255,"_task_hash":1414768323,"_session_id":null,"_view_id":"html","answer":"reject","spans":[],"tokens":[{"text":"distributed_computing|NOUN","start":0,"end":26,"id":0}]}
{"text":"AI_systems|NOUN","word":"AI systems","sense":"NOUN","meta":{"score":0.7979000211,"sense":"NOUN"},"_input_hash":1103152113,"_task_hash":287959374,"_session_id":null,"_view_id":"html","answer":"reject","spans":[],"tokens":[{"text":"AI_systems|NOUN","start":0,"end":15,"id":0}]}
{"text":"am","meta":{"score":0},"_input_hash":167373396,"_task_hash":2007909889,"_session_id":null,"_view_id":"text","answer":"reject","spans":[],"tokens":[{"text":"am","start":0,"end":2,"id":0}]}
{"text":"wo","meta":{"score":0},"_input_hash":-2050708257,"_task_hash":425539932,"_session_id":null,"_view_id":"text","answer":"reject","spans":[],"tokens":[{"text":"wo","start":0,"end":2,"id":0}]}
{"text":"data_analysis|NOUN","word":"data analysis","sense":"NOUN","meta":{"score":0.787800014,"sense":"NOUN"},"_input_hash":527622331,"_task_hash":-753842867,"_session_id":null,"_view_id":"html","answer":"reject","spans":[],"tokens":[{"text":"data_analysis|NOUN","start":0,"end":18,"id":0}]}
{"text":"We consider principal component analysis (PCA) in decomposable Gaussian graphical models.","_input_hash":874169289,"_task_hash":668324253,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"consider","start":3,"end":11,"id":1},{"text":"principal","start":12,"end":21,"id":2},{"text":"component","start":22,"end":31,"id":3},{"text":"analysis","start":32,"end":40,"id":4},{"text":"(","start":41,"end":42,"id":5},{"text":"PCA","start":42,"end":45,"id":6},{"text":")","start":45,"end":46,"id":7},{"text":"in","start":47,"end":49,"id":8},{"text":"decomposable","start":50,"end":62,"id":9},{"text":"Gaussian","start":63,"end":71,"id":10},{"text":"graphical","start":72,"end":81,"id":11},{"text":"models","start":82,"end":88,"id":12},{"text":".","start":88,"end":89,"id":13}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":12,"end":40,"token_start":2,"token_end":4,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"We exploit the prior information in these models in order to distribute its computation.","_input_hash":1119992861,"_task_hash":333611047,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"exploit","start":3,"end":10,"id":1},{"text":"the","start":11,"end":14,"id":2},{"text":"prior","start":15,"end":20,"id":3},{"text":"information","start":21,"end":32,"id":4},{"text":"in","start":33,"end":35,"id":5},{"text":"these","start":36,"end":41,"id":6},{"text":"models","start":42,"end":48,"id":7},{"text":"in","start":49,"end":51,"id":8},{"text":"order","start":52,"end":57,"id":9},{"text":"to","start":58,"end":60,"id":10},{"text":"distribute","start":61,"end":71,"id":11},{"text":"its","start":72,"end":75,"id":12},{"text":"computation","start":76,"end":87,"id":13},{"text":".","start":87,"end":88,"id":14}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"For this purpose, we reformulate the problem in the sparse inverse covariance (concentration) domain and solve the global eigenvalue problem using a sequence of local eigenvalue problems in each of the cliques of the decomposable graph.","_input_hash":-886167127,"_task_hash":-2112496241,"tokens":[{"text":"For","start":0,"end":3,"id":0},{"text":"this","start":4,"end":8,"id":1},{"text":"purpose","start":9,"end":16,"id":2},{"text":",","start":16,"end":17,"id":3},{"text":"we","start":18,"end":20,"id":4},{"text":"reformulate","start":21,"end":32,"id":5},{"text":"the","start":33,"end":36,"id":6},{"text":"problem","start":37,"end":44,"id":7},{"text":"in","start":45,"end":47,"id":8},{"text":"the","start":48,"end":51,"id":9},{"text":"sparse","start":52,"end":58,"id":10},{"text":"inverse","start":59,"end":66,"id":11},{"text":"covariance","start":67,"end":77,"id":12},{"text":"(","start":78,"end":79,"id":13},{"text":"concentration","start":79,"end":92,"id":14},{"text":")","start":92,"end":93,"id":15},{"text":"domain","start":94,"end":100,"id":16},{"text":"and","start":101,"end":104,"id":17},{"text":"solve","start":105,"end":110,"id":18},{"text":"the","start":111,"end":114,"id":19},{"text":"global","start":115,"end":121,"id":20},{"text":"eigenvalue","start":122,"end":132,"id":21},{"text":"problem","start":133,"end":140,"id":22},{"text":"using","start":141,"end":146,"id":23},{"text":"a","start":147,"end":148,"id":24},{"text":"sequence","start":149,"end":157,"id":25},{"text":"of","start":158,"end":160,"id":26},{"text":"local","start":161,"end":166,"id":27},{"text":"eigenvalue","start":167,"end":177,"id":28},{"text":"problems","start":178,"end":186,"id":29},{"text":"in","start":187,"end":189,"id":30},{"text":"each","start":190,"end":194,"id":31},{"text":"of","start":195,"end":197,"id":32},{"text":"the","start":198,"end":201,"id":33},{"text":"cliques","start":202,"end":209,"id":34},{"text":"of","start":210,"end":212,"id":35},{"text":"the","start":213,"end":216,"id":36},{"text":"decomposable","start":217,"end":229,"id":37},{"text":"graph","start":230,"end":235,"id":38},{"text":".","start":235,"end":236,"id":39}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We demonstrate the application of our methodology in the context of decentralized anomaly detection in the Abilene backbone network.","_input_hash":178100919,"_task_hash":-249685443,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"demonstrate","start":3,"end":14,"id":1},{"text":"the","start":15,"end":18,"id":2},{"text":"application","start":19,"end":30,"id":3},{"text":"of","start":31,"end":33,"id":4},{"text":"our","start":34,"end":37,"id":5},{"text":"methodology","start":38,"end":49,"id":6},{"text":"in","start":50,"end":52,"id":7},{"text":"the","start":53,"end":56,"id":8},{"text":"context","start":57,"end":64,"id":9},{"text":"of","start":65,"end":67,"id":10},{"text":"decentralized","start":68,"end":81,"id":11},{"text":"anomaly","start":82,"end":89,"id":12},{"text":"detection","start":90,"end":99,"id":13},{"text":"in","start":100,"end":102,"id":14},{"text":"the","start":103,"end":106,"id":15},{"text":"Abilene","start":107,"end":114,"id":16},{"text":"backbone","start":115,"end":123,"id":17},{"text":"network","start":124,"end":131,"id":18},{"text":".","start":131,"end":132,"id":19}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Based on the topology of the network, we propose an approximate statistical graphical model and distribute the computation of PCA.","_input_hash":1813334575,"_task_hash":1741471501,"tokens":[{"text":"Based","start":0,"end":5,"id":0},{"text":"on","start":6,"end":8,"id":1},{"text":"the","start":9,"end":12,"id":2},{"text":"topology","start":13,"end":21,"id":3},{"text":"of","start":22,"end":24,"id":4},{"text":"the","start":25,"end":28,"id":5},{"text":"network","start":29,"end":36,"id":6},{"text":",","start":36,"end":37,"id":7},{"text":"we","start":38,"end":40,"id":8},{"text":"propose","start":41,"end":48,"id":9},{"text":"an","start":49,"end":51,"id":10},{"text":"approximate","start":52,"end":63,"id":11},{"text":"statistical","start":64,"end":75,"id":12},{"text":"graphical","start":76,"end":85,"id":13},{"text":"model","start":86,"end":91,"id":14},{"text":"and","start":92,"end":95,"id":15},{"text":"distribute","start":96,"end":106,"id":16},{"text":"the","start":107,"end":110,"id":17},{"text":"computation","start":111,"end":122,"id":18},{"text":"of","start":123,"end":125,"id":19},{"text":"PCA","start":126,"end":129,"id":20},{"text":".","start":129,"end":130,"id":21}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"SVMs|NOUN","word":"SVMs","sense":"NOUN","meta":{"score":0.7695000172,"sense":"NOUN"},"_input_hash":249005043,"_task_hash":-703925626,"_session_id":null,"_view_id":"html","answer":"accept","spans":[],"tokens":[{"text":"SVMs|NOUN","start":0,"end":9,"id":0}]}
{"text":"deep_learning|NOUN","word":"deep learning","sense":"NOUN","meta":{"score":0.8554999828,"sense":"NOUN"},"_input_hash":-1592488466,"_task_hash":-2101114905,"_session_id":null,"_view_id":"html","answer":"accept","spans":[],"tokens":[{"text":"deep_learning|NOUN","start":0,"end":18,"id":0}]}
{"text":"Despite the recent progress towards efficient multiple kernel learning (MKL), the structured output case remains an open research front.","_input_hash":-340461261,"_task_hash":-783625002,"tokens":[{"text":"Despite","start":0,"end":7,"id":0},{"text":"the","start":8,"end":11,"id":1},{"text":"recent","start":12,"end":18,"id":2},{"text":"progress","start":19,"end":27,"id":3},{"text":"towards","start":28,"end":35,"id":4},{"text":"efficient","start":36,"end":45,"id":5},{"text":"multiple","start":46,"end":54,"id":6},{"text":"kernel","start":55,"end":61,"id":7},{"text":"learning","start":62,"end":70,"id":8},{"text":"(","start":71,"end":72,"id":9},{"text":"MKL","start":72,"end":75,"id":10},{"text":")","start":75,"end":76,"id":11},{"text":",","start":76,"end":77,"id":12},{"text":"the","start":78,"end":81,"id":13},{"text":"structured","start":82,"end":92,"id":14},{"text":"output","start":93,"end":99,"id":15},{"text":"case","start":100,"end":104,"id":16},{"text":"remains","start":105,"end":112,"id":17},{"text":"an","start":113,"end":115,"id":18},{"text":"open","start":116,"end":120,"id":19},{"text":"research","start":121,"end":129,"id":20},{"text":"front","start":130,"end":135,"id":21},{"text":".","start":135,"end":136,"id":22}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"Current approaches involve repeatedly solving a batch learning problem, which makes them inadequate for large scale scenarios.","_input_hash":-711734251,"_task_hash":93516184,"tokens":[{"text":"Current","start":0,"end":7,"id":0},{"text":"approaches","start":8,"end":18,"id":1},{"text":"involve","start":19,"end":26,"id":2},{"text":"repeatedly","start":27,"end":37,"id":3},{"text":"solving","start":38,"end":45,"id":4},{"text":"a","start":46,"end":47,"id":5},{"text":"batch","start":48,"end":53,"id":6},{"text":"learning","start":54,"end":62,"id":7},{"text":"problem","start":63,"end":70,"id":8},{"text":",","start":70,"end":71,"id":9},{"text":"which","start":72,"end":77,"id":10},{"text":"makes","start":78,"end":83,"id":11},{"text":"them","start":84,"end":88,"id":12},{"text":"inadequate","start":89,"end":99,"id":13},{"text":"for","start":100,"end":103,"id":14},{"text":"large","start":104,"end":109,"id":15},{"text":"scale","start":110,"end":115,"id":16},{"text":"scenarios","start":116,"end":125,"id":17},{"text":".","start":125,"end":126,"id":18}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"We propose a new family of online proximal algorithms for MKL (as well as for group-lasso and variants thereof), which overcomes that drawback.","_input_hash":1216000582,"_task_hash":-978167061,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"propose","start":3,"end":10,"id":1},{"text":"a","start":11,"end":12,"id":2},{"text":"new","start":13,"end":16,"id":3},{"text":"family","start":17,"end":23,"id":4},{"text":"of","start":24,"end":26,"id":5},{"text":"online","start":27,"end":33,"id":6},{"text":"proximal","start":34,"end":42,"id":7},{"text":"algorithms","start":43,"end":53,"id":8},{"text":"for","start":54,"end":57,"id":9},{"text":"MKL","start":58,"end":61,"id":10},{"text":"(","start":62,"end":63,"id":11},{"text":"as","start":63,"end":65,"id":12},{"text":"well","start":66,"end":70,"id":13},{"text":"as","start":71,"end":73,"id":14},{"text":"for","start":74,"end":77,"id":15},{"text":"group","start":78,"end":83,"id":16},{"text":"-","start":83,"end":84,"id":17},{"text":"lasso","start":84,"end":89,"id":18},{"text":"and","start":90,"end":93,"id":19},{"text":"variants","start":94,"end":102,"id":20},{"text":"thereof","start":103,"end":110,"id":21},{"text":")","start":110,"end":111,"id":22},{"text":",","start":111,"end":112,"id":23},{"text":"which","start":113,"end":118,"id":24},{"text":"overcomes","start":119,"end":128,"id":25},{"text":"that","start":129,"end":133,"id":26},{"text":"drawback","start":134,"end":142,"id":27},{"text":".","start":142,"end":143,"id":28}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"We show regret, convergence, and generalization bounds for the proposed method.","_input_hash":-1416708471,"_task_hash":1301231662,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"show","start":3,"end":7,"id":1},{"text":"regret","start":8,"end":14,"id":2},{"text":",","start":14,"end":15,"id":3},{"text":"convergence","start":16,"end":27,"id":4},{"text":",","start":27,"end":28,"id":5},{"text":"and","start":29,"end":32,"id":6},{"text":"generalization","start":33,"end":47,"id":7},{"text":"bounds","start":48,"end":54,"id":8},{"text":"for","start":55,"end":58,"id":9},{"text":"the","start":59,"end":62,"id":10},{"text":"proposed","start":63,"end":71,"id":11},{"text":"method","start":72,"end":78,"id":12},{"text":".","start":78,"end":79,"id":13}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"Experiments on handwriting recognition and dependency parsing testify for the successfulness of the approach.","_input_hash":957913555,"_task_hash":-274463593,"tokens":[{"text":"Experiments","start":0,"end":11,"id":0},{"text":"on","start":12,"end":14,"id":1},{"text":"handwriting","start":15,"end":26,"id":2},{"text":"recognition","start":27,"end":38,"id":3},{"text":"and","start":39,"end":42,"id":4},{"text":"dependency","start":43,"end":53,"id":5},{"text":"parsing","start":54,"end":61,"id":6},{"text":"testify","start":62,"end":69,"id":7},{"text":"for","start":70,"end":73,"id":8},{"text":"the","start":74,"end":77,"id":9},{"text":"successfulness","start":78,"end":92,"id":10},{"text":"of","start":93,"end":95,"id":11},{"text":"the","start":96,"end":99,"id":12},{"text":"approach","start":100,"end":108,"id":13},{"text":".","start":108,"end":109,"id":14}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"A popular method for selecting the number of clusters is based on stability arguments:","_input_hash":-753137441,"_task_hash":-437085051,"tokens":[{"text":"A","start":0,"end":1,"id":0},{"text":"popular","start":2,"end":9,"id":1},{"text":"method","start":10,"end":16,"id":2},{"text":"for","start":17,"end":20,"id":3},{"text":"selecting","start":21,"end":30,"id":4},{"text":"the","start":31,"end":34,"id":5},{"text":"number","start":35,"end":41,"id":6},{"text":"of","start":42,"end":44,"id":7},{"text":"clusters","start":45,"end":53,"id":8},{"text":"is","start":54,"end":56,"id":9},{"text":"based","start":57,"end":62,"id":10},{"text":"on","start":63,"end":65,"id":11},{"text":"stability","start":66,"end":75,"id":12},{"text":"arguments","start":76,"end":85,"id":13},{"text":":","start":85,"end":86,"id":14}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"one chooses the number of clusters such that the corresponding clustering results are \"most stable\".","_input_hash":1276947594,"_task_hash":-1829811564,"tokens":[{"text":"one","start":0,"end":3,"id":0},{"text":"chooses","start":4,"end":11,"id":1},{"text":"the","start":12,"end":15,"id":2},{"text":"number","start":16,"end":22,"id":3},{"text":"of","start":23,"end":25,"id":4},{"text":"clusters","start":26,"end":34,"id":5},{"text":"such","start":35,"end":39,"id":6},{"text":"that","start":40,"end":44,"id":7},{"text":"the","start":45,"end":48,"id":8},{"text":"corresponding","start":49,"end":62,"id":9},{"text":"clustering","start":63,"end":73,"id":10},{"text":"results","start":74,"end":81,"id":11},{"text":"are","start":82,"end":85,"id":12},{"text":"\"","start":86,"end":87,"id":13},{"text":"most","start":87,"end":91,"id":14},{"text":"stable","start":92,"end":98,"id":15},{"text":"\"","start":98,"end":99,"id":16},{"text":".","start":99,"end":100,"id":17}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"In recent years, a series of papers has analyzed the behavior of this method from a theoretical point of view.","_input_hash":-1941245184,"_task_hash":-1509237239,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"recent","start":3,"end":9,"id":1},{"text":"years","start":10,"end":15,"id":2},{"text":",","start":15,"end":16,"id":3},{"text":"a","start":17,"end":18,"id":4},{"text":"series","start":19,"end":25,"id":5},{"text":"of","start":26,"end":28,"id":6},{"text":"papers","start":29,"end":35,"id":7},{"text":"has","start":36,"end":39,"id":8},{"text":"analyzed","start":40,"end":48,"id":9},{"text":"the","start":49,"end":52,"id":10},{"text":"behavior","start":53,"end":61,"id":11},{"text":"of","start":62,"end":64,"id":12},{"text":"this","start":65,"end":69,"id":13},{"text":"method","start":70,"end":76,"id":14},{"text":"from","start":77,"end":81,"id":15},{"text":"a","start":82,"end":83,"id":16},{"text":"theoretical","start":84,"end":95,"id":17},{"text":"point","start":96,"end":101,"id":18},{"text":"of","start":102,"end":104,"id":19},{"text":"view","start":105,"end":109,"id":20},{"text":".","start":109,"end":110,"id":21}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"However, the results are very technical and difficult to interpret for non-experts.","_input_hash":-1141677545,"_task_hash":-1391769287,"tokens":[{"text":"However","start":0,"end":7,"id":0},{"text":",","start":7,"end":8,"id":1},{"text":"the","start":9,"end":12,"id":2},{"text":"results","start":13,"end":20,"id":3},{"text":"are","start":21,"end":24,"id":4},{"text":"very","start":25,"end":29,"id":5},{"text":"technical","start":30,"end":39,"id":6},{"text":"and","start":40,"end":43,"id":7},{"text":"difficult","start":44,"end":53,"id":8},{"text":"to","start":54,"end":56,"id":9},{"text":"interpret","start":57,"end":66,"id":10},{"text":"for","start":67,"end":70,"id":11},{"text":"non","start":71,"end":74,"id":12},{"text":"-","start":74,"end":75,"id":13},{"text":"experts","start":75,"end":82,"id":14},{"text":".","start":82,"end":83,"id":15}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"In this paper we give a high-level overview about the existing literature on clustering stability.","_input_hash":-1013745153,"_task_hash":-1312563659,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"this","start":3,"end":7,"id":1},{"text":"paper","start":8,"end":13,"id":2},{"text":"we","start":14,"end":16,"id":3},{"text":"give","start":17,"end":21,"id":4},{"text":"a","start":22,"end":23,"id":5},{"text":"high","start":24,"end":28,"id":6},{"text":"-","start":28,"end":29,"id":7},{"text":"level","start":29,"end":34,"id":8},{"text":"overview","start":35,"end":43,"id":9},{"text":"about","start":44,"end":49,"id":10},{"text":"the","start":50,"end":53,"id":11},{"text":"existing","start":54,"end":62,"id":12},{"text":"literature","start":63,"end":73,"id":13},{"text":"on","start":74,"end":76,"id":14},{"text":"clustering","start":77,"end":87,"id":15},{"text":"stability","start":88,"end":97,"id":16},{"text":".","start":97,"end":98,"id":17}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"In addition to presenting the results in a slightly informal but accessible way, we relate them to each other and discuss their different implications.","_input_hash":149522558,"_task_hash":2025523720,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"addition","start":3,"end":11,"id":1},{"text":"to","start":12,"end":14,"id":2},{"text":"presenting","start":15,"end":25,"id":3},{"text":"the","start":26,"end":29,"id":4},{"text":"results","start":30,"end":37,"id":5},{"text":"in","start":38,"end":40,"id":6},{"text":"a","start":41,"end":42,"id":7},{"text":"slightly","start":43,"end":51,"id":8},{"text":"informal","start":52,"end":60,"id":9},{"text":"but","start":61,"end":64,"id":10},{"text":"accessible","start":65,"end":75,"id":11},{"text":"way","start":76,"end":79,"id":12},{"text":",","start":79,"end":80,"id":13},{"text":"we","start":81,"end":83,"id":14},{"text":"relate","start":84,"end":90,"id":15},{"text":"them","start":91,"end":95,"id":16},{"text":"to","start":96,"end":98,"id":17},{"text":"each","start":99,"end":103,"id":18},{"text":"other","start":104,"end":109,"id":19},{"text":"and","start":110,"end":113,"id":20},{"text":"discuss","start":114,"end":121,"id":21},{"text":"their","start":122,"end":127,"id":22},{"text":"different","start":128,"end":137,"id":23},{"text":"implications","start":138,"end":150,"id":24},{"text":".","start":150,"end":151,"id":25}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"heuristics|NOUN","word":"heuristics","sense":"NOUN","meta":{"score":0.7659000158,"sense":"NOUN"},"_input_hash":71895469,"_task_hash":118990502,"_session_id":null,"_view_id":"html","answer":"reject","spans":[],"tokens":[{"text":"heuristics|NOUN","start":0,"end":15,"id":0}]}
{"text":"We consider the empirical risk minimization problem for linear supervised learning, with regularization by structured sparsity-inducing norms.","_input_hash":-1295944508,"_task_hash":-486257343,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"consider","start":3,"end":11,"id":1},{"text":"the","start":12,"end":15,"id":2},{"text":"empirical","start":16,"end":25,"id":3},{"text":"risk","start":26,"end":30,"id":4},{"text":"minimization","start":31,"end":43,"id":5},{"text":"problem","start":44,"end":51,"id":6},{"text":"for","start":52,"end":55,"id":7},{"text":"linear","start":56,"end":62,"id":8},{"text":"supervised","start":63,"end":73,"id":9},{"text":"learning","start":74,"end":82,"id":10},{"text":",","start":82,"end":83,"id":11},{"text":"with","start":84,"end":88,"id":12},{"text":"regularization","start":89,"end":103,"id":13},{"text":"by","start":104,"end":106,"id":14},{"text":"structured","start":107,"end":117,"id":15},{"text":"sparsity","start":118,"end":126,"id":16},{"text":"-","start":126,"end":127,"id":17},{"text":"inducing","start":127,"end":135,"id":18},{"text":"norms","start":136,"end":141,"id":19},{"text":".","start":141,"end":142,"id":20}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"These are defined as sums of Euclidean norms on certain subsets of variables, extending the usual $\\ell_1$-norm and the group $\\ell_1$-norm by allowing the subsets to overlap.","_input_hash":-1642135944,"_task_hash":1807253447,"tokens":[{"text":"These","start":0,"end":5,"id":0},{"text":"are","start":6,"end":9,"id":1},{"text":"defined","start":10,"end":17,"id":2},{"text":"as","start":18,"end":20,"id":3},{"text":"sums","start":21,"end":25,"id":4},{"text":"of","start":26,"end":28,"id":5},{"text":"Euclidean","start":29,"end":38,"id":6},{"text":"norms","start":39,"end":44,"id":7},{"text":"on","start":45,"end":47,"id":8},{"text":"certain","start":48,"end":55,"id":9},{"text":"subsets","start":56,"end":63,"id":10},{"text":"of","start":64,"end":66,"id":11},{"text":"variables","start":67,"end":76,"id":12},{"text":",","start":76,"end":77,"id":13},{"text":"extending","start":78,"end":87,"id":14},{"text":"the","start":88,"end":91,"id":15},{"text":"usual","start":92,"end":97,"id":16},{"text":"$","start":98,"end":99,"id":17},{"text":"\\ell_1$-norm","start":99,"end":111,"id":18},{"text":"and","start":112,"end":115,"id":19},{"text":"the","start":116,"end":119,"id":20},{"text":"group","start":120,"end":125,"id":21},{"text":"$","start":126,"end":127,"id":22},{"text":"\\ell_1$-norm","start":127,"end":139,"id":23},{"text":"by","start":140,"end":142,"id":24},{"text":"allowing","start":143,"end":151,"id":25},{"text":"the","start":152,"end":155,"id":26},{"text":"subsets","start":156,"end":163,"id":27},{"text":"to","start":164,"end":166,"id":28},{"text":"overlap","start":167,"end":174,"id":29},{"text":".","start":174,"end":175,"id":30}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"This leads to a specific set of allowed nonzero patterns for the solutions of such problems.","_input_hash":-468147957,"_task_hash":-1296230655,"tokens":[{"text":"This","start":0,"end":4,"id":0},{"text":"leads","start":5,"end":10,"id":1},{"text":"to","start":11,"end":13,"id":2},{"text":"a","start":14,"end":15,"id":3},{"text":"specific","start":16,"end":24,"id":4},{"text":"set","start":25,"end":28,"id":5},{"text":"of","start":29,"end":31,"id":6},{"text":"allowed","start":32,"end":39,"id":7},{"text":"nonzero","start":40,"end":47,"id":8},{"text":"patterns","start":48,"end":56,"id":9},{"text":"for","start":57,"end":60,"id":10},{"text":"the","start":61,"end":64,"id":11},{"text":"solutions","start":65,"end":74,"id":12},{"text":"of","start":75,"end":77,"id":13},{"text":"such","start":78,"end":82,"id":14},{"text":"problems","start":83,"end":91,"id":15},{"text":".","start":91,"end":92,"id":16}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We first explore the relationship between the groups defining the norm and the resulting nonzero patterns, providing both forward and backward algorithms to go back and forth from groups to patterns.","_input_hash":-234136492,"_task_hash":-295065051,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"first","start":3,"end":8,"id":1},{"text":"explore","start":9,"end":16,"id":2},{"text":"the","start":17,"end":20,"id":3},{"text":"relationship","start":21,"end":33,"id":4},{"text":"between","start":34,"end":41,"id":5},{"text":"the","start":42,"end":45,"id":6},{"text":"groups","start":46,"end":52,"id":7},{"text":"defining","start":53,"end":61,"id":8},{"text":"the","start":62,"end":65,"id":9},{"text":"norm","start":66,"end":70,"id":10},{"text":"and","start":71,"end":74,"id":11},{"text":"the","start":75,"end":78,"id":12},{"text":"resulting","start":79,"end":88,"id":13},{"text":"nonzero","start":89,"end":96,"id":14},{"text":"patterns","start":97,"end":105,"id":15},{"text":",","start":105,"end":106,"id":16},{"text":"providing","start":107,"end":116,"id":17},{"text":"both","start":117,"end":121,"id":18},{"text":"forward","start":122,"end":129,"id":19},{"text":"and","start":130,"end":133,"id":20},{"text":"backward","start":134,"end":142,"id":21},{"text":"algorithms","start":143,"end":153,"id":22},{"text":"to","start":154,"end":156,"id":23},{"text":"go","start":157,"end":159,"id":24},{"text":"back","start":160,"end":164,"id":25},{"text":"and","start":165,"end":168,"id":26},{"text":"forth","start":169,"end":174,"id":27},{"text":"from","start":175,"end":179,"id":28},{"text":"groups","start":180,"end":186,"id":29},{"text":"to","start":187,"end":189,"id":30},{"text":"patterns","start":190,"end":198,"id":31},{"text":".","start":198,"end":199,"id":32}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"This allows the design of norms adapted to specific prior knowledge expressed in terms of nonzero patterns.","_input_hash":-348166248,"_task_hash":-1653476760,"tokens":[{"text":"This","start":0,"end":4,"id":0},{"text":"allows","start":5,"end":11,"id":1},{"text":"the","start":12,"end":15,"id":2},{"text":"design","start":16,"end":22,"id":3},{"text":"of","start":23,"end":25,"id":4},{"text":"norms","start":26,"end":31,"id":5},{"text":"adapted","start":32,"end":39,"id":6},{"text":"to","start":40,"end":42,"id":7},{"text":"specific","start":43,"end":51,"id":8},{"text":"prior","start":52,"end":57,"id":9},{"text":"knowledge","start":58,"end":67,"id":10},{"text":"expressed","start":68,"end":77,"id":11},{"text":"in","start":78,"end":80,"id":12},{"text":"terms","start":81,"end":86,"id":13},{"text":"of","start":87,"end":89,"id":14},{"text":"nonzero","start":90,"end":97,"id":15},{"text":"patterns","start":98,"end":106,"id":16},{"text":".","start":106,"end":107,"id":17}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We also present an efficient active set algorithm, and analyze the consistency of variable selection for least-squares linear regression in low and high-dimensional settings.","_input_hash":1222720645,"_task_hash":1863178154,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"also","start":3,"end":7,"id":1},{"text":"present","start":8,"end":15,"id":2},{"text":"an","start":16,"end":18,"id":3},{"text":"efficient","start":19,"end":28,"id":4},{"text":"active","start":29,"end":35,"id":5},{"text":"set","start":36,"end":39,"id":6},{"text":"algorithm","start":40,"end":49,"id":7},{"text":",","start":49,"end":50,"id":8},{"text":"and","start":51,"end":54,"id":9},{"text":"analyze","start":55,"end":62,"id":10},{"text":"the","start":63,"end":66,"id":11},{"text":"consistency","start":67,"end":78,"id":12},{"text":"of","start":79,"end":81,"id":13},{"text":"variable","start":82,"end":90,"id":14},{"text":"selection","start":91,"end":100,"id":15},{"text":"for","start":101,"end":104,"id":16},{"text":"least","start":105,"end":110,"id":17},{"text":"-","start":110,"end":111,"id":18},{"text":"squares","start":111,"end":118,"id":19},{"text":"linear","start":119,"end":125,"id":20},{"text":"regression","start":126,"end":136,"id":21},{"text":"in","start":137,"end":139,"id":22},{"text":"low","start":140,"end":143,"id":23},{"text":"and","start":144,"end":147,"id":24},{"text":"high","start":148,"end":152,"id":25},{"text":"-","start":152,"end":153,"id":26},{"text":"dimensional","start":153,"end":164,"id":27},{"text":"settings","start":165,"end":173,"id":28},{"text":".","start":173,"end":174,"id":29}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":29,"end":49,"token_start":5,"token_end":7,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"parallel_computing|NOUN","word":"parallel computing","sense":"NOUN","meta":{"score":0.7713999748,"sense":"NOUN"},"_input_hash":191453569,"_task_hash":1194834495,"_session_id":null,"_view_id":"html","answer":"reject","spans":[],"tokens":[{"text":"parallel_computing|NOUN","start":0,"end":23,"id":0}]}
{"text":"Network models have been popular for modeling and representing complex relationships and dependencies between observed variables.","_input_hash":699820024,"_task_hash":-1486862666,"tokens":[{"text":"Network","start":0,"end":7,"id":0},{"text":"models","start":8,"end":14,"id":1},{"text":"have","start":15,"end":19,"id":2},{"text":"been","start":20,"end":24,"id":3},{"text":"popular","start":25,"end":32,"id":4},{"text":"for","start":33,"end":36,"id":5},{"text":"modeling","start":37,"end":45,"id":6},{"text":"and","start":46,"end":49,"id":7},{"text":"representing","start":50,"end":62,"id":8},{"text":"complex","start":63,"end":70,"id":9},{"text":"relationships","start":71,"end":84,"id":10},{"text":"and","start":85,"end":88,"id":11},{"text":"dependencies","start":89,"end":101,"id":12},{"text":"between","start":102,"end":109,"id":13},{"text":"observed","start":110,"end":118,"id":14},{"text":"variables","start":119,"end":128,"id":15},{"text":".","start":128,"end":129,"id":16}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":0,"end":14,"token_start":0,"token_end":1,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"When data comes from a dynamic stochastic process, a single static network model cannot adequately capture transient dependencies, such as, gene regulatory dependencies throughout a developmental cycle of an organism.","_input_hash":-236160815,"_task_hash":-1156441500,"tokens":[{"text":"When","start":0,"end":4,"id":0},{"text":"data","start":5,"end":9,"id":1},{"text":"comes","start":10,"end":15,"id":2},{"text":"from","start":16,"end":20,"id":3},{"text":"a","start":21,"end":22,"id":4},{"text":"dynamic","start":23,"end":30,"id":5},{"text":"stochastic","start":31,"end":41,"id":6},{"text":"process","start":42,"end":49,"id":7},{"text":",","start":49,"end":50,"id":8},{"text":"a","start":51,"end":52,"id":9},{"text":"single","start":53,"end":59,"id":10},{"text":"static","start":60,"end":66,"id":11},{"text":"network","start":67,"end":74,"id":12},{"text":"model","start":75,"end":80,"id":13},{"text":"can","start":81,"end":84,"id":14},{"text":"not","start":84,"end":87,"id":15},{"text":"adequately","start":88,"end":98,"id":16},{"text":"capture","start":99,"end":106,"id":17},{"text":"transient","start":107,"end":116,"id":18},{"text":"dependencies","start":117,"end":129,"id":19},{"text":",","start":129,"end":130,"id":20},{"text":"such","start":131,"end":135,"id":21},{"text":"as","start":136,"end":138,"id":22},{"text":",","start":138,"end":139,"id":23},{"text":"gene","start":140,"end":144,"id":24},{"text":"regulatory","start":145,"end":155,"id":25},{"text":"dependencies","start":156,"end":168,"id":26},{"text":"throughout","start":169,"end":179,"id":27},{"text":"a","start":180,"end":181,"id":28},{"text":"developmental","start":182,"end":195,"id":29},{"text":"cycle","start":196,"end":201,"id":30},{"text":"of","start":202,"end":204,"id":31},{"text":"an","start":205,"end":207,"id":32},{"text":"organism","start":208,"end":216,"id":33},{"text":".","start":216,"end":217,"id":34}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Kolar et al (2010b) proposed a method based on kernel-smoothing l1-penalized logistic regression for estimating time-varying networks from nodal observations collected from a time-series of observational data.","_input_hash":-1486393567,"_task_hash":-273381452,"tokens":[{"text":"Kolar","start":0,"end":5,"id":0},{"text":"et","start":6,"end":8,"id":1},{"text":"al","start":9,"end":11,"id":2},{"text":"(","start":12,"end":13,"id":3},{"text":"2010b","start":13,"end":18,"id":4},{"text":")","start":18,"end":19,"id":5},{"text":"proposed","start":20,"end":28,"id":6},{"text":"a","start":29,"end":30,"id":7},{"text":"method","start":31,"end":37,"id":8},{"text":"based","start":38,"end":43,"id":9},{"text":"on","start":44,"end":46,"id":10},{"text":"kernel","start":47,"end":53,"id":11},{"text":"-","start":53,"end":54,"id":12},{"text":"smoothing","start":54,"end":63,"id":13},{"text":"l1-penalized","start":64,"end":76,"id":14},{"text":"logistic","start":77,"end":85,"id":15},{"text":"regression","start":86,"end":96,"id":16},{"text":"for","start":97,"end":100,"id":17},{"text":"estimating","start":101,"end":111,"id":18},{"text":"time","start":112,"end":116,"id":19},{"text":"-","start":116,"end":117,"id":20},{"text":"varying","start":117,"end":124,"id":21},{"text":"networks","start":125,"end":133,"id":22},{"text":"from","start":134,"end":138,"id":23},{"text":"nodal","start":139,"end":144,"id":24},{"text":"observations","start":145,"end":157,"id":25},{"text":"collected","start":158,"end":167,"id":26},{"text":"from","start":168,"end":172,"id":27},{"text":"a","start":173,"end":174,"id":28},{"text":"time","start":175,"end":179,"id":29},{"text":"-","start":179,"end":180,"id":30},{"text":"series","start":180,"end":186,"id":31},{"text":"of","start":187,"end":189,"id":32},{"text":"observational","start":190,"end":203,"id":33},{"text":"data","start":204,"end":208,"id":34},{"text":".","start":208,"end":209,"id":35}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"In this paper, we establish conditions under which the proposed method consistently recovers the structure of a time-varying network.","_input_hash":-1539491207,"_task_hash":1334134881,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"this","start":3,"end":7,"id":1},{"text":"paper","start":8,"end":13,"id":2},{"text":",","start":13,"end":14,"id":3},{"text":"we","start":15,"end":17,"id":4},{"text":"establish","start":18,"end":27,"id":5},{"text":"conditions","start":28,"end":38,"id":6},{"text":"under","start":39,"end":44,"id":7},{"text":"which","start":45,"end":50,"id":8},{"text":"the","start":51,"end":54,"id":9},{"text":"proposed","start":55,"end":63,"id":10},{"text":"method","start":64,"end":70,"id":11},{"text":"consistently","start":71,"end":83,"id":12},{"text":"recovers","start":84,"end":92,"id":13},{"text":"the","start":93,"end":96,"id":14},{"text":"structure","start":97,"end":106,"id":15},{"text":"of","start":107,"end":109,"id":16},{"text":"a","start":110,"end":111,"id":17},{"text":"time","start":112,"end":116,"id":18},{"text":"-","start":116,"end":117,"id":19},{"text":"varying","start":117,"end":124,"id":20},{"text":"network","start":125,"end":132,"id":21},{"text":".","start":132,"end":133,"id":22}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"This work complements previous empirical findings by providing sound theoretical guarantees for the proposed estimation procedure.","_input_hash":1593596978,"_task_hash":1378292479,"tokens":[{"text":"This","start":0,"end":4,"id":0},{"text":"work","start":5,"end":9,"id":1},{"text":"complements","start":10,"end":21,"id":2},{"text":"previous","start":22,"end":30,"id":3},{"text":"empirical","start":31,"end":40,"id":4},{"text":"findings","start":41,"end":49,"id":5},{"text":"by","start":50,"end":52,"id":6},{"text":"providing","start":53,"end":62,"id":7},{"text":"sound","start":63,"end":68,"id":8},{"text":"theoretical","start":69,"end":80,"id":9},{"text":"guarantees","start":81,"end":91,"id":10},{"text":"for","start":92,"end":95,"id":11},{"text":"the","start":96,"end":99,"id":12},{"text":"proposed","start":100,"end":108,"id":13},{"text":"estimation","start":109,"end":119,"id":14},{"text":"procedure","start":120,"end":129,"id":15},{"text":".","start":129,"end":130,"id":16}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"For completeness, we include numerical simulations in the paper.","_input_hash":-1381506018,"_task_hash":370247468,"tokens":[{"text":"For","start":0,"end":3,"id":0},{"text":"completeness","start":4,"end":16,"id":1},{"text":",","start":16,"end":17,"id":2},{"text":"we","start":18,"end":20,"id":3},{"text":"include","start":21,"end":28,"id":4},{"text":"numerical","start":29,"end":38,"id":5},{"text":"simulations","start":39,"end":50,"id":6},{"text":"in","start":51,"end":53,"id":7},{"text":"the","start":54,"end":57,"id":8},{"text":"paper","start":58,"end":63,"id":9},{"text":".","start":63,"end":64,"id":10}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Fourier_transforms|NOUN","word":"Fourier transforms","sense":"NOUN","meta":{"score":0.7833999991,"sense":"NOUN"},"_input_hash":1067371207,"_task_hash":-118815589,"_session_id":null,"_view_id":"html","answer":"reject","spans":[],"tokens":[{"text":"Fourier_transforms|NOUN","start":0,"end":23,"id":0}]}
{"text":"algorithm|NOUN","word":"algorithm","sense":"NOUN","meta":{"score":0.7572000027,"sense":"NOUN"},"_input_hash":511803611,"_task_hash":1321696130,"_session_id":null,"_view_id":"html","answer":"reject","spans":[],"tokens":[{"text":"algorithm|NOUN","start":0,"end":14,"id":0}]}
{"text":"The problem of supervised classification (or discrimination) with functional data is considered, with a special interest on the popular k-nearest neighbors (k-NN) classifier.","_input_hash":1446338438,"_task_hash":-1203685157,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"problem","start":4,"end":11,"id":1},{"text":"of","start":12,"end":14,"id":2},{"text":"supervised","start":15,"end":25,"id":3},{"text":"classification","start":26,"end":40,"id":4},{"text":"(","start":41,"end":42,"id":5},{"text":"or","start":42,"end":44,"id":6},{"text":"discrimination","start":45,"end":59,"id":7},{"text":")","start":59,"end":60,"id":8},{"text":"with","start":61,"end":65,"id":9},{"text":"functional","start":66,"end":76,"id":10},{"text":"data","start":77,"end":81,"id":11},{"text":"is","start":82,"end":84,"id":12},{"text":"considered","start":85,"end":95,"id":13},{"text":",","start":95,"end":96,"id":14},{"text":"with","start":97,"end":101,"id":15},{"text":"a","start":102,"end":103,"id":16},{"text":"special","start":104,"end":111,"id":17},{"text":"interest","start":112,"end":120,"id":18},{"text":"on","start":121,"end":123,"id":19},{"text":"the","start":124,"end":127,"id":20},{"text":"popular","start":128,"end":135,"id":21},{"text":"k","start":136,"end":137,"id":22},{"text":"-","start":137,"end":138,"id":23},{"text":"nearest","start":138,"end":145,"id":24},{"text":"neighbors","start":146,"end":155,"id":25},{"text":"(","start":156,"end":157,"id":26},{"text":"k","start":157,"end":158,"id":27},{"text":"-","start":158,"end":159,"id":28},{"text":"NN","start":159,"end":161,"id":29},{"text":")","start":161,"end":162,"id":30},{"text":"classifier","start":163,"end":173,"id":31},{"text":".","start":173,"end":174,"id":32}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":136,"end":155,"token_start":22,"token_end":25,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"First, relying on a recent result by Cerou and Guyader (2006), we prove the consistency of the k-NN classifier for functional data whose distribution belongs to a broad family of Gaussian processes with triangular covariance functions.","_input_hash":1795532205,"_task_hash":-1319971045,"tokens":[{"text":"First","start":0,"end":5,"id":0},{"text":",","start":5,"end":6,"id":1},{"text":"relying","start":7,"end":14,"id":2},{"text":"on","start":15,"end":17,"id":3},{"text":"a","start":18,"end":19,"id":4},{"text":"recent","start":20,"end":26,"id":5},{"text":"result","start":27,"end":33,"id":6},{"text":"by","start":34,"end":36,"id":7},{"text":"Cerou","start":37,"end":42,"id":8},{"text":"and","start":43,"end":46,"id":9},{"text":"Guyader","start":47,"end":54,"id":10},{"text":"(","start":55,"end":56,"id":11},{"text":"2006","start":56,"end":60,"id":12},{"text":")","start":60,"end":61,"id":13},{"text":",","start":61,"end":62,"id":14},{"text":"we","start":63,"end":65,"id":15},{"text":"prove","start":66,"end":71,"id":16},{"text":"the","start":72,"end":75,"id":17},{"text":"consistency","start":76,"end":87,"id":18},{"text":"of","start":88,"end":90,"id":19},{"text":"the","start":91,"end":94,"id":20},{"text":"k","start":95,"end":96,"id":21},{"text":"-","start":96,"end":97,"id":22},{"text":"NN","start":97,"end":99,"id":23},{"text":"classifier","start":100,"end":110,"id":24},{"text":"for","start":111,"end":114,"id":25},{"text":"functional","start":115,"end":125,"id":26},{"text":"data","start":126,"end":130,"id":27},{"text":"whose","start":131,"end":136,"id":28},{"text":"distribution","start":137,"end":149,"id":29},{"text":"belongs","start":150,"end":157,"id":30},{"text":"to","start":158,"end":160,"id":31},{"text":"a","start":161,"end":162,"id":32},{"text":"broad","start":163,"end":168,"id":33},{"text":"family","start":169,"end":175,"id":34},{"text":"of","start":176,"end":178,"id":35},{"text":"Gaussian","start":179,"end":187,"id":36},{"text":"processes","start":188,"end":197,"id":37},{"text":"with","start":198,"end":202,"id":38},{"text":"triangular","start":203,"end":213,"id":39},{"text":"covariance","start":214,"end":224,"id":40},{"text":"functions","start":225,"end":234,"id":41},{"text":".","start":234,"end":235,"id":42}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Second, on a more practical side, we check the behavior of the k-NN method when compared with a few other functional classifiers.","_input_hash":1170064707,"_task_hash":1948127561,"tokens":[{"text":"Second","start":0,"end":6,"id":0},{"text":",","start":6,"end":7,"id":1},{"text":"on","start":8,"end":10,"id":2},{"text":"a","start":11,"end":12,"id":3},{"text":"more","start":13,"end":17,"id":4},{"text":"practical","start":18,"end":27,"id":5},{"text":"side","start":28,"end":32,"id":6},{"text":",","start":32,"end":33,"id":7},{"text":"we","start":34,"end":36,"id":8},{"text":"check","start":37,"end":42,"id":9},{"text":"the","start":43,"end":46,"id":10},{"text":"behavior","start":47,"end":55,"id":11},{"text":"of","start":56,"end":58,"id":12},{"text":"the","start":59,"end":62,"id":13},{"text":"k","start":63,"end":64,"id":14},{"text":"-","start":64,"end":65,"id":15},{"text":"NN","start":65,"end":67,"id":16},{"text":"method","start":68,"end":74,"id":17},{"text":"when","start":75,"end":79,"id":18},{"text":"compared","start":80,"end":88,"id":19},{"text":"with","start":89,"end":93,"id":20},{"text":"a","start":94,"end":95,"id":21},{"text":"few","start":96,"end":99,"id":22},{"text":"other","start":100,"end":105,"id":23},{"text":"functional","start":106,"end":116,"id":24},{"text":"classifiers","start":117,"end":128,"id":25},{"text":".","start":128,"end":129,"id":26}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"This is carried out through a small simulation study and the analysis of several real functional data sets.","_input_hash":1263647153,"_task_hash":-1692974147,"tokens":[{"text":"This","start":0,"end":4,"id":0},{"text":"is","start":5,"end":7,"id":1},{"text":"carried","start":8,"end":15,"id":2},{"text":"out","start":16,"end":19,"id":3},{"text":"through","start":20,"end":27,"id":4},{"text":"a","start":28,"end":29,"id":5},{"text":"small","start":30,"end":35,"id":6},{"text":"simulation","start":36,"end":46,"id":7},{"text":"study","start":47,"end":52,"id":8},{"text":"and","start":53,"end":56,"id":9},{"text":"the","start":57,"end":60,"id":10},{"text":"analysis","start":61,"end":69,"id":11},{"text":"of","start":70,"end":72,"id":12},{"text":"several","start":73,"end":80,"id":13},{"text":"real","start":81,"end":85,"id":14},{"text":"functional","start":86,"end":96,"id":15},{"text":"data","start":97,"end":101,"id":16},{"text":"sets","start":102,"end":106,"id":17},{"text":".","start":106,"end":107,"id":18}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"While no global \"uniform\" winner emerges from such comparisons, the overall performance of the k-NN method, together with its sound intuitive motivation and relative simplicity, suggests that it could represent a reasonable benchmark for the classification problem with functional data.","_input_hash":624564835,"_task_hash":-1730985630,"tokens":[{"text":"While","start":0,"end":5,"id":0},{"text":"no","start":6,"end":8,"id":1},{"text":"global","start":9,"end":15,"id":2},{"text":"\"","start":16,"end":17,"id":3},{"text":"uniform","start":17,"end":24,"id":4},{"text":"\"","start":24,"end":25,"id":5},{"text":"winner","start":26,"end":32,"id":6},{"text":"emerges","start":33,"end":40,"id":7},{"text":"from","start":41,"end":45,"id":8},{"text":"such","start":46,"end":50,"id":9},{"text":"comparisons","start":51,"end":62,"id":10},{"text":",","start":62,"end":63,"id":11},{"text":"the","start":64,"end":67,"id":12},{"text":"overall","start":68,"end":75,"id":13},{"text":"performance","start":76,"end":87,"id":14},{"text":"of","start":88,"end":90,"id":15},{"text":"the","start":91,"end":94,"id":16},{"text":"k","start":95,"end":96,"id":17},{"text":"-","start":96,"end":97,"id":18},{"text":"NN","start":97,"end":99,"id":19},{"text":"method","start":100,"end":106,"id":20},{"text":",","start":106,"end":107,"id":21},{"text":"together","start":108,"end":116,"id":22},{"text":"with","start":117,"end":121,"id":23},{"text":"its","start":122,"end":125,"id":24},{"text":"sound","start":126,"end":131,"id":25},{"text":"intuitive","start":132,"end":141,"id":26},{"text":"motivation","start":142,"end":152,"id":27},{"text":"and","start":153,"end":156,"id":28},{"text":"relative","start":157,"end":165,"id":29},{"text":"simplicity","start":166,"end":176,"id":30},{"text":",","start":176,"end":177,"id":31},{"text":"suggests","start":178,"end":186,"id":32},{"text":"that","start":187,"end":191,"id":33},{"text":"it","start":192,"end":194,"id":34},{"text":"could","start":195,"end":200,"id":35},{"text":"represent","start":201,"end":210,"id":36},{"text":"a","start":211,"end":212,"id":37},{"text":"reasonable","start":213,"end":223,"id":38},{"text":"benchmark","start":224,"end":233,"id":39},{"text":"for","start":234,"end":237,"id":40},{"text":"the","start":238,"end":241,"id":41},{"text":"classification","start":242,"end":256,"id":42},{"text":"problem","start":257,"end":264,"id":43},{"text":"with","start":265,"end":269,"id":44},{"text":"functional","start":270,"end":280,"id":45},{"text":"data","start":281,"end":285,"id":46},{"text":".","start":285,"end":286,"id":47}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
