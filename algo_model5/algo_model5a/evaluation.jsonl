{"text":"This method is in practice difficult, because it requires a global optimization of a complicated function, the joint distribution by fixed input variables.","_input_hash":-2105218453,"_task_hash":-1582819205,"tokens":[{"text":"This","start":0,"end":4,"id":0},{"text":"method","start":5,"end":11,"id":1},{"text":"is","start":12,"end":14,"id":2},{"text":"in","start":15,"end":17,"id":3},{"text":"practice","start":18,"end":26,"id":4},{"text":"difficult","start":27,"end":36,"id":5},{"text":",","start":36,"end":37,"id":6},{"text":"because","start":38,"end":45,"id":7},{"text":"it","start":46,"end":48,"id":8},{"text":"requires","start":49,"end":57,"id":9},{"text":"a","start":58,"end":59,"id":10},{"text":"global","start":60,"end":66,"id":11},{"text":"optimization","start":67,"end":79,"id":12},{"text":"of","start":80,"end":82,"id":13},{"text":"a","start":83,"end":84,"id":14},{"text":"complicated","start":85,"end":96,"id":15},{"text":"function","start":97,"end":105,"id":16},{"text":",","start":105,"end":106,"id":17},{"text":"the","start":107,"end":110,"id":18},{"text":"joint","start":111,"end":116,"id":19},{"text":"distribution","start":117,"end":129,"id":20},{"text":"by","start":130,"end":132,"id":21},{"text":"fixed","start":133,"end":138,"id":22},{"text":"input","start":139,"end":144,"id":23},{"text":"variables","start":145,"end":154,"id":24},{"text":".","start":154,"end":155,"id":25}],"spans":[],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"Finally, we suggest a simple iterative method that can be used to improve the output of existing algorithms.","_input_hash":-402573250,"_task_hash":-2136247451,"tokens":[{"text":"Finally","start":0,"end":7,"id":0},{"text":",","start":7,"end":8,"id":1},{"text":"we","start":9,"end":11,"id":2},{"text":"suggest","start":12,"end":19,"id":3},{"text":"a","start":20,"end":21,"id":4},{"text":"simple","start":22,"end":28,"id":5},{"text":"iterative","start":29,"end":38,"id":6},{"text":"method","start":39,"end":45,"id":7},{"text":"that","start":46,"end":50,"id":8},{"text":"can","start":51,"end":54,"id":9},{"text":"be","start":55,"end":57,"id":10},{"text":"used","start":58,"end":62,"id":11},{"text":"to","start":63,"end":65,"id":12},{"text":"improve","start":66,"end":73,"id":13},{"text":"the","start":74,"end":77,"id":14},{"text":"output","start":78,"end":84,"id":15},{"text":"of","start":85,"end":87,"id":16},{"text":"existing","start":88,"end":96,"id":17},{"text":"algorithms","start":97,"end":107,"id":18},{"text":".","start":107,"end":108,"id":19}],"spans":[],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"We present and analyse three online algorithms for learning in discrete Hidden Markov Models (HMMs) and compare them with the Baldi-Chauvin Algorithm.","_input_hash":451561862,"_task_hash":1501748067,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"present","start":3,"end":10,"id":1},{"text":"and","start":11,"end":14,"id":2},{"text":"analyse","start":15,"end":22,"id":3},{"text":"three","start":23,"end":28,"id":4},{"text":"online","start":29,"end":35,"id":5},{"text":"algorithms","start":36,"end":46,"id":6},{"text":"for","start":47,"end":50,"id":7},{"text":"learning","start":51,"end":59,"id":8},{"text":"in","start":60,"end":62,"id":9},{"text":"discrete","start":63,"end":71,"id":10},{"text":"Hidden","start":72,"end":78,"id":11},{"text":"Markov","start":79,"end":85,"id":12},{"text":"Models","start":86,"end":92,"id":13},{"text":"(","start":93,"end":94,"id":14},{"text":"HMMs","start":94,"end":98,"id":15},{"text":")","start":98,"end":99,"id":16},{"text":"and","start":100,"end":103,"id":17},{"text":"compare","start":104,"end":111,"id":18},{"text":"them","start":112,"end":116,"id":19},{"text":"with","start":117,"end":121,"id":20},{"text":"the","start":122,"end":125,"id":21},{"text":"Baldi","start":126,"end":131,"id":22},{"text":"-","start":131,"end":132,"id":23},{"text":"Chauvin","start":132,"end":139,"id":24},{"text":"Algorithm","start":140,"end":149,"id":25},{"text":".","start":149,"end":150,"id":26}],"spans":[{"start":29,"end":35,"token_start":5,"token_end":5,"label":"ALGO","answer":"accept"},{"start":72,"end":85,"token_start":11,"token_end":12,"label":"ALGO","answer":"accept"},{"start":126,"end":139,"token_start":22,"token_end":24,"label":"ALGO","answer":"accept"}],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"The decisional states form a partition of the lower-level causal states that is defined according to the higher-level user's knowledge.","_input_hash":-90963145,"_task_hash":-1141820307,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"decisional","start":4,"end":14,"id":1},{"text":"states","start":15,"end":21,"id":2},{"text":"form","start":22,"end":26,"id":3},{"text":"a","start":27,"end":28,"id":4},{"text":"partition","start":29,"end":38,"id":5},{"text":"of","start":39,"end":41,"id":6},{"text":"the","start":42,"end":45,"id":7},{"text":"lower","start":46,"end":51,"id":8},{"text":"-","start":51,"end":52,"id":9},{"text":"level","start":52,"end":57,"id":10},{"text":"causal","start":58,"end":64,"id":11},{"text":"states","start":65,"end":71,"id":12},{"text":"that","start":72,"end":76,"id":13},{"text":"is","start":77,"end":79,"id":14},{"text":"defined","start":80,"end":87,"id":15},{"text":"according","start":88,"end":97,"id":16},{"text":"to","start":98,"end":100,"id":17},{"text":"the","start":101,"end":104,"id":18},{"text":"higher","start":105,"end":111,"id":19},{"text":"-","start":111,"end":112,"id":20},{"text":"level","start":112,"end":117,"id":21},{"text":"user","start":118,"end":122,"id":22},{"text":"'s","start":122,"end":124,"id":23},{"text":"knowledge","start":125,"end":134,"id":24},{"text":".","start":134,"end":135,"id":25}],"spans":[],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"We consider principal component analysis (PCA) in decomposable Gaussian graphical models.","_input_hash":874169289,"_task_hash":-1837408934,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"consider","start":3,"end":11,"id":1},{"text":"principal","start":12,"end":21,"id":2},{"text":"component","start":22,"end":31,"id":3},{"text":"analysis","start":32,"end":40,"id":4},{"text":"(","start":41,"end":42,"id":5},{"text":"PCA","start":42,"end":45,"id":6},{"text":")","start":45,"end":46,"id":7},{"text":"in","start":47,"end":49,"id":8},{"text":"decomposable","start":50,"end":62,"id":9},{"text":"Gaussian","start":63,"end":71,"id":10},{"text":"graphical","start":72,"end":81,"id":11},{"text":"models","start":82,"end":88,"id":12},{"text":".","start":88,"end":89,"id":13}],"spans":[{"token_start":2,"token_end":4,"start":12,"end":40,"text":"principal component analysis","label":"ALGO","source":"./algo_model5","input_hash":874169289,"answer":"accept"},{"token_start":9,"token_end":11,"start":50,"end":81,"text":"decomposable Gaussian graphical","label":"ALGO","source":"./algo_model5","input_hash":874169289,"answer":"accept"}],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"Specifically, we present an application to information retrieval in which documents are modeled as paths down a random tree, and the preferential attachment dynamics of the nCRP leads to clustering of documents according to sharing of topics at multiple levels of abstraction.","_input_hash":1951118404,"_task_hash":1289881453,"tokens":[{"text":"Specifically","start":0,"end":12,"id":0},{"text":",","start":12,"end":13,"id":1},{"text":"we","start":14,"end":16,"id":2},{"text":"present","start":17,"end":24,"id":3},{"text":"an","start":25,"end":27,"id":4},{"text":"application","start":28,"end":39,"id":5},{"text":"to","start":40,"end":42,"id":6},{"text":"information","start":43,"end":54,"id":7},{"text":"retrieval","start":55,"end":64,"id":8},{"text":"in","start":65,"end":67,"id":9},{"text":"which","start":68,"end":73,"id":10},{"text":"documents","start":74,"end":83,"id":11},{"text":"are","start":84,"end":87,"id":12},{"text":"modeled","start":88,"end":95,"id":13},{"text":"as","start":96,"end":98,"id":14},{"text":"paths","start":99,"end":104,"id":15},{"text":"down","start":105,"end":109,"id":16},{"text":"a","start":110,"end":111,"id":17},{"text":"random","start":112,"end":118,"id":18},{"text":"tree","start":119,"end":123,"id":19},{"text":",","start":123,"end":124,"id":20},{"text":"and","start":125,"end":128,"id":21},{"text":"the","start":129,"end":132,"id":22},{"text":"preferential","start":133,"end":145,"id":23},{"text":"attachment","start":146,"end":156,"id":24},{"text":"dynamics","start":157,"end":165,"id":25},{"text":"of","start":166,"end":168,"id":26},{"text":"the","start":169,"end":172,"id":27},{"text":"nCRP","start":173,"end":177,"id":28},{"text":"leads","start":178,"end":183,"id":29},{"text":"to","start":184,"end":186,"id":30},{"text":"clustering","start":187,"end":197,"id":31},{"text":"of","start":198,"end":200,"id":32},{"text":"documents","start":201,"end":210,"id":33},{"text":"according","start":211,"end":220,"id":34},{"text":"to","start":221,"end":223,"id":35},{"text":"sharing","start":224,"end":231,"id":36},{"text":"of","start":232,"end":234,"id":37},{"text":"topics","start":235,"end":241,"id":38},{"text":"at","start":242,"end":244,"id":39},{"text":"multiple","start":245,"end":253,"id":40},{"text":"levels","start":254,"end":260,"id":41},{"text":"of","start":261,"end":263,"id":42},{"text":"abstraction","start":264,"end":275,"id":43},{"text":".","start":275,"end":276,"id":44}],"spans":[],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"We show how this stochastic process can be used as a prior distribution in a Bayesian nonparametric model of document collections.","_input_hash":-1051689315,"_task_hash":-214433426,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"show","start":3,"end":7,"id":1},{"text":"how","start":8,"end":11,"id":2},{"text":"this","start":12,"end":16,"id":3},{"text":"stochastic","start":17,"end":27,"id":4},{"text":"process","start":28,"end":35,"id":5},{"text":"can","start":36,"end":39,"id":6},{"text":"be","start":40,"end":42,"id":7},{"text":"used","start":43,"end":47,"id":8},{"text":"as","start":48,"end":50,"id":9},{"text":"a","start":51,"end":52,"id":10},{"text":"prior","start":53,"end":58,"id":11},{"text":"distribution","start":59,"end":71,"id":12},{"text":"in","start":72,"end":74,"id":13},{"text":"a","start":75,"end":76,"id":14},{"text":"Bayesian","start":77,"end":85,"id":15},{"text":"nonparametric","start":86,"end":99,"id":16},{"text":"model","start":100,"end":105,"id":17},{"text":"of","start":106,"end":108,"id":18},{"text":"document","start":109,"end":117,"id":19},{"text":"collections","start":118,"end":129,"id":20},{"text":".","start":129,"end":130,"id":21}],"spans":[{"start":77,"end":99,"token_start":15,"token_end":16,"label":"ALGO","answer":"accept"}],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"Finally, an adaptive version of our sparsity-smoothness penalized approach yields large additional performance gains.","_input_hash":835233476,"_task_hash":1281631127,"tokens":[{"text":"Finally","start":0,"end":7,"id":0},{"text":",","start":7,"end":8,"id":1},{"text":"an","start":9,"end":11,"id":2},{"text":"adaptive","start":12,"end":20,"id":3},{"text":"version","start":21,"end":28,"id":4},{"text":"of","start":29,"end":31,"id":5},{"text":"our","start":32,"end":35,"id":6},{"text":"sparsity","start":36,"end":44,"id":7},{"text":"-","start":44,"end":45,"id":8},{"text":"smoothness","start":45,"end":55,"id":9},{"text":"penalized","start":56,"end":65,"id":10},{"text":"approach","start":66,"end":74,"id":11},{"text":"yields","start":75,"end":81,"id":12},{"text":"large","start":82,"end":87,"id":13},{"text":"additional","start":88,"end":98,"id":14},{"text":"performance","start":99,"end":110,"id":15},{"text":"gains","start":111,"end":116,"id":16},{"text":".","start":116,"end":117,"id":17}],"spans":[],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"The theorem appears to be new but is closely related to results achieved by other investigators.","_input_hash":-1493657758,"_task_hash":1946779967,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"theorem","start":4,"end":11,"id":1},{"text":"appears","start":12,"end":19,"id":2},{"text":"to","start":20,"end":22,"id":3},{"text":"be","start":23,"end":25,"id":4},{"text":"new","start":26,"end":29,"id":5},{"text":"but","start":30,"end":33,"id":6},{"text":"is","start":34,"end":36,"id":7},{"text":"closely","start":37,"end":44,"id":8},{"text":"related","start":45,"end":52,"id":9},{"text":"to","start":53,"end":55,"id":10},{"text":"results","start":56,"end":63,"id":11},{"text":"achieved","start":64,"end":72,"id":12},{"text":"by","start":73,"end":75,"id":13},{"text":"other","start":76,"end":81,"id":14},{"text":"investigators","start":82,"end":95,"id":15},{"text":".","start":95,"end":96,"id":16}],"spans":[],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"Unlike previous methods, its quantization error depends only on the intrinsic dimension of the data distribution, rather than the apparent dimension of the space in which the data happen to lie.","_input_hash":1862424817,"_task_hash":351926450,"tokens":[{"text":"Unlike","start":0,"end":6,"id":0},{"text":"previous","start":7,"end":15,"id":1},{"text":"methods","start":16,"end":23,"id":2},{"text":",","start":23,"end":24,"id":3},{"text":"its","start":25,"end":28,"id":4},{"text":"quantization","start":29,"end":41,"id":5},{"text":"error","start":42,"end":47,"id":6},{"text":"depends","start":48,"end":55,"id":7},{"text":"only","start":56,"end":60,"id":8},{"text":"on","start":61,"end":63,"id":9},{"text":"the","start":64,"end":67,"id":10},{"text":"intrinsic","start":68,"end":77,"id":11},{"text":"dimension","start":78,"end":87,"id":12},{"text":"of","start":88,"end":90,"id":13},{"text":"the","start":91,"end":94,"id":14},{"text":"data","start":95,"end":99,"id":15},{"text":"distribution","start":100,"end":112,"id":16},{"text":",","start":112,"end":113,"id":17},{"text":"rather","start":114,"end":120,"id":18},{"text":"than","start":121,"end":125,"id":19},{"text":"the","start":126,"end":129,"id":20},{"text":"apparent","start":130,"end":138,"id":21},{"text":"dimension","start":139,"end":148,"id":22},{"text":"of","start":149,"end":151,"id":23},{"text":"the","start":152,"end":155,"id":24},{"text":"space","start":156,"end":161,"id":25},{"text":"in","start":162,"end":164,"id":26},{"text":"which","start":165,"end":170,"id":27},{"text":"the","start":171,"end":174,"id":28},{"text":"data","start":175,"end":179,"id":29},{"text":"happen","start":180,"end":186,"id":30},{"text":"to","start":187,"end":189,"id":31},{"text":"lie","start":190,"end":193,"id":32},{"text":".","start":193,"end":194,"id":33}],"spans":[],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"The intrinsic underlying structure of the system is modeled by an epsilon-machine and its causal states.","_input_hash":-1157640748,"_task_hash":1877334064,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"intrinsic","start":4,"end":13,"id":1},{"text":"underlying","start":14,"end":24,"id":2},{"text":"structure","start":25,"end":34,"id":3},{"text":"of","start":35,"end":37,"id":4},{"text":"the","start":38,"end":41,"id":5},{"text":"system","start":42,"end":48,"id":6},{"text":"is","start":49,"end":51,"id":7},{"text":"modeled","start":52,"end":59,"id":8},{"text":"by","start":60,"end":62,"id":9},{"text":"an","start":63,"end":65,"id":10},{"text":"epsilon","start":66,"end":73,"id":11},{"text":"-","start":73,"end":74,"id":12},{"text":"machine","start":74,"end":81,"id":13},{"text":"and","start":82,"end":85,"id":14},{"text":"its","start":86,"end":89,"id":15},{"text":"causal","start":90,"end":96,"id":16},{"text":"states","start":97,"end":103,"id":17},{"text":".","start":103,"end":104,"id":18}],"spans":[{"start":66,"end":81,"token_start":11,"token_end":13,"label":"ALGO","answer":"accept"}],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"We compare approximation error to batch AdaBoost on synthetic datasets and generalization error on face datasets and the MNIST dataset.","_input_hash":1258227701,"_task_hash":330753842,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"compare","start":3,"end":10,"id":1},{"text":"approximation","start":11,"end":24,"id":2},{"text":"error","start":25,"end":30,"id":3},{"text":"to","start":31,"end":33,"id":4},{"text":"batch","start":34,"end":39,"id":5},{"text":"AdaBoost","start":40,"end":48,"id":6},{"text":"on","start":49,"end":51,"id":7},{"text":"synthetic","start":52,"end":61,"id":8},{"text":"datasets","start":62,"end":70,"id":9},{"text":"and","start":71,"end":74,"id":10},{"text":"generalization","start":75,"end":89,"id":11},{"text":"error","start":90,"end":95,"id":12},{"text":"on","start":96,"end":98,"id":13},{"text":"face","start":99,"end":103,"id":14},{"text":"datasets","start":104,"end":112,"id":15},{"text":"and","start":113,"end":116,"id":16},{"text":"the","start":117,"end":120,"id":17},{"text":"MNIST","start":121,"end":126,"id":18},{"text":"dataset","start":127,"end":134,"id":19},{"text":".","start":134,"end":135,"id":20}],"spans":[{"token_start":6,"token_end":6,"start":40,"end":48,"text":"AdaBoost","label":"ALGO","source":"./algo_model5","input_hash":1258227701,"answer":"accept"}],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"  There are two situations where such high dimensional features arise.","_input_hash":237257470,"_task_hash":-1881310355,"tokens":[{"text":"  ","start":0,"end":2,"id":0},{"text":"There","start":2,"end":7,"id":1},{"text":"are","start":8,"end":11,"id":2},{"text":"two","start":12,"end":15,"id":3},{"text":"situations","start":16,"end":26,"id":4},{"text":"where","start":27,"end":32,"id":5},{"text":"such","start":33,"end":37,"id":6},{"text":"high","start":38,"end":42,"id":7},{"text":"dimensional","start":43,"end":54,"id":8},{"text":"features","start":55,"end":63,"id":9},{"text":"arise","start":64,"end":69,"id":10},{"text":".","start":69,"end":70,"id":11}],"spans":[],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"We detail optimal algorithms to predict sequences generated in this way.","_input_hash":1746763958,"_task_hash":476958436,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"detail","start":3,"end":9,"id":1},{"text":"optimal","start":10,"end":17,"id":2},{"text":"algorithms","start":18,"end":28,"id":3},{"text":"to","start":29,"end":31,"id":4},{"text":"predict","start":32,"end":39,"id":5},{"text":"sequences","start":40,"end":49,"id":6},{"text":"generated","start":50,"end":59,"id":7},{"text":"in","start":60,"end":62,"id":8},{"text":"this","start":63,"end":67,"id":9},{"text":"way","start":68,"end":71,"id":10},{"text":".","start":71,"end":72,"id":11}],"spans":[],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"We present an out-of-sample expressions for both labeled and unlabeled data.","_input_hash":2024165145,"_task_hash":1186591962,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"present","start":3,"end":10,"id":1},{"text":"an","start":11,"end":13,"id":2},{"text":"out","start":14,"end":17,"id":3},{"text":"-","start":17,"end":18,"id":4},{"text":"of","start":18,"end":20,"id":5},{"text":"-","start":20,"end":21,"id":6},{"text":"sample","start":21,"end":27,"id":7},{"text":"expressions","start":28,"end":39,"id":8},{"text":"for","start":40,"end":43,"id":9},{"text":"both","start":44,"end":48,"id":10},{"text":"labeled","start":49,"end":56,"id":11},{"text":"and","start":57,"end":60,"id":12},{"text":"unlabeled","start":61,"end":70,"id":13},{"text":"data","start":71,"end":75,"id":14},{"text":".","start":75,"end":76,"id":15}],"spans":[],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"For fast mixing graphs, we show that the cost functions introduced by Shi and Malik can be well approximated as the rate of loss of predictive information about the location of random walkers on the graph.","_input_hash":-1891153758,"_task_hash":1014870552,"tokens":[{"text":"For","start":0,"end":3,"id":0},{"text":"fast","start":4,"end":8,"id":1},{"text":"mixing","start":9,"end":15,"id":2},{"text":"graphs","start":16,"end":22,"id":3},{"text":",","start":22,"end":23,"id":4},{"text":"we","start":24,"end":26,"id":5},{"text":"show","start":27,"end":31,"id":6},{"text":"that","start":32,"end":36,"id":7},{"text":"the","start":37,"end":40,"id":8},{"text":"cost","start":41,"end":45,"id":9},{"text":"functions","start":46,"end":55,"id":10},{"text":"introduced","start":56,"end":66,"id":11},{"text":"by","start":67,"end":69,"id":12},{"text":"Shi","start":70,"end":73,"id":13},{"text":"and","start":74,"end":77,"id":14},{"text":"Malik","start":78,"end":83,"id":15},{"text":"can","start":84,"end":87,"id":16},{"text":"be","start":88,"end":90,"id":17},{"text":"well","start":91,"end":95,"id":18},{"text":"approximated","start":96,"end":108,"id":19},{"text":"as","start":109,"end":111,"id":20},{"text":"the","start":112,"end":115,"id":21},{"text":"rate","start":116,"end":120,"id":22},{"text":"of","start":121,"end":123,"id":23},{"text":"loss","start":124,"end":128,"id":24},{"text":"of","start":129,"end":131,"id":25},{"text":"predictive","start":132,"end":142,"id":26},{"text":"information","start":143,"end":154,"id":27},{"text":"about","start":155,"end":160,"id":28},{"text":"the","start":161,"end":164,"id":29},{"text":"location","start":165,"end":173,"id":30},{"text":"of","start":174,"end":176,"id":31},{"text":"random","start":177,"end":183,"id":32},{"text":"walkers","start":184,"end":191,"id":33},{"text":"on","start":192,"end":194,"id":34},{"text":"the","start":195,"end":198,"id":35},{"text":"graph","start":199,"end":204,"id":36},{"text":".","start":204,"end":205,"id":37}],"spans":[],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"Although it is used very commonly, this procedure will make the response appear more predictable than it actually is.","_input_hash":2035627713,"_task_hash":-838434883,"tokens":[{"text":"Although","start":0,"end":8,"id":0},{"text":"it","start":9,"end":11,"id":1},{"text":"is","start":12,"end":14,"id":2},{"text":"used","start":15,"end":19,"id":3},{"text":"very","start":20,"end":24,"id":4},{"text":"commonly","start":25,"end":33,"id":5},{"text":",","start":33,"end":34,"id":6},{"text":"this","start":35,"end":39,"id":7},{"text":"procedure","start":40,"end":49,"id":8},{"text":"will","start":50,"end":54,"id":9},{"text":"make","start":55,"end":59,"id":10},{"text":"the","start":60,"end":63,"id":11},{"text":"response","start":64,"end":72,"id":12},{"text":"appear","start":73,"end":79,"id":13},{"text":"more","start":80,"end":84,"id":14},{"text":"predictable","start":85,"end":96,"id":15},{"text":"than","start":97,"end":101,"id":16},{"text":"it","start":102,"end":104,"id":17},{"text":"actually","start":105,"end":113,"id":18},{"text":"is","start":114,"end":116,"id":19},{"text":".","start":116,"end":117,"id":20}],"spans":[],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"to provide some insights about the behavior of the variable importance index based on random forests and in addition, to propose to investigate two classical issues of variable selection.","_input_hash":1956359793,"_task_hash":1819099401,"tokens":[{"text":"to","start":0,"end":2,"id":0},{"text":"provide","start":3,"end":10,"id":1},{"text":"some","start":11,"end":15,"id":2},{"text":"insights","start":16,"end":24,"id":3},{"text":"about","start":25,"end":30,"id":4},{"text":"the","start":31,"end":34,"id":5},{"text":"behavior","start":35,"end":43,"id":6},{"text":"of","start":44,"end":46,"id":7},{"text":"the","start":47,"end":50,"id":8},{"text":"variable","start":51,"end":59,"id":9},{"text":"importance","start":60,"end":70,"id":10},{"text":"index","start":71,"end":76,"id":11},{"text":"based","start":77,"end":82,"id":12},{"text":"on","start":83,"end":85,"id":13},{"text":"random","start":86,"end":92,"id":14},{"text":"forests","start":93,"end":100,"id":15},{"text":"and","start":101,"end":104,"id":16},{"text":"in","start":105,"end":107,"id":17},{"text":"addition","start":108,"end":116,"id":18},{"text":",","start":116,"end":117,"id":19},{"text":"to","start":118,"end":120,"id":20},{"text":"propose","start":121,"end":128,"id":21},{"text":"to","start":129,"end":131,"id":22},{"text":"investigate","start":132,"end":143,"id":23},{"text":"two","start":144,"end":147,"id":24},{"text":"classical","start":148,"end":157,"id":25},{"text":"issues","start":158,"end":164,"id":26},{"text":"of","start":165,"end":167,"id":27},{"text":"variable","start":168,"end":176,"id":28},{"text":"selection","start":177,"end":186,"id":29},{"text":".","start":186,"end":187,"id":30}],"spans":[{"start":86,"end":100,"token_start":14,"token_end":15,"label":"ALGO","answer":"accept"}],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"We demonstrate this algorithm on collections of scientific abstracts from several journals.","_input_hash":1728424860,"_task_hash":-1387184893,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"demonstrate","start":3,"end":14,"id":1},{"text":"this","start":15,"end":19,"id":2},{"text":"algorithm","start":20,"end":29,"id":3},{"text":"on","start":30,"end":32,"id":4},{"text":"collections","start":33,"end":44,"id":5},{"text":"of","start":45,"end":47,"id":6},{"text":"scientific","start":48,"end":58,"id":7},{"text":"abstracts","start":59,"end":68,"id":8},{"text":"from","start":69,"end":73,"id":9},{"text":"several","start":74,"end":81,"id":10},{"text":"journals","start":82,"end":90,"id":11},{"text":".","start":90,"end":91,"id":12}],"spans":[],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"We present a computationally efficient algorithm, with provable numerical convergence properties, for optimizing the penalized likelihood.","_input_hash":-1310496817,"_task_hash":539971387,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"present","start":3,"end":10,"id":1},{"text":"a","start":11,"end":12,"id":2},{"text":"computationally","start":13,"end":28,"id":3},{"text":"efficient","start":29,"end":38,"id":4},{"text":"algorithm","start":39,"end":48,"id":5},{"text":",","start":48,"end":49,"id":6},{"text":"with","start":50,"end":54,"id":7},{"text":"provable","start":55,"end":63,"id":8},{"text":"numerical","start":64,"end":73,"id":9},{"text":"convergence","start":74,"end":85,"id":10},{"text":"properties","start":86,"end":96,"id":11},{"text":",","start":96,"end":97,"id":12},{"text":"for","start":98,"end":101,"id":13},{"text":"optimizing","start":102,"end":112,"id":14},{"text":"the","start":113,"end":116,"id":15},{"text":"penalized","start":117,"end":126,"id":16},{"text":"likelihood","start":127,"end":137,"id":17},{"text":".","start":137,"end":138,"id":18}],"spans":[],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"The impact of missing data is then investigated and decision forrests are found to improve the results.","_input_hash":-1496861163,"_task_hash":595301050,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"impact","start":4,"end":10,"id":1},{"text":"of","start":11,"end":13,"id":2},{"text":"missing","start":14,"end":21,"id":3},{"text":"data","start":22,"end":26,"id":4},{"text":"is","start":27,"end":29,"id":5},{"text":"then","start":30,"end":34,"id":6},{"text":"investigated","start":35,"end":47,"id":7},{"text":"and","start":48,"end":51,"id":8},{"text":"decision","start":52,"end":60,"id":9},{"text":"forrests","start":61,"end":69,"id":10},{"text":"are","start":70,"end":73,"id":11},{"text":"found","start":74,"end":79,"id":12},{"text":"to","start":80,"end":82,"id":13},{"text":"improve","start":83,"end":90,"id":14},{"text":"the","start":91,"end":94,"id":15},{"text":"results","start":95,"end":102,"id":16},{"text":".","start":102,"end":103,"id":17}],"spans":[{"start":52,"end":69,"token_start":9,"token_end":10,"label":"ALGO","answer":"accept"}],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"This paper re-examines the issues in two parts.","_input_hash":-2035294479,"_task_hash":965280369,"tokens":[{"text":"This","start":0,"end":4,"id":0},{"text":"paper","start":5,"end":10,"id":1},{"text":"re","start":11,"end":13,"id":2},{"text":"-","start":13,"end":14,"id":3},{"text":"examines","start":14,"end":22,"id":4},{"text":"the","start":23,"end":26,"id":5},{"text":"issues","start":27,"end":33,"id":6},{"text":"in","start":34,"end":36,"id":7},{"text":"two","start":37,"end":40,"id":8},{"text":"parts","start":41,"end":46,"id":9},{"text":".","start":46,"end":47,"id":10}],"spans":[],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"Based on the topology of the network, we propose an approximate statistical graphical model and distribute the computation of PCA.","_input_hash":1813334575,"_task_hash":1493916161,"tokens":[{"text":"Based","start":0,"end":5,"id":0},{"text":"on","start":6,"end":8,"id":1},{"text":"the","start":9,"end":12,"id":2},{"text":"topology","start":13,"end":21,"id":3},{"text":"of","start":22,"end":24,"id":4},{"text":"the","start":25,"end":28,"id":5},{"text":"network","start":29,"end":36,"id":6},{"text":",","start":36,"end":37,"id":7},{"text":"we","start":38,"end":40,"id":8},{"text":"propose","start":41,"end":48,"id":9},{"text":"an","start":49,"end":51,"id":10},{"text":"approximate","start":52,"end":63,"id":11},{"text":"statistical","start":64,"end":75,"id":12},{"text":"graphical","start":76,"end":85,"id":13},{"text":"model","start":86,"end":91,"id":14},{"text":"and","start":92,"end":95,"id":15},{"text":"distribute","start":96,"end":106,"id":16},{"text":"the","start":107,"end":110,"id":17},{"text":"computation","start":111,"end":122,"id":18},{"text":"of","start":123,"end":125,"id":19},{"text":"PCA","start":126,"end":129,"id":20},{"text":".","start":129,"end":130,"id":21}],"spans":[{"start":126,"end":129,"token_start":20,"token_end":20,"label":"ALGO","answer":"accept"}],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"We exploit the prior information in these models in order to distribute its computation.","_input_hash":1119992861,"_task_hash":333611047,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"exploit","start":3,"end":10,"id":1},{"text":"the","start":11,"end":14,"id":2},{"text":"prior","start":15,"end":20,"id":3},{"text":"information","start":21,"end":32,"id":4},{"text":"in","start":33,"end":35,"id":5},{"text":"these","start":36,"end":41,"id":6},{"text":"models","start":42,"end":48,"id":7},{"text":"in","start":49,"end":51,"id":8},{"text":"order","start":52,"end":57,"id":9},{"text":"to","start":58,"end":60,"id":10},{"text":"distribute","start":61,"end":71,"id":11},{"text":"its","start":72,"end":75,"id":12},{"text":"computation","start":76,"end":87,"id":13},{"text":".","start":87,"end":88,"id":14}],"spans":[],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"The number of parameters will increase exponentially with the order considered.","_input_hash":539571614,"_task_hash":-552580186,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"number","start":4,"end":10,"id":1},{"text":"of","start":11,"end":13,"id":2},{"text":"parameters","start":14,"end":24,"id":3},{"text":"will","start":25,"end":29,"id":4},{"text":"increase","start":30,"end":38,"id":5},{"text":"exponentially","start":39,"end":52,"id":6},{"text":"with","start":53,"end":57,"id":7},{"text":"the","start":58,"end":61,"id":8},{"text":"order","start":62,"end":67,"id":9},{"text":"considered","start":68,"end":78,"id":10},{"text":".","start":78,"end":79,"id":11}],"spans":[],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"We describe and study an alternative selection scheme based on relative bounds between estimators, and present a two step localization technique which can handle the selection of a parametric model from a family of those.","_input_hash":890575210,"_task_hash":-548643541,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"describe","start":3,"end":11,"id":1},{"text":"and","start":12,"end":15,"id":2},{"text":"study","start":16,"end":21,"id":3},{"text":"an","start":22,"end":24,"id":4},{"text":"alternative","start":25,"end":36,"id":5},{"text":"selection","start":37,"end":46,"id":6},{"text":"scheme","start":47,"end":53,"id":7},{"text":"based","start":54,"end":59,"id":8},{"text":"on","start":60,"end":62,"id":9},{"text":"relative","start":63,"end":71,"id":10},{"text":"bounds","start":72,"end":78,"id":11},{"text":"between","start":79,"end":86,"id":12},{"text":"estimators","start":87,"end":97,"id":13},{"text":",","start":97,"end":98,"id":14},{"text":"and","start":99,"end":102,"id":15},{"text":"present","start":103,"end":110,"id":16},{"text":"a","start":111,"end":112,"id":17},{"text":"two","start":113,"end":116,"id":18},{"text":"step","start":117,"end":121,"id":19},{"text":"localization","start":122,"end":134,"id":20},{"text":"technique","start":135,"end":144,"id":21},{"text":"which","start":145,"end":150,"id":22},{"text":"can","start":151,"end":154,"id":23},{"text":"handle","start":155,"end":161,"id":24},{"text":"the","start":162,"end":165,"id":25},{"text":"selection","start":166,"end":175,"id":26},{"text":"of","start":176,"end":178,"id":27},{"text":"a","start":179,"end":180,"id":28},{"text":"parametric","start":181,"end":191,"id":29},{"text":"model","start":192,"end":197,"id":30},{"text":"from","start":198,"end":202,"id":31},{"text":"a","start":203,"end":204,"id":32},{"text":"family","start":205,"end":211,"id":33},{"text":"of","start":212,"end":214,"id":34},{"text":"those","start":215,"end":220,"id":35},{"text":".","start":220,"end":221,"id":36}],"spans":[],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"We introduce a new general formulation of simulated annealing which allows one to guarantee finite-time performance in the optimization of functions of continuous variables.","_input_hash":2099441561,"_task_hash":930732446,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"introduce","start":3,"end":12,"id":1},{"text":"a","start":13,"end":14,"id":2},{"text":"new","start":15,"end":18,"id":3},{"text":"general","start":19,"end":26,"id":4},{"text":"formulation","start":27,"end":38,"id":5},{"text":"of","start":39,"end":41,"id":6},{"text":"simulated","start":42,"end":51,"id":7},{"text":"annealing","start":52,"end":61,"id":8},{"text":"which","start":62,"end":67,"id":9},{"text":"allows","start":68,"end":74,"id":10},{"text":"one","start":75,"end":78,"id":11},{"text":"to","start":79,"end":81,"id":12},{"text":"guarantee","start":82,"end":91,"id":13},{"text":"finite","start":92,"end":98,"id":14},{"text":"-","start":98,"end":99,"id":15},{"text":"time","start":99,"end":103,"id":16},{"text":"performance","start":104,"end":115,"id":17},{"text":"in","start":116,"end":118,"id":18},{"text":"the","start":119,"end":122,"id":19},{"text":"optimization","start":123,"end":135,"id":20},{"text":"of","start":136,"end":138,"id":21},{"text":"functions","start":139,"end":148,"id":22},{"text":"of","start":149,"end":151,"id":23},{"text":"continuous","start":152,"end":162,"id":24},{"text":"variables","start":163,"end":172,"id":25},{"text":".","start":172,"end":173,"id":26}],"spans":[{"token_start":7,"token_end":8,"start":42,"end":61,"text":"simulated annealing","label":"ALGO","source":"./algo_model5","input_hash":2099441561,"answer":"accept"}],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"In particular, by means of a detailed example, we provide some characterization of the properties of ERG models, and, in particular, of certain behaviors of ERG models known as degeneracy.","_input_hash":1206154583,"_task_hash":-1997537402,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"particular","start":3,"end":13,"id":1},{"text":",","start":13,"end":14,"id":2},{"text":"by","start":15,"end":17,"id":3},{"text":"means","start":18,"end":23,"id":4},{"text":"of","start":24,"end":26,"id":5},{"text":"a","start":27,"end":28,"id":6},{"text":"detailed","start":29,"end":37,"id":7},{"text":"example","start":38,"end":45,"id":8},{"text":",","start":45,"end":46,"id":9},{"text":"we","start":47,"end":49,"id":10},{"text":"provide","start":50,"end":57,"id":11},{"text":"some","start":58,"end":62,"id":12},{"text":"characterization","start":63,"end":79,"id":13},{"text":"of","start":80,"end":82,"id":14},{"text":"the","start":83,"end":86,"id":15},{"text":"properties","start":87,"end":97,"id":16},{"text":"of","start":98,"end":100,"id":17},{"text":"ERG","start":101,"end":104,"id":18},{"text":"models","start":105,"end":111,"id":19},{"text":",","start":111,"end":112,"id":20},{"text":"and","start":113,"end":116,"id":21},{"text":",","start":116,"end":117,"id":22},{"text":"in","start":118,"end":120,"id":23},{"text":"particular","start":121,"end":131,"id":24},{"text":",","start":131,"end":132,"id":25},{"text":"of","start":133,"end":135,"id":26},{"text":"certain","start":136,"end":143,"id":27},{"text":"behaviors","start":144,"end":153,"id":28},{"text":"of","start":154,"end":156,"id":29},{"text":"ERG","start":157,"end":160,"id":30},{"text":"models","start":161,"end":167,"id":31},{"text":"known","start":168,"end":173,"id":32},{"text":"as","start":174,"end":176,"id":33},{"text":"degeneracy","start":177,"end":187,"id":34},{"text":".","start":187,"end":188,"id":35}],"spans":[{"start":101,"end":104,"token_start":18,"token_end":18,"label":"ALGO","answer":"accept"},{"start":157,"end":160,"token_start":30,"token_end":30,"label":"ALGO","answer":"accept"}],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"Furthermore, we provide oracle results which yield asymptotic optimality of our estimator for high dimensional but sparse additive models.","_input_hash":529858503,"_task_hash":2136883094,"tokens":[{"text":"Furthermore","start":0,"end":11,"id":0},{"text":",","start":11,"end":12,"id":1},{"text":"we","start":13,"end":15,"id":2},{"text":"provide","start":16,"end":23,"id":3},{"text":"oracle","start":24,"end":30,"id":4},{"text":"results","start":31,"end":38,"id":5},{"text":"which","start":39,"end":44,"id":6},{"text":"yield","start":45,"end":50,"id":7},{"text":"asymptotic","start":51,"end":61,"id":8},{"text":"optimality","start":62,"end":72,"id":9},{"text":"of","start":73,"end":75,"id":10},{"text":"our","start":76,"end":79,"id":11},{"text":"estimator","start":80,"end":89,"id":12},{"text":"for","start":90,"end":93,"id":13},{"text":"high","start":94,"end":98,"id":14},{"text":"dimensional","start":99,"end":110,"id":15},{"text":"but","start":111,"end":114,"id":16},{"text":"sparse","start":115,"end":121,"id":17},{"text":"additive","start":122,"end":130,"id":18},{"text":"models","start":131,"end":137,"id":19},{"text":".","start":137,"end":138,"id":20}],"spans":[{"token_start":0,"token_end":1,"start":0,"end":12,"text":"Furthermore,","label":"ALGO","source":"./algo_model5","input_hash":529858503,"answer":"accept"},{"token_start":2,"token_end":3,"start":13,"end":23,"text":"we provide","label":"ALGO","source":"./algo_model5","input_hash":529858503,"answer":"accept"},{"token_start":4,"token_end":5,"start":24,"end":38,"text":"oracle results","label":"ALGO","source":"./algo_model5","input_hash":529858503,"answer":"accept"},{"token_start":6,"token_end":7,"start":39,"end":50,"text":"which yield","label":"ALGO","source":"./algo_model5","input_hash":529858503,"answer":"accept"},{"token_start":8,"token_end":9,"start":51,"end":72,"text":"asymptotic optimality","label":"ALGO","source":"./algo_model5","input_hash":529858503,"answer":"accept"},{"token_start":10,"token_end":11,"start":73,"end":79,"text":"of our","label":"ALGO","source":"./algo_model5","input_hash":529858503,"answer":"accept"},{"token_start":12,"token_end":13,"start":80,"end":93,"text":"estimator for","label":"ALGO","source":"./algo_model5","input_hash":529858503,"answer":"accept"},{"token_start":14,"token_end":15,"start":94,"end":110,"text":"high dimensional","label":"ALGO","source":"./algo_model5","input_hash":529858503,"answer":"accept"},{"token_start":17,"token_end":18,"start":115,"end":130,"text":"sparse additive","label":"ALGO","source":"./algo_model5","input_hash":529858503,"answer":"accept"},{"token_start":19,"token_end":19,"start":131,"end":137,"text":"models","label":"ALGO","source":"./algo_model5","input_hash":529858503,"answer":"accept"},{"token_start":20,"token_end":20,"start":137,"end":138,"text":".","label":"ALGO","source":"./algo_model5","input_hash":529858503,"answer":"accept"}],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"This article introduces both a new algorithm for reconstructing epsilon-machines from data, as well as the decisional states.","_input_hash":-318982839,"_task_hash":307882630,"tokens":[{"text":"This","start":0,"end":4,"id":0},{"text":"article","start":5,"end":12,"id":1},{"text":"introduces","start":13,"end":23,"id":2},{"text":"both","start":24,"end":28,"id":3},{"text":"a","start":29,"end":30,"id":4},{"text":"new","start":31,"end":34,"id":5},{"text":"algorithm","start":35,"end":44,"id":6},{"text":"for","start":45,"end":48,"id":7},{"text":"reconstructing","start":49,"end":63,"id":8},{"text":"epsilon","start":64,"end":71,"id":9},{"text":"-","start":71,"end":72,"id":10},{"text":"machines","start":72,"end":80,"id":11},{"text":"from","start":81,"end":85,"id":12},{"text":"data","start":86,"end":90,"id":13},{"text":",","start":90,"end":91,"id":14},{"text":"as","start":92,"end":94,"id":15},{"text":"well","start":95,"end":99,"id":16},{"text":"as","start":100,"end":102,"id":17},{"text":"the","start":103,"end":106,"id":18},{"text":"decisional","start":107,"end":117,"id":19},{"text":"states","start":118,"end":124,"id":20},{"text":".","start":124,"end":125,"id":21}],"spans":[{"token_start":9,"token_end":11,"start":64,"end":80,"text":"epsilon-machines","label":"ALGO","source":"./algo_model5","input_hash":-318982839,"answer":"accept"}],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"The algorithm can account for multiple classes as well as the semi-supervised setting.","_input_hash":-1517052669,"_task_hash":-985925882,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"algorithm","start":4,"end":13,"id":1},{"text":"can","start":14,"end":17,"id":2},{"text":"account","start":18,"end":25,"id":3},{"text":"for","start":26,"end":29,"id":4},{"text":"multiple","start":30,"end":38,"id":5},{"text":"classes","start":39,"end":46,"id":6},{"text":"as","start":47,"end":49,"id":7},{"text":"well","start":50,"end":54,"id":8},{"text":"as","start":55,"end":57,"id":9},{"text":"the","start":58,"end":61,"id":10},{"text":"semi","start":62,"end":66,"id":11},{"text":"-","start":66,"end":67,"id":12},{"text":"supervised","start":67,"end":77,"id":13},{"text":"setting","start":78,"end":85,"id":14},{"text":".","start":85,"end":86,"id":15}],"spans":[],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"The kernel density estimation based approaches are of interest due to the low time complexity of either O(n) or O(n*log(n)) for constructing a classifier, where n is the number of sampling instances.","_input_hash":-1025131444,"_task_hash":-2069335017,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"kernel","start":4,"end":10,"id":1},{"text":"density","start":11,"end":18,"id":2},{"text":"estimation","start":19,"end":29,"id":3},{"text":"based","start":30,"end":35,"id":4},{"text":"approaches","start":36,"end":46,"id":5},{"text":"are","start":47,"end":50,"id":6},{"text":"of","start":51,"end":53,"id":7},{"text":"interest","start":54,"end":62,"id":8},{"text":"due","start":63,"end":66,"id":9},{"text":"to","start":67,"end":69,"id":10},{"text":"the","start":70,"end":73,"id":11},{"text":"low","start":74,"end":77,"id":12},{"text":"time","start":78,"end":82,"id":13},{"text":"complexity","start":83,"end":93,"id":14},{"text":"of","start":94,"end":96,"id":15},{"text":"either","start":97,"end":103,"id":16},{"text":"O(n","start":104,"end":107,"id":17},{"text":")","start":107,"end":108,"id":18},{"text":"or","start":109,"end":111,"id":19},{"text":"O(n*log(n","start":112,"end":121,"id":20},{"text":")","start":121,"end":122,"id":21},{"text":")","start":122,"end":123,"id":22},{"text":"for","start":124,"end":127,"id":23},{"text":"constructing","start":128,"end":140,"id":24},{"text":"a","start":141,"end":142,"id":25},{"text":"classifier","start":143,"end":153,"id":26},{"text":",","start":153,"end":154,"id":27},{"text":"where","start":155,"end":160,"id":28},{"text":"n","start":161,"end":162,"id":29},{"text":"is","start":163,"end":165,"id":30},{"text":"the","start":166,"end":169,"id":31},{"text":"number","start":170,"end":176,"id":32},{"text":"of","start":177,"end":179,"id":33},{"text":"sampling","start":180,"end":188,"id":34},{"text":"instances","start":189,"end":198,"id":35},{"text":".","start":198,"end":199,"id":36}],"spans":[],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"Min-cut clustering, based on minimizing one of two heuristic cost-functions proposed by Shi and Malik, has spawned tremendous research, both analytic and algorithmic, in the graph partitioning and image segmentation communities over the last decade.","_input_hash":-2126837843,"_task_hash":18091559,"tokens":[{"text":"Min","start":0,"end":3,"id":0},{"text":"-","start":3,"end":4,"id":1},{"text":"cut","start":4,"end":7,"id":2},{"text":"clustering","start":8,"end":18,"id":3},{"text":",","start":18,"end":19,"id":4},{"text":"based","start":20,"end":25,"id":5},{"text":"on","start":26,"end":28,"id":6},{"text":"minimizing","start":29,"end":39,"id":7},{"text":"one","start":40,"end":43,"id":8},{"text":"of","start":44,"end":46,"id":9},{"text":"two","start":47,"end":50,"id":10},{"text":"heuristic","start":51,"end":60,"id":11},{"text":"cost","start":61,"end":65,"id":12},{"text":"-","start":65,"end":66,"id":13},{"text":"functions","start":66,"end":75,"id":14},{"text":"proposed","start":76,"end":84,"id":15},{"text":"by","start":85,"end":87,"id":16},{"text":"Shi","start":88,"end":91,"id":17},{"text":"and","start":92,"end":95,"id":18},{"text":"Malik","start":96,"end":101,"id":19},{"text":",","start":101,"end":102,"id":20},{"text":"has","start":103,"end":106,"id":21},{"text":"spawned","start":107,"end":114,"id":22},{"text":"tremendous","start":115,"end":125,"id":23},{"text":"research","start":126,"end":134,"id":24},{"text":",","start":134,"end":135,"id":25},{"text":"both","start":136,"end":140,"id":26},{"text":"analytic","start":141,"end":149,"id":27},{"text":"and","start":150,"end":153,"id":28},{"text":"algorithmic","start":154,"end":165,"id":29},{"text":",","start":165,"end":166,"id":30},{"text":"in","start":167,"end":169,"id":31},{"text":"the","start":170,"end":173,"id":32},{"text":"graph","start":174,"end":179,"id":33},{"text":"partitioning","start":180,"end":192,"id":34},{"text":"and","start":193,"end":196,"id":35},{"text":"image","start":197,"end":202,"id":36},{"text":"segmentation","start":203,"end":215,"id":37},{"text":"communities","start":216,"end":227,"id":38},{"text":"over","start":228,"end":232,"id":39},{"text":"the","start":233,"end":236,"id":40},{"text":"last","start":237,"end":241,"id":41},{"text":"decade","start":242,"end":248,"id":42},{"text":".","start":248,"end":249,"id":43}],"spans":[{"token_start":0,"token_end":3,"start":0,"end":18,"text":"Min-cut clustering","label":"ALGO","source":"./algo_model5","input_hash":-2126837843,"answer":"accept"}],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"Through the years, clinicians have determined combinations of different fluorescent markers which generate relatively known expression patterns for specific subtypes of leukemia and lymphoma -- cancers of the hematopoietic system.","_input_hash":-770091940,"_task_hash":2008927478,"tokens":[{"text":"Through","start":0,"end":7,"id":0},{"text":"the","start":8,"end":11,"id":1},{"text":"years","start":12,"end":17,"id":2},{"text":",","start":17,"end":18,"id":3},{"text":"clinicians","start":19,"end":29,"id":4},{"text":"have","start":30,"end":34,"id":5},{"text":"determined","start":35,"end":45,"id":6},{"text":"combinations","start":46,"end":58,"id":7},{"text":"of","start":59,"end":61,"id":8},{"text":"different","start":62,"end":71,"id":9},{"text":"fluorescent","start":72,"end":83,"id":10},{"text":"markers","start":84,"end":91,"id":11},{"text":"which","start":92,"end":97,"id":12},{"text":"generate","start":98,"end":106,"id":13},{"text":"relatively","start":107,"end":117,"id":14},{"text":"known","start":118,"end":123,"id":15},{"text":"expression","start":124,"end":134,"id":16},{"text":"patterns","start":135,"end":143,"id":17},{"text":"for","start":144,"end":147,"id":18},{"text":"specific","start":148,"end":156,"id":19},{"text":"subtypes","start":157,"end":165,"id":20},{"text":"of","start":166,"end":168,"id":21},{"text":"leukemia","start":169,"end":177,"id":22},{"text":"and","start":178,"end":181,"id":23},{"text":"lymphoma","start":182,"end":190,"id":24},{"text":"--","start":191,"end":193,"id":25},{"text":"cancers","start":194,"end":201,"id":26},{"text":"of","start":202,"end":204,"id":27},{"text":"the","start":205,"end":208,"id":28},{"text":"hematopoietic","start":209,"end":222,"id":29},{"text":"system","start":223,"end":229,"id":30},{"text":".","start":229,"end":230,"id":31}],"spans":[],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"By only viewing a series of 2-dimensional projections, the high-dimensional nature of the data is rarely exploited.","_input_hash":608820998,"_task_hash":452229493,"tokens":[{"text":"By","start":0,"end":2,"id":0},{"text":"only","start":3,"end":7,"id":1},{"text":"viewing","start":8,"end":15,"id":2},{"text":"a","start":16,"end":17,"id":3},{"text":"series","start":18,"end":24,"id":4},{"text":"of","start":25,"end":27,"id":5},{"text":"2-dimensional","start":28,"end":41,"id":6},{"text":"projections","start":42,"end":53,"id":7},{"text":",","start":53,"end":54,"id":8},{"text":"the","start":55,"end":58,"id":9},{"text":"high","start":59,"end":63,"id":10},{"text":"-","start":63,"end":64,"id":11},{"text":"dimensional","start":64,"end":75,"id":12},{"text":"nature","start":76,"end":82,"id":13},{"text":"of","start":83,"end":85,"id":14},{"text":"the","start":86,"end":89,"id":15},{"text":"data","start":90,"end":94,"id":16},{"text":"is","start":95,"end":97,"id":17},{"text":"rarely","start":98,"end":104,"id":18},{"text":"exploited","start":105,"end":114,"id":19},{"text":".","start":114,"end":115,"id":20}],"spans":[],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"The problem of supervised classification (or discrimination) with functional data is considered, with a special interest on the popular k-nearest neighbors (k-NN) classifier.","_input_hash":1446338438,"_task_hash":1821250191,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"problem","start":4,"end":11,"id":1},{"text":"of","start":12,"end":14,"id":2},{"text":"supervised","start":15,"end":25,"id":3},{"text":"classification","start":26,"end":40,"id":4},{"text":"(","start":41,"end":42,"id":5},{"text":"or","start":42,"end":44,"id":6},{"text":"discrimination","start":45,"end":59,"id":7},{"text":")","start":59,"end":60,"id":8},{"text":"with","start":61,"end":65,"id":9},{"text":"functional","start":66,"end":76,"id":10},{"text":"data","start":77,"end":81,"id":11},{"text":"is","start":82,"end":84,"id":12},{"text":"considered","start":85,"end":95,"id":13},{"text":",","start":95,"end":96,"id":14},{"text":"with","start":97,"end":101,"id":15},{"text":"a","start":102,"end":103,"id":16},{"text":"special","start":104,"end":111,"id":17},{"text":"interest","start":112,"end":120,"id":18},{"text":"on","start":121,"end":123,"id":19},{"text":"the","start":124,"end":127,"id":20},{"text":"popular","start":128,"end":135,"id":21},{"text":"k","start":136,"end":137,"id":22},{"text":"-","start":137,"end":138,"id":23},{"text":"nearest","start":138,"end":145,"id":24},{"text":"neighbors","start":146,"end":155,"id":25},{"text":"(","start":156,"end":157,"id":26},{"text":"k","start":157,"end":158,"id":27},{"text":"-","start":158,"end":159,"id":28},{"text":"NN","start":159,"end":161,"id":29},{"text":")","start":161,"end":162,"id":30},{"text":"classifier","start":163,"end":173,"id":31},{"text":".","start":173,"end":174,"id":32}],"spans":[{"start":15,"end":40,"token_start":3,"token_end":4,"label":"ALGO","answer":"accept"},{"start":136,"end":155,"token_start":22,"token_end":25,"label":"ALGO","answer":"accept"}],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"We show that within this framework, one can prove a theorem analogous to one of J. Kleinberg, in which one obtains an existence and uniqueness theorem instead of a non-existence result.","_input_hash":-874321344,"_task_hash":-1692011917,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"show","start":3,"end":7,"id":1},{"text":"that","start":8,"end":12,"id":2},{"text":"within","start":13,"end":19,"id":3},{"text":"this","start":20,"end":24,"id":4},{"text":"framework","start":25,"end":34,"id":5},{"text":",","start":34,"end":35,"id":6},{"text":"one","start":36,"end":39,"id":7},{"text":"can","start":40,"end":43,"id":8},{"text":"prove","start":44,"end":49,"id":9},{"text":"a","start":50,"end":51,"id":10},{"text":"theorem","start":52,"end":59,"id":11},{"text":"analogous","start":60,"end":69,"id":12},{"text":"to","start":70,"end":72,"id":13},{"text":"one","start":73,"end":76,"id":14},{"text":"of","start":77,"end":79,"id":15},{"text":"J.","start":80,"end":82,"id":16},{"text":"Kleinberg","start":83,"end":92,"id":17},{"text":",","start":92,"end":93,"id":18},{"text":"in","start":94,"end":96,"id":19},{"text":"which","start":97,"end":102,"id":20},{"text":"one","start":103,"end":106,"id":21},{"text":"obtains","start":107,"end":114,"id":22},{"text":"an","start":115,"end":117,"id":23},{"text":"existence","start":118,"end":127,"id":24},{"text":"and","start":128,"end":131,"id":25},{"text":"uniqueness","start":132,"end":142,"id":26},{"text":"theorem","start":143,"end":150,"id":27},{"text":"instead","start":151,"end":158,"id":28},{"text":"of","start":159,"end":161,"id":29},{"text":"a","start":162,"end":163,"id":30},{"text":"non","start":164,"end":167,"id":31},{"text":"-","start":167,"end":168,"id":32},{"text":"existence","start":168,"end":177,"id":33},{"text":"result","start":178,"end":184,"id":34},{"text":".","start":184,"end":185,"id":35}],"spans":[],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"The embedding function is then determined by solving a semidefinite program which has an interesting connection to the soft-margin linear binary support vector machine classifier.","_input_hash":1743355789,"_task_hash":1071167073,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"embedding","start":4,"end":13,"id":1},{"text":"function","start":14,"end":22,"id":2},{"text":"is","start":23,"end":25,"id":3},{"text":"then","start":26,"end":30,"id":4},{"text":"determined","start":31,"end":41,"id":5},{"text":"by","start":42,"end":44,"id":6},{"text":"solving","start":45,"end":52,"id":7},{"text":"a","start":53,"end":54,"id":8},{"text":"semidefinite","start":55,"end":67,"id":9},{"text":"program","start":68,"end":75,"id":10},{"text":"which","start":76,"end":81,"id":11},{"text":"has","start":82,"end":85,"id":12},{"text":"an","start":86,"end":88,"id":13},{"text":"interesting","start":89,"end":100,"id":14},{"text":"connection","start":101,"end":111,"id":15},{"text":"to","start":112,"end":114,"id":16},{"text":"the","start":115,"end":118,"id":17},{"text":"soft","start":119,"end":123,"id":18},{"text":"-","start":123,"end":124,"id":19},{"text":"margin","start":124,"end":130,"id":20},{"text":"linear","start":131,"end":137,"id":21},{"text":"binary","start":138,"end":144,"id":22},{"text":"support","start":145,"end":152,"id":23},{"text":"vector","start":153,"end":159,"id":24},{"text":"machine","start":160,"end":167,"id":25},{"text":"classifier","start":168,"end":178,"id":26},{"text":".","start":178,"end":179,"id":27}],"spans":[{"token_start":18,"token_end":26,"start":119,"end":178,"text":"soft-margin linear binary support vector machine classifier","label":"ALGO","source":"./algo_model5","input_hash":1743355789,"answer":"accept"}],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"We refer to our method as Information Preserving Component Analysis (IPCA).","_input_hash":-455619717,"_task_hash":-212535663,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"refer","start":3,"end":8,"id":1},{"text":"to","start":9,"end":11,"id":2},{"text":"our","start":12,"end":15,"id":3},{"text":"method","start":16,"end":22,"id":4},{"text":"as","start":23,"end":25,"id":5},{"text":"Information","start":26,"end":37,"id":6},{"text":"Preserving","start":38,"end":48,"id":7},{"text":"Component","start":49,"end":58,"id":8},{"text":"Analysis","start":59,"end":67,"id":9},{"text":"(","start":68,"end":69,"id":10},{"text":"IPCA","start":69,"end":73,"id":11},{"text":")","start":73,"end":74,"id":12},{"text":".","start":74,"end":75,"id":13}],"spans":[{"start":26,"end":67,"token_start":6,"token_end":9,"label":"ALGO","answer":"accept"}],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"We discuss its relevance to maximum likelihood estimation, both from a theoretical and computational standpoint.","_input_hash":-1688515034,"_task_hash":-1378774903,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"discuss","start":3,"end":10,"id":1},{"text":"its","start":11,"end":14,"id":2},{"text":"relevance","start":15,"end":24,"id":3},{"text":"to","start":25,"end":27,"id":4},{"text":"maximum","start":28,"end":35,"id":5},{"text":"likelihood","start":36,"end":46,"id":6},{"text":"estimation","start":47,"end":57,"id":7},{"text":",","start":57,"end":58,"id":8},{"text":"both","start":59,"end":63,"id":9},{"text":"from","start":64,"end":68,"id":10},{"text":"a","start":69,"end":70,"id":11},{"text":"theoretical","start":71,"end":82,"id":12},{"text":"and","start":83,"end":86,"id":13},{"text":"computational","start":87,"end":100,"id":14},{"text":"standpoint","start":101,"end":111,"id":15},{"text":".","start":111,"end":112,"id":16}],"spans":[],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
{"text":"In this report, we derive a non-negative series expansion for the Jensen-Shannon divergence (JSD) between two probability distributions.","_input_hash":-379261663,"_task_hash":-1352715429,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"this","start":3,"end":7,"id":1},{"text":"report","start":8,"end":14,"id":2},{"text":",","start":14,"end":15,"id":3},{"text":"we","start":16,"end":18,"id":4},{"text":"derive","start":19,"end":25,"id":5},{"text":"a","start":26,"end":27,"id":6},{"text":"non","start":28,"end":31,"id":7},{"text":"-","start":31,"end":32,"id":8},{"text":"negative","start":32,"end":40,"id":9},{"text":"series","start":41,"end":47,"id":10},{"text":"expansion","start":48,"end":57,"id":11},{"text":"for","start":58,"end":61,"id":12},{"text":"the","start":62,"end":65,"id":13},{"text":"Jensen","start":66,"end":72,"id":14},{"text":"-","start":72,"end":73,"id":15},{"text":"Shannon","start":73,"end":80,"id":16},{"text":"divergence","start":81,"end":91,"id":17},{"text":"(","start":92,"end":93,"id":18},{"text":"JSD","start":93,"end":96,"id":19},{"text":")","start":96,"end":97,"id":20},{"text":"between","start":98,"end":105,"id":21},{"text":"two","start":106,"end":109,"id":22},{"text":"probability","start":110,"end":121,"id":23},{"text":"distributions","start":122,"end":135,"id":24},{"text":".","start":135,"end":136,"id":25}],"spans":[],"_session_id":null,"_view_id":"ner_manual","answer":"accept"}
