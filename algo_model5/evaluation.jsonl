{"text":"Information-maximization clustering learns a probabilistic classifier in an unsupervised manner so that mutual information between feature vectors and cluster assignments is maximized.","_input_hash":-1804904464,"_task_hash":-840624603,"tokens":[{"text":"Information","start":0,"end":11,"id":0},{"text":"-","start":11,"end":12,"id":1},{"text":"maximization","start":12,"end":24,"id":2},{"text":"clustering","start":25,"end":35,"id":3},{"text":"learns","start":36,"end":42,"id":4},{"text":"a","start":43,"end":44,"id":5},{"text":"probabilistic","start":45,"end":58,"id":6},{"text":"classifier","start":59,"end":69,"id":7},{"text":"in","start":70,"end":72,"id":8},{"text":"an","start":73,"end":75,"id":9},{"text":"unsupervised","start":76,"end":88,"id":10},{"text":"manner","start":89,"end":95,"id":11},{"text":"so","start":96,"end":98,"id":12},{"text":"that","start":99,"end":103,"id":13},{"text":"mutual","start":104,"end":110,"id":14},{"text":"information","start":111,"end":122,"id":15},{"text":"between","start":123,"end":130,"id":16},{"text":"feature","start":131,"end":138,"id":17},{"text":"vectors","start":139,"end":146,"id":18},{"text":"and","start":147,"end":150,"id":19},{"text":"cluster","start":151,"end":158,"id":20},{"text":"assignments","start":159,"end":170,"id":21},{"text":"is","start":171,"end":173,"id":22},{"text":"maximized","start":174,"end":183,"id":23},{"text":".","start":183,"end":184,"id":24}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":0,"end":35,"token_start":0,"token_end":3,"label":"ALGO","answer":"accept"},{"start":45,"end":69,"token_start":6,"token_end":7,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"A notable advantage of this approach is that it only involves continuous optimization of model parameters, which is substantially easier to solve than discrete optimization of cluster assignments.","_input_hash":-1301216252,"_task_hash":-1815590578,"tokens":[{"text":"A","start":0,"end":1,"id":0},{"text":"notable","start":2,"end":9,"id":1},{"text":"advantage","start":10,"end":19,"id":2},{"text":"of","start":20,"end":22,"id":3},{"text":"this","start":23,"end":27,"id":4},{"text":"approach","start":28,"end":36,"id":5},{"text":"is","start":37,"end":39,"id":6},{"text":"that","start":40,"end":44,"id":7},{"text":"it","start":45,"end":47,"id":8},{"text":"only","start":48,"end":52,"id":9},{"text":"involves","start":53,"end":61,"id":10},{"text":"continuous","start":62,"end":72,"id":11},{"text":"optimization","start":73,"end":85,"id":12},{"text":"of","start":86,"end":88,"id":13},{"text":"model","start":89,"end":94,"id":14},{"text":"parameters","start":95,"end":105,"id":15},{"text":",","start":105,"end":106,"id":16},{"text":"which","start":107,"end":112,"id":17},{"text":"is","start":113,"end":115,"id":18},{"text":"substantially","start":116,"end":129,"id":19},{"text":"easier","start":130,"end":136,"id":20},{"text":"to","start":137,"end":139,"id":21},{"text":"solve","start":140,"end":145,"id":22},{"text":"than","start":146,"end":150,"id":23},{"text":"discrete","start":151,"end":159,"id":24},{"text":"optimization","start":160,"end":172,"id":25},{"text":"of","start":173,"end":175,"id":26},{"text":"cluster","start":176,"end":183,"id":27},{"text":"assignments","start":184,"end":195,"id":28},{"text":".","start":195,"end":196,"id":29}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"However, existing methods still involve non-convex optimization problems, and therefore finding a good local optimal solution is not straightforward in practice.","_input_hash":-982290883,"_task_hash":-1609333353,"tokens":[{"text":"However","start":0,"end":7,"id":0},{"text":",","start":7,"end":8,"id":1},{"text":"existing","start":9,"end":17,"id":2},{"text":"methods","start":18,"end":25,"id":3},{"text":"still","start":26,"end":31,"id":4},{"text":"involve","start":32,"end":39,"id":5},{"text":"non","start":40,"end":43,"id":6},{"text":"-","start":43,"end":44,"id":7},{"text":"convex","start":44,"end":50,"id":8},{"text":"optimization","start":51,"end":63,"id":9},{"text":"problems","start":64,"end":72,"id":10},{"text":",","start":72,"end":73,"id":11},{"text":"and","start":74,"end":77,"id":12},{"text":"therefore","start":78,"end":87,"id":13},{"text":"finding","start":88,"end":95,"id":14},{"text":"a","start":96,"end":97,"id":15},{"text":"good","start":98,"end":102,"id":16},{"text":"local","start":103,"end":108,"id":17},{"text":"optimal","start":109,"end":116,"id":18},{"text":"solution","start":117,"end":125,"id":19},{"text":"is","start":126,"end":128,"id":20},{"text":"not","start":129,"end":132,"id":21},{"text":"straightforward","start":133,"end":148,"id":22},{"text":"in","start":149,"end":151,"id":23},{"text":"practice","start":152,"end":160,"id":24},{"text":".","start":160,"end":161,"id":25}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"In this paper, we propose an alternative information-maximization clustering method based on a squared-loss variant of mutual information.","_input_hash":-267030141,"_task_hash":1450967886,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"this","start":3,"end":7,"id":1},{"text":"paper","start":8,"end":13,"id":2},{"text":",","start":13,"end":14,"id":3},{"text":"we","start":15,"end":17,"id":4},{"text":"propose","start":18,"end":25,"id":5},{"text":"an","start":26,"end":28,"id":6},{"text":"alternative","start":29,"end":40,"id":7},{"text":"information","start":41,"end":52,"id":8},{"text":"-","start":52,"end":53,"id":9},{"text":"maximization","start":53,"end":65,"id":10},{"text":"clustering","start":66,"end":76,"id":11},{"text":"method","start":77,"end":83,"id":12},{"text":"based","start":84,"end":89,"id":13},{"text":"on","start":90,"end":92,"id":14},{"text":"a","start":93,"end":94,"id":15},{"text":"squared","start":95,"end":102,"id":16},{"text":"-","start":102,"end":103,"id":17},{"text":"loss","start":103,"end":107,"id":18},{"text":"variant","start":108,"end":115,"id":19},{"text":"of","start":116,"end":118,"id":20},{"text":"mutual","start":119,"end":125,"id":21},{"text":"information","start":126,"end":137,"id":22},{"text":".","start":137,"end":138,"id":23}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":41,"end":76,"token_start":8,"token_end":11,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"This novel approach gives a clustering solution analytically in a computationally efficient way via kernel eigenvalue decomposition.","_input_hash":-1597765672,"_task_hash":1299557727,"tokens":[{"text":"This","start":0,"end":4,"id":0},{"text":"novel","start":5,"end":10,"id":1},{"text":"approach","start":11,"end":19,"id":2},{"text":"gives","start":20,"end":25,"id":3},{"text":"a","start":26,"end":27,"id":4},{"text":"clustering","start":28,"end":38,"id":5},{"text":"solution","start":39,"end":47,"id":6},{"text":"analytically","start":48,"end":60,"id":7},{"text":"in","start":61,"end":63,"id":8},{"text":"a","start":64,"end":65,"id":9},{"text":"computationally","start":66,"end":81,"id":10},{"text":"efficient","start":82,"end":91,"id":11},{"text":"way","start":92,"end":95,"id":12},{"text":"via","start":96,"end":99,"id":13},{"text":"kernel","start":100,"end":106,"id":14},{"text":"eigenvalue","start":107,"end":117,"id":15},{"text":"decomposition","start":118,"end":131,"id":16},{"text":".","start":131,"end":132,"id":17}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Furthermore, we provide a practical model selection procedure that allows us to objectively optimize tuning parameters included in the kernel function.","_input_hash":-117988726,"_task_hash":-284549061,"tokens":[{"text":"Furthermore","start":0,"end":11,"id":0},{"text":",","start":11,"end":12,"id":1},{"text":"we","start":13,"end":15,"id":2},{"text":"provide","start":16,"end":23,"id":3},{"text":"a","start":24,"end":25,"id":4},{"text":"practical","start":26,"end":35,"id":5},{"text":"model","start":36,"end":41,"id":6},{"text":"selection","start":42,"end":51,"id":7},{"text":"procedure","start":52,"end":61,"id":8},{"text":"that","start":62,"end":66,"id":9},{"text":"allows","start":67,"end":73,"id":10},{"text":"us","start":74,"end":76,"id":11},{"text":"to","start":77,"end":79,"id":12},{"text":"objectively","start":80,"end":91,"id":13},{"text":"optimize","start":92,"end":100,"id":14},{"text":"tuning","start":101,"end":107,"id":15},{"text":"parameters","start":108,"end":118,"id":16},{"text":"included","start":119,"end":127,"id":17},{"text":"in","start":128,"end":130,"id":18},{"text":"the","start":131,"end":134,"id":19},{"text":"kernel","start":135,"end":141,"id":20},{"text":"function","start":142,"end":150,"id":21},{"text":".","start":150,"end":151,"id":22}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Through experiments, we demonstrate the usefulness of the proposed approach.","_input_hash":936175702,"_task_hash":-1717843253,"tokens":[{"text":"Through","start":0,"end":7,"id":0},{"text":"experiments","start":8,"end":19,"id":1},{"text":",","start":19,"end":20,"id":2},{"text":"we","start":21,"end":23,"id":3},{"text":"demonstrate","start":24,"end":35,"id":4},{"text":"the","start":36,"end":39,"id":5},{"text":"usefulness","start":40,"end":50,"id":6},{"text":"of","start":51,"end":53,"id":7},{"text":"the","start":54,"end":57,"id":8},{"text":"proposed","start":58,"end":66,"id":9},{"text":"approach","start":67,"end":75,"id":10},{"text":".","start":75,"end":76,"id":11}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We propose a new sparsity-smoothness penalty for high-dimensional generalized additive models.","_input_hash":1320253224,"_task_hash":1325741529,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"propose","start":3,"end":10,"id":1},{"text":"a","start":11,"end":12,"id":2},{"text":"new","start":13,"end":16,"id":3},{"text":"sparsity","start":17,"end":25,"id":4},{"text":"-","start":25,"end":26,"id":5},{"text":"smoothness","start":26,"end":36,"id":6},{"text":"penalty","start":37,"end":44,"id":7},{"text":"for","start":45,"end":48,"id":8},{"text":"high","start":49,"end":53,"id":9},{"text":"-","start":53,"end":54,"id":10},{"text":"dimensional","start":54,"end":65,"id":11},{"text":"generalized","start":66,"end":77,"id":12},{"text":"additive","start":78,"end":86,"id":13},{"text":"models","start":87,"end":93,"id":14},{"text":".","start":93,"end":94,"id":15}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"reject"}
{"text":"The combination of sparsity and smoothness is crucial for mathematical theory as well as performance for finite-sample data.","_input_hash":161615895,"_task_hash":-1344135724,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"combination","start":4,"end":15,"id":1},{"text":"of","start":16,"end":18,"id":2},{"text":"sparsity","start":19,"end":27,"id":3},{"text":"and","start":28,"end":31,"id":4},{"text":"smoothness","start":32,"end":42,"id":5},{"text":"is","start":43,"end":45,"id":6},{"text":"crucial","start":46,"end":53,"id":7},{"text":"for","start":54,"end":57,"id":8},{"text":"mathematical","start":58,"end":70,"id":9},{"text":"theory","start":71,"end":77,"id":10},{"text":"as","start":78,"end":80,"id":11},{"text":"well","start":81,"end":85,"id":12},{"text":"as","start":86,"end":88,"id":13},{"text":"performance","start":89,"end":100,"id":14},{"text":"for","start":101,"end":104,"id":15},{"text":"finite","start":105,"end":111,"id":16},{"text":"-","start":111,"end":112,"id":17},{"text":"sample","start":112,"end":118,"id":18},{"text":"data","start":119,"end":123,"id":19},{"text":".","start":123,"end":124,"id":20}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"reject"}
{"text":"We present a computationally efficient algorithm, with provable numerical convergence properties, for optimizing the penalized likelihood.","_input_hash":-1310496817,"_task_hash":255031727,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"present","start":3,"end":10,"id":1},{"text":"a","start":11,"end":12,"id":2},{"text":"computationally","start":13,"end":28,"id":3},{"text":"efficient","start":29,"end":38,"id":4},{"text":"algorithm","start":39,"end":48,"id":5},{"text":",","start":48,"end":49,"id":6},{"text":"with","start":50,"end":54,"id":7},{"text":"provable","start":55,"end":63,"id":8},{"text":"numerical","start":64,"end":73,"id":9},{"text":"convergence","start":74,"end":85,"id":10},{"text":"properties","start":86,"end":96,"id":11},{"text":",","start":96,"end":97,"id":12},{"text":"for","start":98,"end":101,"id":13},{"text":"optimizing","start":102,"end":112,"id":14},{"text":"the","start":113,"end":116,"id":15},{"text":"penalized","start":117,"end":126,"id":16},{"text":"likelihood","start":127,"end":137,"id":17},{"text":".","start":137,"end":138,"id":18}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":13,"end":38,"token_start":3,"token_end":4,"label":"ALGO","answer":"reject"}],"answer":"reject"}
{"text":"Furthermore, we provide oracle results which yield asymptotic optimality of our estimator for high dimensional but sparse additive models.","_input_hash":529858503,"_task_hash":-2082599448,"tokens":[{"text":"Furthermore","start":0,"end":11,"id":0},{"text":",","start":11,"end":12,"id":1},{"text":"we","start":13,"end":15,"id":2},{"text":"provide","start":16,"end":23,"id":3},{"text":"oracle","start":24,"end":30,"id":4},{"text":"results","start":31,"end":38,"id":5},{"text":"which","start":39,"end":44,"id":6},{"text":"yield","start":45,"end":50,"id":7},{"text":"asymptotic","start":51,"end":61,"id":8},{"text":"optimality","start":62,"end":72,"id":9},{"text":"of","start":73,"end":75,"id":10},{"text":"our","start":76,"end":79,"id":11},{"text":"estimator","start":80,"end":89,"id":12},{"text":"for","start":90,"end":93,"id":13},{"text":"high","start":94,"end":98,"id":14},{"text":"dimensional","start":99,"end":110,"id":15},{"text":"but","start":111,"end":114,"id":16},{"text":"sparse","start":115,"end":121,"id":17},{"text":"additive","start":122,"end":130,"id":18},{"text":"models","start":131,"end":137,"id":19},{"text":".","start":137,"end":138,"id":20}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":0,"end":79,"token_start":0,"token_end":11,"label":"ALGO","answer":"reject"}],"answer":"reject"}
{"text":"Finally, an adaptive version of our sparsity-smoothness penalized approach yields large additional performance gains.","_input_hash":835233476,"_task_hash":-1681976132,"tokens":[{"text":"Finally","start":0,"end":7,"id":0},{"text":",","start":7,"end":8,"id":1},{"text":"an","start":9,"end":11,"id":2},{"text":"adaptive","start":12,"end":20,"id":3},{"text":"version","start":21,"end":28,"id":4},{"text":"of","start":29,"end":31,"id":5},{"text":"our","start":32,"end":35,"id":6},{"text":"sparsity","start":36,"end":44,"id":7},{"text":"-","start":44,"end":45,"id":8},{"text":"smoothness","start":45,"end":55,"id":9},{"text":"penalized","start":56,"end":65,"id":10},{"text":"approach","start":66,"end":74,"id":11},{"text":"yields","start":75,"end":81,"id":12},{"text":"large","start":82,"end":87,"id":13},{"text":"additional","start":88,"end":98,"id":14},{"text":"performance","start":99,"end":110,"id":15},{"text":"gains","start":111,"end":116,"id":16},{"text":".","start":116,"end":117,"id":17}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":0,"end":7,"token_start":0,"token_end":0,"label":"ALGO","answer":"reject"},{"start":99,"end":110,"token_start":15,"token_end":15,"label":"ALGO","answer":"reject"}],"answer":"reject"}
{"text":"A challenging problem in estimating high-dimensional graphical models is to choose the regularization parameter in a data-dependent way.","_input_hash":-429533200,"_task_hash":-17330569,"tokens":[{"text":"A","start":0,"end":1,"id":0},{"text":"challenging","start":2,"end":13,"id":1},{"text":"problem","start":14,"end":21,"id":2},{"text":"in","start":22,"end":24,"id":3},{"text":"estimating","start":25,"end":35,"id":4},{"text":"high","start":36,"end":40,"id":5},{"text":"-","start":40,"end":41,"id":6},{"text":"dimensional","start":41,"end":52,"id":7},{"text":"graphical","start":53,"end":62,"id":8},{"text":"models","start":63,"end":69,"id":9},{"text":"is","start":70,"end":72,"id":10},{"text":"to","start":73,"end":75,"id":11},{"text":"choose","start":76,"end":82,"id":12},{"text":"the","start":83,"end":86,"id":13},{"text":"regularization","start":87,"end":101,"id":14},{"text":"parameter","start":102,"end":111,"id":15},{"text":"in","start":112,"end":114,"id":16},{"text":"a","start":115,"end":116,"id":17},{"text":"data","start":117,"end":121,"id":18},{"text":"-","start":121,"end":122,"id":19},{"text":"dependent","start":122,"end":131,"id":20},{"text":"way","start":132,"end":135,"id":21},{"text":".","start":135,"end":136,"id":22}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"The standard techniques include $K$-fold cross-validation ($K$-CV), Akaike information criterion (AIC), and Bayesian information criterion (BIC).","_input_hash":26445775,"_task_hash":450316953,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"standard","start":4,"end":12,"id":1},{"text":"techniques","start":13,"end":23,"id":2},{"text":"include","start":24,"end":31,"id":3},{"text":"$","start":32,"end":33,"id":4},{"text":"K$-fold","start":33,"end":40,"id":5},{"text":"cross","start":41,"end":46,"id":6},{"text":"-","start":46,"end":47,"id":7},{"text":"validation","start":47,"end":57,"id":8},{"text":"(","start":58,"end":59,"id":9},{"text":"$","start":59,"end":60,"id":10},{"text":"K$-CV","start":60,"end":65,"id":11},{"text":")","start":65,"end":66,"id":12},{"text":",","start":66,"end":67,"id":13},{"text":"Akaike","start":68,"end":74,"id":14},{"text":"information","start":75,"end":86,"id":15},{"text":"criterion","start":87,"end":96,"id":16},{"text":"(","start":97,"end":98,"id":17},{"text":"AIC","start":98,"end":101,"id":18},{"text":")","start":101,"end":102,"id":19},{"text":",","start":102,"end":103,"id":20},{"text":"and","start":104,"end":107,"id":21},{"text":"Bayesian","start":108,"end":116,"id":22},{"text":"information","start":117,"end":128,"id":23},{"text":"criterion","start":129,"end":138,"id":24},{"text":"(","start":139,"end":140,"id":25},{"text":"BIC","start":140,"end":143,"id":26},{"text":")","start":143,"end":144,"id":27},{"text":".","start":144,"end":145,"id":28}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":32,"end":57,"token_start":4,"token_end":8,"label":"ALGO","answer":"accept"},{"start":68,"end":96,"token_start":14,"token_end":16,"label":"ALGO","answer":"accept"},{"start":108,"end":138,"token_start":22,"token_end":24,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"Though these methods work well for low-dimensional problems, they are not suitable in high dimensional settings.","_input_hash":-239673365,"_task_hash":-1537214801,"tokens":[{"text":"Though","start":0,"end":6,"id":0},{"text":"these","start":7,"end":12,"id":1},{"text":"methods","start":13,"end":20,"id":2},{"text":"work","start":21,"end":25,"id":3},{"text":"well","start":26,"end":30,"id":4},{"text":"for","start":31,"end":34,"id":5},{"text":"low","start":35,"end":38,"id":6},{"text":"-","start":38,"end":39,"id":7},{"text":"dimensional","start":39,"end":50,"id":8},{"text":"problems","start":51,"end":59,"id":9},{"text":",","start":59,"end":60,"id":10},{"text":"they","start":61,"end":65,"id":11},{"text":"are","start":66,"end":69,"id":12},{"text":"not","start":70,"end":73,"id":13},{"text":"suitable","start":74,"end":82,"id":14},{"text":"in","start":83,"end":85,"id":15},{"text":"high","start":86,"end":90,"id":16},{"text":"dimensional","start":91,"end":102,"id":17},{"text":"settings","start":103,"end":111,"id":18},{"text":".","start":111,"end":112,"id":19}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"In this paper, we present StARS:","_input_hash":-930151000,"_task_hash":-193945727,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"this","start":3,"end":7,"id":1},{"text":"paper","start":8,"end":13,"id":2},{"text":",","start":13,"end":14,"id":3},{"text":"we","start":15,"end":17,"id":4},{"text":"present","start":18,"end":25,"id":5},{"text":"StARS","start":26,"end":31,"id":6},{"text":":","start":31,"end":32,"id":7}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":26,"end":31,"token_start":6,"token_end":6,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"a new stability-based method for choosing the regularization parameter in high dimensional inference for undirected graphs.","_input_hash":-1506303016,"_task_hash":982909148,"tokens":[{"text":"a","start":0,"end":1,"id":0},{"text":"new","start":2,"end":5,"id":1},{"text":"stability","start":6,"end":15,"id":2},{"text":"-","start":15,"end":16,"id":3},{"text":"based","start":16,"end":21,"id":4},{"text":"method","start":22,"end":28,"id":5},{"text":"for","start":29,"end":32,"id":6},{"text":"choosing","start":33,"end":41,"id":7},{"text":"the","start":42,"end":45,"id":8},{"text":"regularization","start":46,"end":60,"id":9},{"text":"parameter","start":61,"end":70,"id":10},{"text":"in","start":71,"end":73,"id":11},{"text":"high","start":74,"end":78,"id":12},{"text":"dimensional","start":79,"end":90,"id":13},{"text":"inference","start":91,"end":100,"id":14},{"text":"for","start":101,"end":104,"id":15},{"text":"undirected","start":105,"end":115,"id":16},{"text":"graphs","start":116,"end":122,"id":17},{"text":".","start":122,"end":123,"id":18}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":6,"end":21,"token_start":2,"token_end":4,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"The method has a clear interpretation:","_input_hash":558527787,"_task_hash":697620002,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"method","start":4,"end":10,"id":1},{"text":"has","start":11,"end":14,"id":2},{"text":"a","start":15,"end":16,"id":3},{"text":"clear","start":17,"end":22,"id":4},{"text":"interpretation","start":23,"end":37,"id":5},{"text":":","start":37,"end":38,"id":6}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"we use the least amount of regularization that simultaneously makes a graph sparse and replicable under random sampling.","_input_hash":-1982708874,"_task_hash":751722846,"tokens":[{"text":"we","start":0,"end":2,"id":0},{"text":"use","start":3,"end":6,"id":1},{"text":"the","start":7,"end":10,"id":2},{"text":"least","start":11,"end":16,"id":3},{"text":"amount","start":17,"end":23,"id":4},{"text":"of","start":24,"end":26,"id":5},{"text":"regularization","start":27,"end":41,"id":6},{"text":"that","start":42,"end":46,"id":7},{"text":"simultaneously","start":47,"end":61,"id":8},{"text":"makes","start":62,"end":67,"id":9},{"text":"a","start":68,"end":69,"id":10},{"text":"graph","start":70,"end":75,"id":11},{"text":"sparse","start":76,"end":82,"id":12},{"text":"and","start":83,"end":86,"id":13},{"text":"replicable","start":87,"end":97,"id":14},{"text":"under","start":98,"end":103,"id":15},{"text":"random","start":104,"end":110,"id":16},{"text":"sampling","start":111,"end":119,"id":17},{"text":".","start":119,"end":120,"id":18}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"This interpretation requires essentially no conditions.","_input_hash":-1174012755,"_task_hash":1113905910,"tokens":[{"text":"This","start":0,"end":4,"id":0},{"text":"interpretation","start":5,"end":19,"id":1},{"text":"requires","start":20,"end":28,"id":2},{"text":"essentially","start":29,"end":40,"id":3},{"text":"no","start":41,"end":43,"id":4},{"text":"conditions","start":44,"end":54,"id":5},{"text":".","start":54,"end":55,"id":6}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Under mild conditions, we show that StARS is partially sparsistent in terms of graph estimation:","_input_hash":1336059987,"_task_hash":457329661,"tokens":[{"text":"Under","start":0,"end":5,"id":0},{"text":"mild","start":6,"end":10,"id":1},{"text":"conditions","start":11,"end":21,"id":2},{"text":",","start":21,"end":22,"id":3},{"text":"we","start":23,"end":25,"id":4},{"text":"show","start":26,"end":30,"id":5},{"text":"that","start":31,"end":35,"id":6},{"text":"StARS","start":36,"end":41,"id":7},{"text":"is","start":42,"end":44,"id":8},{"text":"partially","start":45,"end":54,"id":9},{"text":"sparsistent","start":55,"end":66,"id":10},{"text":"in","start":67,"end":69,"id":11},{"text":"terms","start":70,"end":75,"id":12},{"text":"of","start":76,"end":78,"id":13},{"text":"graph","start":79,"end":84,"id":14},{"text":"estimation","start":85,"end":95,"id":15},{"text":":","start":95,"end":96,"id":16}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":36,"end":41,"token_start":7,"token_end":7,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"i.e. with high probability, all the true edges will be included in the selected model even when the graph size diverges with the sample size.","_input_hash":-1163250996,"_task_hash":-772001038,"tokens":[{"text":"i.e.","start":0,"end":4,"id":0},{"text":"with","start":5,"end":9,"id":1},{"text":"high","start":10,"end":14,"id":2},{"text":"probability","start":15,"end":26,"id":3},{"text":",","start":26,"end":27,"id":4},{"text":"all","start":28,"end":31,"id":5},{"text":"the","start":32,"end":35,"id":6},{"text":"true","start":36,"end":40,"id":7},{"text":"edges","start":41,"end":46,"id":8},{"text":"will","start":47,"end":51,"id":9},{"text":"be","start":52,"end":54,"id":10},{"text":"included","start":55,"end":63,"id":11},{"text":"in","start":64,"end":66,"id":12},{"text":"the","start":67,"end":70,"id":13},{"text":"selected","start":71,"end":79,"id":14},{"text":"model","start":80,"end":85,"id":15},{"text":"even","start":86,"end":90,"id":16},{"text":"when","start":91,"end":95,"id":17},{"text":"the","start":96,"end":99,"id":18},{"text":"graph","start":100,"end":105,"id":19},{"text":"size","start":106,"end":110,"id":20},{"text":"diverges","start":111,"end":119,"id":21},{"text":"with","start":120,"end":124,"id":22},{"text":"the","start":125,"end":128,"id":23},{"text":"sample","start":129,"end":135,"id":24},{"text":"size","start":136,"end":140,"id":25},{"text":".","start":140,"end":141,"id":26}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Empirically, the performance of StARS is compared with the state-of-the-art model selection procedures, including $K$-CV, AIC, and BIC, on both synthetic data and a real microarray dataset.","_input_hash":-570864727,"_task_hash":-2036563339,"tokens":[{"text":"Empirically","start":0,"end":11,"id":0},{"text":",","start":11,"end":12,"id":1},{"text":"the","start":13,"end":16,"id":2},{"text":"performance","start":17,"end":28,"id":3},{"text":"of","start":29,"end":31,"id":4},{"text":"StARS","start":32,"end":37,"id":5},{"text":"is","start":38,"end":40,"id":6},{"text":"compared","start":41,"end":49,"id":7},{"text":"with","start":50,"end":54,"id":8},{"text":"the","start":55,"end":58,"id":9},{"text":"state","start":59,"end":64,"id":10},{"text":"-","start":64,"end":65,"id":11},{"text":"of","start":65,"end":67,"id":12},{"text":"-","start":67,"end":68,"id":13},{"text":"the","start":68,"end":71,"id":14},{"text":"-","start":71,"end":72,"id":15},{"text":"art","start":72,"end":75,"id":16},{"text":"model","start":76,"end":81,"id":17},{"text":"selection","start":82,"end":91,"id":18},{"text":"procedures","start":92,"end":102,"id":19},{"text":",","start":102,"end":103,"id":20},{"text":"including","start":104,"end":113,"id":21},{"text":"$","start":114,"end":115,"id":22},{"text":"K$-CV","start":115,"end":120,"id":23},{"text":",","start":120,"end":121,"id":24},{"text":"AIC","start":122,"end":125,"id":25},{"text":",","start":125,"end":126,"id":26},{"text":"and","start":127,"end":130,"id":27},{"text":"BIC","start":131,"end":134,"id":28},{"text":",","start":134,"end":135,"id":29},{"text":"on","start":136,"end":138,"id":30},{"text":"both","start":139,"end":143,"id":31},{"text":"synthetic","start":144,"end":153,"id":32},{"text":"data","start":154,"end":158,"id":33},{"text":"and","start":159,"end":162,"id":34},{"text":"a","start":163,"end":164,"id":35},{"text":"real","start":165,"end":169,"id":36},{"text":"microarray","start":170,"end":180,"id":37},{"text":"dataset","start":181,"end":188,"id":38},{"text":".","start":188,"end":189,"id":39}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":32,"end":37,"token_start":5,"token_end":5,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"StARS outperforms all these competing procedures.","_input_hash":2127472659,"_task_hash":-1658378728,"tokens":[{"text":"StARS","start":0,"end":5,"id":0},{"text":"outperforms","start":6,"end":17,"id":1},{"text":"all","start":18,"end":21,"id":2},{"text":"these","start":22,"end":27,"id":3},{"text":"competing","start":28,"end":37,"id":4},{"text":"procedures","start":38,"end":48,"id":5},{"text":".","start":48,"end":49,"id":6}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":0,"end":5,"token_start":0,"token_end":0,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"We present surrogate regret bounds for arbitrary surrogate losses in the context of binary classification with label-dependent costs.","_input_hash":-1479826433,"_task_hash":-56122201,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"present","start":3,"end":10,"id":1},{"text":"surrogate","start":11,"end":20,"id":2},{"text":"regret","start":21,"end":27,"id":3},{"text":"bounds","start":28,"end":34,"id":4},{"text":"for","start":35,"end":38,"id":5},{"text":"arbitrary","start":39,"end":48,"id":6},{"text":"surrogate","start":49,"end":58,"id":7},{"text":"losses","start":59,"end":65,"id":8},{"text":"in","start":66,"end":68,"id":9},{"text":"the","start":69,"end":72,"id":10},{"text":"context","start":73,"end":80,"id":11},{"text":"of","start":81,"end":83,"id":12},{"text":"binary","start":84,"end":90,"id":13},{"text":"classification","start":91,"end":105,"id":14},{"text":"with","start":106,"end":110,"id":15},{"text":"label","start":111,"end":116,"id":16},{"text":"-","start":116,"end":117,"id":17},{"text":"dependent","start":117,"end":126,"id":18},{"text":"costs","start":127,"end":132,"id":19},{"text":".","start":132,"end":133,"id":20}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":84,"end":105,"token_start":13,"token_end":14,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"Such bounds relate a classifier's risk, assessed with respect to a surrogate loss, to its cost-sensitive classification risk.","_input_hash":-554488191,"_task_hash":-2086478102,"tokens":[{"text":"Such","start":0,"end":4,"id":0},{"text":"bounds","start":5,"end":11,"id":1},{"text":"relate","start":12,"end":18,"id":2},{"text":"a","start":19,"end":20,"id":3},{"text":"classifier","start":21,"end":31,"id":4},{"text":"'s","start":31,"end":33,"id":5},{"text":"risk","start":34,"end":38,"id":6},{"text":",","start":38,"end":39,"id":7},{"text":"assessed","start":40,"end":48,"id":8},{"text":"with","start":49,"end":53,"id":9},{"text":"respect","start":54,"end":61,"id":10},{"text":"to","start":62,"end":64,"id":11},{"text":"a","start":65,"end":66,"id":12},{"text":"surrogate","start":67,"end":76,"id":13},{"text":"loss","start":77,"end":81,"id":14},{"text":",","start":81,"end":82,"id":15},{"text":"to","start":83,"end":85,"id":16},{"text":"its","start":86,"end":89,"id":17},{"text":"cost","start":90,"end":94,"id":18},{"text":"-","start":94,"end":95,"id":19},{"text":"sensitive","start":95,"end":104,"id":20},{"text":"classification","start":105,"end":119,"id":21},{"text":"risk","start":120,"end":124,"id":22},{"text":".","start":124,"end":125,"id":23}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Two approaches to surrogate regret bounds are developed.","_input_hash":1489249856,"_task_hash":307187196,"tokens":[{"text":"Two","start":0,"end":3,"id":0},{"text":"approaches","start":4,"end":14,"id":1},{"text":"to","start":15,"end":17,"id":2},{"text":"surrogate","start":18,"end":27,"id":3},{"text":"regret","start":28,"end":34,"id":4},{"text":"bounds","start":35,"end":41,"id":5},{"text":"are","start":42,"end":45,"id":6},{"text":"developed","start":46,"end":55,"id":7},{"text":".","start":55,"end":56,"id":8}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"The first is a direct generalization of Bartlett et al. [","_input_hash":-845656059,"_task_hash":1605296307,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"first","start":4,"end":9,"id":1},{"text":"is","start":10,"end":12,"id":2},{"text":"a","start":13,"end":14,"id":3},{"text":"direct","start":15,"end":21,"id":4},{"text":"generalization","start":22,"end":36,"id":5},{"text":"of","start":37,"end":39,"id":6},{"text":"Bartlett","start":40,"end":48,"id":7},{"text":"et","start":49,"end":51,"id":8},{"text":"al","start":52,"end":54,"id":9},{"text":".","start":54,"end":55,"id":10},{"text":"[","start":56,"end":57,"id":11}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"2006], who focus on margin-based losses and cost-insensitive classification, while the second adopts the framework of Steinwart [2007] based on calibration functions.","_input_hash":104294326,"_task_hash":-901203550,"tokens":[{"text":"2006","start":0,"end":4,"id":0},{"text":"]","start":4,"end":5,"id":1},{"text":",","start":5,"end":6,"id":2},{"text":"who","start":7,"end":10,"id":3},{"text":"focus","start":11,"end":16,"id":4},{"text":"on","start":17,"end":19,"id":5},{"text":"margin","start":20,"end":26,"id":6},{"text":"-","start":26,"end":27,"id":7},{"text":"based","start":27,"end":32,"id":8},{"text":"losses","start":33,"end":39,"id":9},{"text":"and","start":40,"end":43,"id":10},{"text":"cost","start":44,"end":48,"id":11},{"text":"-","start":48,"end":49,"id":12},{"text":"insensitive","start":49,"end":60,"id":13},{"text":"classification","start":61,"end":75,"id":14},{"text":",","start":75,"end":76,"id":15},{"text":"while","start":77,"end":82,"id":16},{"text":"the","start":83,"end":86,"id":17},{"text":"second","start":87,"end":93,"id":18},{"text":"adopts","start":94,"end":100,"id":19},{"text":"the","start":101,"end":104,"id":20},{"text":"framework","start":105,"end":114,"id":21},{"text":"of","start":115,"end":117,"id":22},{"text":"Steinwart","start":118,"end":127,"id":23},{"text":"[","start":128,"end":129,"id":24},{"text":"2007","start":129,"end":133,"id":25},{"text":"]","start":133,"end":134,"id":26},{"text":"based","start":135,"end":140,"id":27},{"text":"on","start":141,"end":143,"id":28},{"text":"calibration","start":144,"end":155,"id":29},{"text":"functions","start":156,"end":165,"id":30},{"text":".","start":165,"end":166,"id":31}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Nontrivial surrogate regret bounds are shown to exist precisely when the surrogate loss satisfies a \"calibration\" condition that is easily verified for many common losses.","_input_hash":498887588,"_task_hash":738081253,"tokens":[{"text":"Nontrivial","start":0,"end":10,"id":0},{"text":"surrogate","start":11,"end":20,"id":1},{"text":"regret","start":21,"end":27,"id":2},{"text":"bounds","start":28,"end":34,"id":3},{"text":"are","start":35,"end":38,"id":4},{"text":"shown","start":39,"end":44,"id":5},{"text":"to","start":45,"end":47,"id":6},{"text":"exist","start":48,"end":53,"id":7},{"text":"precisely","start":54,"end":63,"id":8},{"text":"when","start":64,"end":68,"id":9},{"text":"the","start":69,"end":72,"id":10},{"text":"surrogate","start":73,"end":82,"id":11},{"text":"loss","start":83,"end":87,"id":12},{"text":"satisfies","start":88,"end":97,"id":13},{"text":"a","start":98,"end":99,"id":14},{"text":"\"","start":100,"end":101,"id":15},{"text":"calibration","start":101,"end":112,"id":16},{"text":"\"","start":112,"end":113,"id":17},{"text":"condition","start":114,"end":123,"id":18},{"text":"that","start":124,"end":128,"id":19},{"text":"is","start":129,"end":131,"id":20},{"text":"easily","start":132,"end":138,"id":21},{"text":"verified","start":139,"end":147,"id":22},{"text":"for","start":148,"end":151,"id":23},{"text":"many","start":152,"end":156,"id":24},{"text":"common","start":157,"end":163,"id":25},{"text":"losses","start":164,"end":170,"id":26},{"text":".","start":170,"end":171,"id":27}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We apply this theory to the class of uneven margin losses, and characterize when these losses are properly calibrated.","_input_hash":1803974302,"_task_hash":-398803600,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"apply","start":3,"end":8,"id":1},{"text":"this","start":9,"end":13,"id":2},{"text":"theory","start":14,"end":20,"id":3},{"text":"to","start":21,"end":23,"id":4},{"text":"the","start":24,"end":27,"id":5},{"text":"class","start":28,"end":33,"id":6},{"text":"of","start":34,"end":36,"id":7},{"text":"uneven","start":37,"end":43,"id":8},{"text":"margin","start":44,"end":50,"id":9},{"text":"losses","start":51,"end":57,"id":10},{"text":",","start":57,"end":58,"id":11},{"text":"and","start":59,"end":62,"id":12},{"text":"characterize","start":63,"end":75,"id":13},{"text":"when","start":76,"end":80,"id":14},{"text":"these","start":81,"end":86,"id":15},{"text":"losses","start":87,"end":93,"id":16},{"text":"are","start":94,"end":97,"id":17},{"text":"properly","start":98,"end":106,"id":18},{"text":"calibrated","start":107,"end":117,"id":19},{"text":".","start":117,"end":118,"id":20}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"The uneven hinge, squared error, exponential, and sigmoid losses are then treated in detail.","_input_hash":1449106070,"_task_hash":-176172246,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"uneven","start":4,"end":10,"id":1},{"text":"hinge","start":11,"end":16,"id":2},{"text":",","start":16,"end":17,"id":3},{"text":"squared","start":18,"end":25,"id":4},{"text":"error","start":26,"end":31,"id":5},{"text":",","start":31,"end":32,"id":6},{"text":"exponential","start":33,"end":44,"id":7},{"text":",","start":44,"end":45,"id":8},{"text":"and","start":46,"end":49,"id":9},{"text":"sigmoid","start":50,"end":57,"id":10},{"text":"losses","start":58,"end":64,"id":11},{"text":"are","start":65,"end":68,"id":12},{"text":"then","start":69,"end":73,"id":13},{"text":"treated","start":74,"end":81,"id":14},{"text":"in","start":82,"end":84,"id":15},{"text":"detail","start":85,"end":91,"id":16},{"text":".","start":91,"end":92,"id":17}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Kernel Induced Random Survival Forests (KIRSF) is a statistical learning algorithm which aims to improve prediction accuracy for survival data.","_input_hash":1699288305,"_task_hash":-1092952878,"tokens":[{"text":"Kernel","start":0,"end":6,"id":0},{"text":"Induced","start":7,"end":14,"id":1},{"text":"Random","start":15,"end":21,"id":2},{"text":"Survival","start":22,"end":30,"id":3},{"text":"Forests","start":31,"end":38,"id":4},{"text":"(","start":39,"end":40,"id":5},{"text":"KIRSF","start":40,"end":45,"id":6},{"text":")","start":45,"end":46,"id":7},{"text":"is","start":47,"end":49,"id":8},{"text":"a","start":50,"end":51,"id":9},{"text":"statistical","start":52,"end":63,"id":10},{"text":"learning","start":64,"end":72,"id":11},{"text":"algorithm","start":73,"end":82,"id":12},{"text":"which","start":83,"end":88,"id":13},{"text":"aims","start":89,"end":93,"id":14},{"text":"to","start":94,"end":96,"id":15},{"text":"improve","start":97,"end":104,"id":16},{"text":"prediction","start":105,"end":115,"id":17},{"text":"accuracy","start":116,"end":124,"id":18},{"text":"for","start":125,"end":128,"id":19},{"text":"survival","start":129,"end":137,"id":20},{"text":"data","start":138,"end":142,"id":21},{"text":".","start":142,"end":143,"id":22}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":0,"end":38,"token_start":0,"token_end":4,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"As in Random Survival Forests (RSF), Cumulative Hazard Function is predicted for each individual in the test set.","_input_hash":-2099253541,"_task_hash":891697865,"tokens":[{"text":"As","start":0,"end":2,"id":0},{"text":"in","start":3,"end":5,"id":1},{"text":"Random","start":6,"end":12,"id":2},{"text":"Survival","start":13,"end":21,"id":3},{"text":"Forests","start":22,"end":29,"id":4},{"text":"(","start":30,"end":31,"id":5},{"text":"RSF","start":31,"end":34,"id":6},{"text":")","start":34,"end":35,"id":7},{"text":",","start":35,"end":36,"id":8},{"text":"Cumulative","start":37,"end":47,"id":9},{"text":"Hazard","start":48,"end":54,"id":10},{"text":"Function","start":55,"end":63,"id":11},{"text":"is","start":64,"end":66,"id":12},{"text":"predicted","start":67,"end":76,"id":13},{"text":"for","start":77,"end":80,"id":14},{"text":"each","start":81,"end":85,"id":15},{"text":"individual","start":86,"end":96,"id":16},{"text":"in","start":97,"end":99,"id":17},{"text":"the","start":100,"end":103,"id":18},{"text":"test","start":104,"end":108,"id":19},{"text":"set","start":109,"end":112,"id":20},{"text":".","start":112,"end":113,"id":21}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":6,"end":29,"token_start":2,"token_end":4,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"Prediction error is estimated using Harrell's concordance index (C index) [Harrell et al. (","_input_hash":853719302,"_task_hash":-1634706227,"tokens":[{"text":"Prediction","start":0,"end":10,"id":0},{"text":"error","start":11,"end":16,"id":1},{"text":"is","start":17,"end":19,"id":2},{"text":"estimated","start":20,"end":29,"id":3},{"text":"using","start":30,"end":35,"id":4},{"text":"Harrell","start":36,"end":43,"id":5},{"text":"'s","start":43,"end":45,"id":6},{"text":"concordance","start":46,"end":57,"id":7},{"text":"index","start":58,"end":63,"id":8},{"text":"(","start":64,"end":65,"id":9},{"text":"C","start":65,"end":66,"id":10},{"text":"index","start":67,"end":72,"id":11},{"text":")","start":72,"end":73,"id":12},{"text":"[","start":74,"end":75,"id":13},{"text":"Harrell","start":75,"end":82,"id":14},{"text":"et","start":83,"end":85,"id":15},{"text":"al","start":86,"end":88,"id":16},{"text":".","start":88,"end":89,"id":17},{"text":"(","start":90,"end":91,"id":18}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"1982)].","_input_hash":-976923240,"_task_hash":1555611612,"tokens":[{"text":"1982","start":0,"end":4,"id":0},{"text":")","start":4,"end":5,"id":1},{"text":"]","start":5,"end":6,"id":2},{"text":".","start":6,"end":7,"id":3}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"The C-index can be interpreted as a misclassification probability and does not depend on a single fixed time for evaluation.","_input_hash":-1594195599,"_task_hash":582997713,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"C","start":4,"end":5,"id":1},{"text":"-","start":5,"end":6,"id":2},{"text":"index","start":6,"end":11,"id":3},{"text":"can","start":12,"end":15,"id":4},{"text":"be","start":16,"end":18,"id":5},{"text":"interpreted","start":19,"end":30,"id":6},{"text":"as","start":31,"end":33,"id":7},{"text":"a","start":34,"end":35,"id":8},{"text":"misclassification","start":36,"end":53,"id":9},{"text":"probability","start":54,"end":65,"id":10},{"text":"and","start":66,"end":69,"id":11},{"text":"does","start":70,"end":74,"id":12},{"text":"not","start":75,"end":78,"id":13},{"text":"depend","start":79,"end":85,"id":14},{"text":"on","start":86,"end":88,"id":15},{"text":"a","start":89,"end":90,"id":16},{"text":"single","start":91,"end":97,"id":17},{"text":"fixed","start":98,"end":103,"id":18},{"text":"time","start":104,"end":108,"id":19},{"text":"for","start":109,"end":112,"id":20},{"text":"evaluation","start":113,"end":123,"id":21},{"text":".","start":123,"end":124,"id":22}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"The C-index also specifically accounts for censoring.","_input_hash":-471066451,"_task_hash":-95155375,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"C","start":4,"end":5,"id":1},{"text":"-","start":5,"end":6,"id":2},{"text":"index","start":6,"end":11,"id":3},{"text":"also","start":12,"end":16,"id":4},{"text":"specifically","start":17,"end":29,"id":5},{"text":"accounts","start":30,"end":38,"id":6},{"text":"for","start":39,"end":42,"id":7},{"text":"censoring","start":43,"end":52,"id":8},{"text":".","start":52,"end":53,"id":9}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"By utilizing kernel functions, KIRSF achieves better results than RSF in many situations.","_input_hash":-748775233,"_task_hash":-825716663,"tokens":[{"text":"By","start":0,"end":2,"id":0},{"text":"utilizing","start":3,"end":12,"id":1},{"text":"kernel","start":13,"end":19,"id":2},{"text":"functions","start":20,"end":29,"id":3},{"text":",","start":29,"end":30,"id":4},{"text":"KIRSF","start":31,"end":36,"id":5},{"text":"achieves","start":37,"end":45,"id":6},{"text":"better","start":46,"end":52,"id":7},{"text":"results","start":53,"end":60,"id":8},{"text":"than","start":61,"end":65,"id":9},{"text":"RSF","start":66,"end":69,"id":10},{"text":"in","start":70,"end":72,"id":11},{"text":"many","start":73,"end":77,"id":12},{"text":"situations","start":78,"end":88,"id":13},{"text":".","start":88,"end":89,"id":14}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"In this report, we show how to incorporate kernel functions into RSF.","_input_hash":-282059572,"_task_hash":2119442806,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"this","start":3,"end":7,"id":1},{"text":"report","start":8,"end":14,"id":2},{"text":",","start":14,"end":15,"id":3},{"text":"we","start":16,"end":18,"id":4},{"text":"show","start":19,"end":23,"id":5},{"text":"how","start":24,"end":27,"id":6},{"text":"to","start":28,"end":30,"id":7},{"text":"incorporate","start":31,"end":42,"id":8},{"text":"kernel","start":43,"end":49,"id":9},{"text":"functions","start":50,"end":59,"id":10},{"text":"into","start":60,"end":64,"id":11},{"text":"RSF","start":65,"end":68,"id":12},{"text":".","start":68,"end":69,"id":13}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We test the performance of KIRSF and compare our method to RSF.","_input_hash":-1089035827,"_task_hash":1589398985,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"test","start":3,"end":7,"id":1},{"text":"the","start":8,"end":11,"id":2},{"text":"performance","start":12,"end":23,"id":3},{"text":"of","start":24,"end":26,"id":4},{"text":"KIRSF","start":27,"end":32,"id":5},{"text":"and","start":33,"end":36,"id":6},{"text":"compare","start":37,"end":44,"id":7},{"text":"our","start":45,"end":48,"id":8},{"text":"method","start":49,"end":55,"id":9},{"text":"to","start":56,"end":58,"id":10},{"text":"RSF","start":59,"end":62,"id":11},{"text":".","start":62,"end":63,"id":12}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We find that the KIRSF's performance is better than RSF in many occasions.","_input_hash":-1291543225,"_task_hash":691437902,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"find","start":3,"end":7,"id":1},{"text":"that","start":8,"end":12,"id":2},{"text":"the","start":13,"end":16,"id":3},{"text":"KIRSF","start":17,"end":22,"id":4},{"text":"'s","start":22,"end":24,"id":5},{"text":"performance","start":25,"end":36,"id":6},{"text":"is","start":37,"end":39,"id":7},{"text":"better","start":40,"end":46,"id":8},{"text":"than","start":47,"end":51,"id":9},{"text":"RSF","start":52,"end":55,"id":10},{"text":"in","start":56,"end":58,"id":11},{"text":"many","start":59,"end":63,"id":12},{"text":"occasions","start":64,"end":73,"id":13},{"text":".","start":73,"end":74,"id":14}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"There is an increasing body of evidence suggesting that exact nearest neighbour search in high-dimensional spaces is affected by the curse of dimensionality at a fundamental level.","_input_hash":883169193,"_task_hash":-1114935882,"tokens":[{"text":"There","start":0,"end":5,"id":0},{"text":"is","start":6,"end":8,"id":1},{"text":"an","start":9,"end":11,"id":2},{"text":"increasing","start":12,"end":22,"id":3},{"text":"body","start":23,"end":27,"id":4},{"text":"of","start":28,"end":30,"id":5},{"text":"evidence","start":31,"end":39,"id":6},{"text":"suggesting","start":40,"end":50,"id":7},{"text":"that","start":51,"end":55,"id":8},{"text":"exact","start":56,"end":61,"id":9},{"text":"nearest","start":62,"end":69,"id":10},{"text":"neighbour","start":70,"end":79,"id":11},{"text":"search","start":80,"end":86,"id":12},{"text":"in","start":87,"end":89,"id":13},{"text":"high","start":90,"end":94,"id":14},{"text":"-","start":94,"end":95,"id":15},{"text":"dimensional","start":95,"end":106,"id":16},{"text":"spaces","start":107,"end":113,"id":17},{"text":"is","start":114,"end":116,"id":18},{"text":"affected","start":117,"end":125,"id":19},{"text":"by","start":126,"end":128,"id":20},{"text":"the","start":129,"end":132,"id":21},{"text":"curse","start":133,"end":138,"id":22},{"text":"of","start":139,"end":141,"id":23},{"text":"dimensionality","start":142,"end":156,"id":24},{"text":"at","start":157,"end":159,"id":25},{"text":"a","start":160,"end":161,"id":26},{"text":"fundamental","start":162,"end":173,"id":27},{"text":"level","start":174,"end":179,"id":28},{"text":".","start":179,"end":180,"id":29}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Does it necessarily mean that the same is true for k nearest neighbours based learning algorithms such as the k-NN classifier?","_input_hash":-1464832100,"_task_hash":-441925523,"tokens":[{"text":"Does","start":0,"end":4,"id":0},{"text":"it","start":5,"end":7,"id":1},{"text":"necessarily","start":8,"end":19,"id":2},{"text":"mean","start":20,"end":24,"id":3},{"text":"that","start":25,"end":29,"id":4},{"text":"the","start":30,"end":33,"id":5},{"text":"same","start":34,"end":38,"id":6},{"text":"is","start":39,"end":41,"id":7},{"text":"true","start":42,"end":46,"id":8},{"text":"for","start":47,"end":50,"id":9},{"text":"k","start":51,"end":52,"id":10},{"text":"nearest","start":53,"end":60,"id":11},{"text":"neighbours","start":61,"end":71,"id":12},{"text":"based","start":72,"end":77,"id":13},{"text":"learning","start":78,"end":86,"id":14},{"text":"algorithms","start":87,"end":97,"id":15},{"text":"such","start":98,"end":102,"id":16},{"text":"as","start":103,"end":105,"id":17},{"text":"the","start":106,"end":109,"id":18},{"text":"k","start":110,"end":111,"id":19},{"text":"-","start":111,"end":112,"id":20},{"text":"NN","start":112,"end":114,"id":21},{"text":"classifier","start":115,"end":125,"id":22},{"text":"?","start":125,"end":126,"id":23}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":51,"end":71,"token_start":10,"token_end":12,"label":"ALGO","answer":"accept"},{"start":110,"end":125,"token_start":19,"token_end":22,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"We analyse this question at a number of levels and show that the answer is different at each of them.","_input_hash":576876087,"_task_hash":1400711571,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"analyse","start":3,"end":10,"id":1},{"text":"this","start":11,"end":15,"id":2},{"text":"question","start":16,"end":24,"id":3},{"text":"at","start":25,"end":27,"id":4},{"text":"a","start":28,"end":29,"id":5},{"text":"number","start":30,"end":36,"id":6},{"text":"of","start":37,"end":39,"id":7},{"text":"levels","start":40,"end":46,"id":8},{"text":"and","start":47,"end":50,"id":9},{"text":"show","start":51,"end":55,"id":10},{"text":"that","start":56,"end":60,"id":11},{"text":"the","start":61,"end":64,"id":12},{"text":"answer","start":65,"end":71,"id":13},{"text":"is","start":72,"end":74,"id":14},{"text":"different","start":75,"end":84,"id":15},{"text":"at","start":85,"end":87,"id":16},{"text":"each","start":88,"end":92,"id":17},{"text":"of","start":93,"end":95,"id":18},{"text":"them","start":96,"end":100,"id":19},{"text":".","start":100,"end":101,"id":20}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"As our first main observation, we show the consistency of a k approximate nearest neighbour classifier.","_input_hash":685866895,"_task_hash":492264691,"tokens":[{"text":"As","start":0,"end":2,"id":0},{"text":"our","start":3,"end":6,"id":1},{"text":"first","start":7,"end":12,"id":2},{"text":"main","start":13,"end":17,"id":3},{"text":"observation","start":18,"end":29,"id":4},{"text":",","start":29,"end":30,"id":5},{"text":"we","start":31,"end":33,"id":6},{"text":"show","start":34,"end":38,"id":7},{"text":"the","start":39,"end":42,"id":8},{"text":"consistency","start":43,"end":54,"id":9},{"text":"of","start":55,"end":57,"id":10},{"text":"a","start":58,"end":59,"id":11},{"text":"k","start":60,"end":61,"id":12},{"text":"approximate","start":62,"end":73,"id":13},{"text":"nearest","start":74,"end":81,"id":14},{"text":"neighbour","start":82,"end":91,"id":15},{"text":"classifier","start":92,"end":102,"id":16},{"text":".","start":102,"end":103,"id":17}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":60,"end":102,"token_start":12,"token_end":16,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"However, the performance of the classifier in very high dimensions is provably unstable.","_input_hash":1459024373,"_task_hash":900152795,"tokens":[{"text":"However","start":0,"end":7,"id":0},{"text":",","start":7,"end":8,"id":1},{"text":"the","start":9,"end":12,"id":2},{"text":"performance","start":13,"end":24,"id":3},{"text":"of","start":25,"end":27,"id":4},{"text":"the","start":28,"end":31,"id":5},{"text":"classifier","start":32,"end":42,"id":6},{"text":"in","start":43,"end":45,"id":7},{"text":"very","start":46,"end":50,"id":8},{"text":"high","start":51,"end":55,"id":9},{"text":"dimensions","start":56,"end":66,"id":10},{"text":"is","start":67,"end":69,"id":11},{"text":"provably","start":70,"end":78,"id":12},{"text":"unstable","start":79,"end":87,"id":13},{"text":".","start":87,"end":88,"id":14}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"As our second main observation, we point out that the existing model for statistical learning is oblivious of dimension of the domain and so every learning problem admits a universally consistent deterministic reduction to the one-dimensional case by means of a Borel isomorphism.","_input_hash":463332582,"_task_hash":-73008929,"tokens":[{"text":"As","start":0,"end":2,"id":0},{"text":"our","start":3,"end":6,"id":1},{"text":"second","start":7,"end":13,"id":2},{"text":"main","start":14,"end":18,"id":3},{"text":"observation","start":19,"end":30,"id":4},{"text":",","start":30,"end":31,"id":5},{"text":"we","start":32,"end":34,"id":6},{"text":"point","start":35,"end":40,"id":7},{"text":"out","start":41,"end":44,"id":8},{"text":"that","start":45,"end":49,"id":9},{"text":"the","start":50,"end":53,"id":10},{"text":"existing","start":54,"end":62,"id":11},{"text":"model","start":63,"end":68,"id":12},{"text":"for","start":69,"end":72,"id":13},{"text":"statistical","start":73,"end":84,"id":14},{"text":"learning","start":85,"end":93,"id":15},{"text":"is","start":94,"end":96,"id":16},{"text":"oblivious","start":97,"end":106,"id":17},{"text":"of","start":107,"end":109,"id":18},{"text":"dimension","start":110,"end":119,"id":19},{"text":"of","start":120,"end":122,"id":20},{"text":"the","start":123,"end":126,"id":21},{"text":"domain","start":127,"end":133,"id":22},{"text":"and","start":134,"end":137,"id":23},{"text":"so","start":138,"end":140,"id":24},{"text":"every","start":141,"end":146,"id":25},{"text":"learning","start":147,"end":155,"id":26},{"text":"problem","start":156,"end":163,"id":27},{"text":"admits","start":164,"end":170,"id":28},{"text":"a","start":171,"end":172,"id":29},{"text":"universally","start":173,"end":184,"id":30},{"text":"consistent","start":185,"end":195,"id":31},{"text":"deterministic","start":196,"end":209,"id":32},{"text":"reduction","start":210,"end":219,"id":33},{"text":"to","start":220,"end":222,"id":34},{"text":"the","start":223,"end":226,"id":35},{"text":"one","start":227,"end":230,"id":36},{"text":"-","start":230,"end":231,"id":37},{"text":"dimensional","start":231,"end":242,"id":38},{"text":"case","start":243,"end":247,"id":39},{"text":"by","start":248,"end":250,"id":40},{"text":"means","start":251,"end":256,"id":41},{"text":"of","start":257,"end":259,"id":42},{"text":"a","start":260,"end":261,"id":43},{"text":"Borel","start":262,"end":267,"id":44},{"text":"isomorphism","start":268,"end":279,"id":45},{"text":".","start":279,"end":280,"id":46}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"In this paper, we give a new generalization error bound of Multiple Kernel Learning (MKL) for a general class of regularizations, and discuss what kind of regularization gives a favorable predictive accuracy.","_input_hash":1103928728,"_task_hash":204831727,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"this","start":3,"end":7,"id":1},{"text":"paper","start":8,"end":13,"id":2},{"text":",","start":13,"end":14,"id":3},{"text":"we","start":15,"end":17,"id":4},{"text":"give","start":18,"end":22,"id":5},{"text":"a","start":23,"end":24,"id":6},{"text":"new","start":25,"end":28,"id":7},{"text":"generalization","start":29,"end":43,"id":8},{"text":"error","start":44,"end":49,"id":9},{"text":"bound","start":50,"end":55,"id":10},{"text":"of","start":56,"end":58,"id":11},{"text":"Multiple","start":59,"end":67,"id":12},{"text":"Kernel","start":68,"end":74,"id":13},{"text":"Learning","start":75,"end":83,"id":14},{"text":"(","start":84,"end":85,"id":15},{"text":"MKL","start":85,"end":88,"id":16},{"text":")","start":88,"end":89,"id":17},{"text":"for","start":90,"end":93,"id":18},{"text":"a","start":94,"end":95,"id":19},{"text":"general","start":96,"end":103,"id":20},{"text":"class","start":104,"end":109,"id":21},{"text":"of","start":110,"end":112,"id":22},{"text":"regularizations","start":113,"end":128,"id":23},{"text":",","start":128,"end":129,"id":24},{"text":"and","start":130,"end":133,"id":25},{"text":"discuss","start":134,"end":141,"id":26},{"text":"what","start":142,"end":146,"id":27},{"text":"kind","start":147,"end":151,"id":28},{"text":"of","start":152,"end":154,"id":29},{"text":"regularization","start":155,"end":169,"id":30},{"text":"gives","start":170,"end":175,"id":31},{"text":"a","start":176,"end":177,"id":32},{"text":"favorable","start":178,"end":187,"id":33},{"text":"predictive","start":188,"end":198,"id":34},{"text":"accuracy","start":199,"end":207,"id":35},{"text":".","start":207,"end":208,"id":36}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":59,"end":83,"token_start":12,"token_end":14,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"Our main target in this paper is dense type regularizations including \\ellp-MKL.","_input_hash":411717690,"_task_hash":-624884751,"tokens":[{"text":"Our","start":0,"end":3,"id":0},{"text":"main","start":4,"end":8,"id":1},{"text":"target","start":9,"end":15,"id":2},{"text":"in","start":16,"end":18,"id":3},{"text":"this","start":19,"end":23,"id":4},{"text":"paper","start":24,"end":29,"id":5},{"text":"is","start":30,"end":32,"id":6},{"text":"dense","start":33,"end":38,"id":7},{"text":"type","start":39,"end":43,"id":8},{"text":"regularizations","start":44,"end":59,"id":9},{"text":"including","start":60,"end":69,"id":10},{"text":"\\ellp","start":70,"end":75,"id":11},{"text":"-","start":75,"end":76,"id":12},{"text":"MKL","start":76,"end":79,"id":13},{"text":".","start":79,"end":80,"id":14}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"According to the recent numerical experiments, the sparse regularization does not necessarily show a good performance compared with dense type regularizations.","_input_hash":-77254502,"_task_hash":-1678040975,"tokens":[{"text":"According","start":0,"end":9,"id":0},{"text":"to","start":10,"end":12,"id":1},{"text":"the","start":13,"end":16,"id":2},{"text":"recent","start":17,"end":23,"id":3},{"text":"numerical","start":24,"end":33,"id":4},{"text":"experiments","start":34,"end":45,"id":5},{"text":",","start":45,"end":46,"id":6},{"text":"the","start":47,"end":50,"id":7},{"text":"sparse","start":51,"end":57,"id":8},{"text":"regularization","start":58,"end":72,"id":9},{"text":"does","start":73,"end":77,"id":10},{"text":"not","start":78,"end":81,"id":11},{"text":"necessarily","start":82,"end":93,"id":12},{"text":"show","start":94,"end":98,"id":13},{"text":"a","start":99,"end":100,"id":14},{"text":"good","start":101,"end":105,"id":15},{"text":"performance","start":106,"end":117,"id":16},{"text":"compared","start":118,"end":126,"id":17},{"text":"with","start":127,"end":131,"id":18},{"text":"dense","start":132,"end":137,"id":19},{"text":"type","start":138,"end":142,"id":20},{"text":"regularizations","start":143,"end":158,"id":21},{"text":".","start":158,"end":159,"id":22}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Motivated by this fact, this paper gives a general theoretical tool to derive fast learning rates of MKL that is applicable to arbitrary mixed-norm-type regularizations in a unifying manner.","_input_hash":-1266924270,"_task_hash":-1406706644,"tokens":[{"text":"Motivated","start":0,"end":9,"id":0},{"text":"by","start":10,"end":12,"id":1},{"text":"this","start":13,"end":17,"id":2},{"text":"fact","start":18,"end":22,"id":3},{"text":",","start":22,"end":23,"id":4},{"text":"this","start":24,"end":28,"id":5},{"text":"paper","start":29,"end":34,"id":6},{"text":"gives","start":35,"end":40,"id":7},{"text":"a","start":41,"end":42,"id":8},{"text":"general","start":43,"end":50,"id":9},{"text":"theoretical","start":51,"end":62,"id":10},{"text":"tool","start":63,"end":67,"id":11},{"text":"to","start":68,"end":70,"id":12},{"text":"derive","start":71,"end":77,"id":13},{"text":"fast","start":78,"end":82,"id":14},{"text":"learning","start":83,"end":91,"id":15},{"text":"rates","start":92,"end":97,"id":16},{"text":"of","start":98,"end":100,"id":17},{"text":"MKL","start":101,"end":104,"id":18},{"text":"that","start":105,"end":109,"id":19},{"text":"is","start":110,"end":112,"id":20},{"text":"applicable","start":113,"end":123,"id":21},{"text":"to","start":124,"end":126,"id":22},{"text":"arbitrary","start":127,"end":136,"id":23},{"text":"mixed","start":137,"end":142,"id":24},{"text":"-","start":142,"end":143,"id":25},{"text":"norm","start":143,"end":147,"id":26},{"text":"-","start":147,"end":148,"id":27},{"text":"type","start":148,"end":152,"id":28},{"text":"regularizations","start":153,"end":168,"id":29},{"text":"in","start":169,"end":171,"id":30},{"text":"a","start":172,"end":173,"id":31},{"text":"unifying","start":174,"end":182,"id":32},{"text":"manner","start":183,"end":189,"id":33},{"text":".","start":189,"end":190,"id":34}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"This enables us to compare the generalization performances of various types of regularizations.","_input_hash":640648082,"_task_hash":-1791237505,"tokens":[{"text":"This","start":0,"end":4,"id":0},{"text":"enables","start":5,"end":12,"id":1},{"text":"us","start":13,"end":15,"id":2},{"text":"to","start":16,"end":18,"id":3},{"text":"compare","start":19,"end":26,"id":4},{"text":"the","start":27,"end":30,"id":5},{"text":"generalization","start":31,"end":45,"id":6},{"text":"performances","start":46,"end":58,"id":7},{"text":"of","start":59,"end":61,"id":8},{"text":"various","start":62,"end":69,"id":9},{"text":"types","start":70,"end":75,"id":10},{"text":"of","start":76,"end":78,"id":11},{"text":"regularizations","start":79,"end":94,"id":12},{"text":".","start":94,"end":95,"id":13}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"As a consequence, we observe that the homogeneity of the complexities of candidate reproducing kernel Hilbert spaces (RKHSs) affects which regularization strategy (\\ell1 or dense) is preferred.","_input_hash":398102437,"_task_hash":-1272312213,"tokens":[{"text":"As","start":0,"end":2,"id":0},{"text":"a","start":3,"end":4,"id":1},{"text":"consequence","start":5,"end":16,"id":2},{"text":",","start":16,"end":17,"id":3},{"text":"we","start":18,"end":20,"id":4},{"text":"observe","start":21,"end":28,"id":5},{"text":"that","start":29,"end":33,"id":6},{"text":"the","start":34,"end":37,"id":7},{"text":"homogeneity","start":38,"end":49,"id":8},{"text":"of","start":50,"end":52,"id":9},{"text":"the","start":53,"end":56,"id":10},{"text":"complexities","start":57,"end":69,"id":11},{"text":"of","start":70,"end":72,"id":12},{"text":"candidate","start":73,"end":82,"id":13},{"text":"reproducing","start":83,"end":94,"id":14},{"text":"kernel","start":95,"end":101,"id":15},{"text":"Hilbert","start":102,"end":109,"id":16},{"text":"spaces","start":110,"end":116,"id":17},{"text":"(","start":117,"end":118,"id":18},{"text":"RKHSs","start":118,"end":123,"id":19},{"text":")","start":123,"end":124,"id":20},{"text":"affects","start":125,"end":132,"id":21},{"text":"which","start":133,"end":138,"id":22},{"text":"regularization","start":139,"end":153,"id":23},{"text":"strategy","start":154,"end":162,"id":24},{"text":"(","start":163,"end":164,"id":25},{"text":"\\ell1","start":164,"end":169,"id":26},{"text":"or","start":170,"end":172,"id":27},{"text":"dense","start":173,"end":178,"id":28},{"text":")","start":178,"end":179,"id":29},{"text":"is","start":180,"end":182,"id":30},{"text":"preferred","start":183,"end":192,"id":31},{"text":".","start":192,"end":193,"id":32}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":95,"end":116,"token_start":15,"token_end":17,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"In fact, in homogeneous complexity settings where the complexities of all RKHSs are evenly same, \\ell1-regularization is optimal among all isotropic norms.","_input_hash":-1669054670,"_task_hash":-1458262221,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"fact","start":3,"end":7,"id":1},{"text":",","start":7,"end":8,"id":2},{"text":"in","start":9,"end":11,"id":3},{"text":"homogeneous","start":12,"end":23,"id":4},{"text":"complexity","start":24,"end":34,"id":5},{"text":"settings","start":35,"end":43,"id":6},{"text":"where","start":44,"end":49,"id":7},{"text":"the","start":50,"end":53,"id":8},{"text":"complexities","start":54,"end":66,"id":9},{"text":"of","start":67,"end":69,"id":10},{"text":"all","start":70,"end":73,"id":11},{"text":"RKHSs","start":74,"end":79,"id":12},{"text":"are","start":80,"end":83,"id":13},{"text":"evenly","start":84,"end":90,"id":14},{"text":"same","start":91,"end":95,"id":15},{"text":",","start":95,"end":96,"id":16},{"text":"\\ell1-regularization","start":97,"end":117,"id":17},{"text":"is","start":118,"end":120,"id":18},{"text":"optimal","start":121,"end":128,"id":19},{"text":"among","start":129,"end":134,"id":20},{"text":"all","start":135,"end":138,"id":21},{"text":"isotropic","start":139,"end":148,"id":22},{"text":"norms","start":149,"end":154,"id":23},{"text":".","start":154,"end":155,"id":24}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"On the other hand, in inhomogeneous complexity settings, dense type regularizations can show better learning rate than sparse \\ell1-regularization.","_input_hash":-1295141376,"_task_hash":-1504995534,"tokens":[{"text":"On","start":0,"end":2,"id":0},{"text":"the","start":3,"end":6,"id":1},{"text":"other","start":7,"end":12,"id":2},{"text":"hand","start":13,"end":17,"id":3},{"text":",","start":17,"end":18,"id":4},{"text":"in","start":19,"end":21,"id":5},{"text":"inhomogeneous","start":22,"end":35,"id":6},{"text":"complexity","start":36,"end":46,"id":7},{"text":"settings","start":47,"end":55,"id":8},{"text":",","start":55,"end":56,"id":9},{"text":"dense","start":57,"end":62,"id":10},{"text":"type","start":63,"end":67,"id":11},{"text":"regularizations","start":68,"end":83,"id":12},{"text":"can","start":84,"end":87,"id":13},{"text":"show","start":88,"end":92,"id":14},{"text":"better","start":93,"end":99,"id":15},{"text":"learning","start":100,"end":108,"id":16},{"text":"rate","start":109,"end":113,"id":17},{"text":"than","start":114,"end":118,"id":18},{"text":"sparse","start":119,"end":125,"id":19},{"text":"\\ell1-regularization","start":126,"end":146,"id":20},{"text":".","start":146,"end":147,"id":21}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We also show that our learning rate achieves the minimax lower bound in homogeneous complexity settings.","_input_hash":-1582745087,"_task_hash":-579042073,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"also","start":3,"end":7,"id":1},{"text":"show","start":8,"end":12,"id":2},{"text":"that","start":13,"end":17,"id":3},{"text":"our","start":18,"end":21,"id":4},{"text":"learning","start":22,"end":30,"id":5},{"text":"rate","start":31,"end":35,"id":6},{"text":"achieves","start":36,"end":44,"id":7},{"text":"the","start":45,"end":48,"id":8},{"text":"minimax","start":49,"end":56,"id":9},{"text":"lower","start":57,"end":62,"id":10},{"text":"bound","start":63,"end":68,"id":11},{"text":"in","start":69,"end":71,"id":12},{"text":"homogeneous","start":72,"end":83,"id":13},{"text":"complexity","start":84,"end":94,"id":14},{"text":"settings","start":95,"end":103,"id":15},{"text":".","start":103,"end":104,"id":16}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Many problems of low-level computer vision and image processing, such as denoising, deconvolution, tomographic reconstruction or super-resolution, can be addressed by maximizing the posterior distribution of a sparse linear model (SLM).","_input_hash":1701962311,"_task_hash":1236810890,"tokens":[{"text":"Many","start":0,"end":4,"id":0},{"text":"problems","start":5,"end":13,"id":1},{"text":"of","start":14,"end":16,"id":2},{"text":"low","start":17,"end":20,"id":3},{"text":"-","start":20,"end":21,"id":4},{"text":"level","start":21,"end":26,"id":5},{"text":"computer","start":27,"end":35,"id":6},{"text":"vision","start":36,"end":42,"id":7},{"text":"and","start":43,"end":46,"id":8},{"text":"image","start":47,"end":52,"id":9},{"text":"processing","start":53,"end":63,"id":10},{"text":",","start":63,"end":64,"id":11},{"text":"such","start":65,"end":69,"id":12},{"text":"as","start":70,"end":72,"id":13},{"text":"denoising","start":73,"end":82,"id":14},{"text":",","start":82,"end":83,"id":15},{"text":"deconvolution","start":84,"end":97,"id":16},{"text":",","start":97,"end":98,"id":17},{"text":"tomographic","start":99,"end":110,"id":18},{"text":"reconstruction","start":111,"end":125,"id":19},{"text":"or","start":126,"end":128,"id":20},{"text":"super","start":129,"end":134,"id":21},{"text":"-","start":134,"end":135,"id":22},{"text":"resolution","start":135,"end":145,"id":23},{"text":",","start":145,"end":146,"id":24},{"text":"can","start":147,"end":150,"id":25},{"text":"be","start":151,"end":153,"id":26},{"text":"addressed","start":154,"end":163,"id":27},{"text":"by","start":164,"end":166,"id":28},{"text":"maximizing","start":167,"end":177,"id":29},{"text":"the","start":178,"end":181,"id":30},{"text":"posterior","start":182,"end":191,"id":31},{"text":"distribution","start":192,"end":204,"id":32},{"text":"of","start":205,"end":207,"id":33},{"text":"a","start":208,"end":209,"id":34},{"text":"sparse","start":210,"end":216,"id":35},{"text":"linear","start":217,"end":223,"id":36},{"text":"model","start":224,"end":229,"id":37},{"text":"(","start":230,"end":231,"id":38},{"text":"SLM","start":231,"end":234,"id":39},{"text":")","start":234,"end":235,"id":40},{"text":".","start":235,"end":236,"id":41}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":27,"end":42,"token_start":6,"token_end":7,"label":"ALGO","answer":"accept"},{"start":47,"end":63,"token_start":9,"token_end":10,"label":"ALGO","answer":"accept"},{"start":210,"end":223,"token_start":35,"token_end":36,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"We show how higher-order Bayesian decision-making problems, such as optimizing image acquisition in magnetic resonance scanners, can be addressed by querying the SLM posterior covariance, unrelated to the density's mode.","_input_hash":1008301903,"_task_hash":-1109592901,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"show","start":3,"end":7,"id":1},{"text":"how","start":8,"end":11,"id":2},{"text":"higher","start":12,"end":18,"id":3},{"text":"-","start":18,"end":19,"id":4},{"text":"order","start":19,"end":24,"id":5},{"text":"Bayesian","start":25,"end":33,"id":6},{"text":"decision","start":34,"end":42,"id":7},{"text":"-","start":42,"end":43,"id":8},{"text":"making","start":43,"end":49,"id":9},{"text":"problems","start":50,"end":58,"id":10},{"text":",","start":58,"end":59,"id":11},{"text":"such","start":60,"end":64,"id":12},{"text":"as","start":65,"end":67,"id":13},{"text":"optimizing","start":68,"end":78,"id":14},{"text":"image","start":79,"end":84,"id":15},{"text":"acquisition","start":85,"end":96,"id":16},{"text":"in","start":97,"end":99,"id":17},{"text":"magnetic","start":100,"end":108,"id":18},{"text":"resonance","start":109,"end":118,"id":19},{"text":"scanners","start":119,"end":127,"id":20},{"text":",","start":127,"end":128,"id":21},{"text":"can","start":129,"end":132,"id":22},{"text":"be","start":133,"end":135,"id":23},{"text":"addressed","start":136,"end":145,"id":24},{"text":"by","start":146,"end":148,"id":25},{"text":"querying","start":149,"end":157,"id":26},{"text":"the","start":158,"end":161,"id":27},{"text":"SLM","start":162,"end":165,"id":28},{"text":"posterior","start":166,"end":175,"id":29},{"text":"covariance","start":176,"end":186,"id":30},{"text":",","start":186,"end":187,"id":31},{"text":"unrelated","start":188,"end":197,"id":32},{"text":"to","start":198,"end":200,"id":33},{"text":"the","start":201,"end":204,"id":34},{"text":"density","start":205,"end":212,"id":35},{"text":"'s","start":212,"end":214,"id":36},{"text":"mode","start":215,"end":219,"id":37},{"text":".","start":219,"end":220,"id":38}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":162,"end":165,"token_start":28,"token_end":28,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"We propose a scalable algorithmic framework, with which SLM posteriors over full, high-resolution images can be approximated for the first time, solving a variational optimization problem which is convex iff posterior mode finding is convex.","_input_hash":-1049062672,"_task_hash":1168492821,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"propose","start":3,"end":10,"id":1},{"text":"a","start":11,"end":12,"id":2},{"text":"scalable","start":13,"end":21,"id":3},{"text":"algorithmic","start":22,"end":33,"id":4},{"text":"framework","start":34,"end":43,"id":5},{"text":",","start":43,"end":44,"id":6},{"text":"with","start":45,"end":49,"id":7},{"text":"which","start":50,"end":55,"id":8},{"text":"SLM","start":56,"end":59,"id":9},{"text":"posteriors","start":60,"end":70,"id":10},{"text":"over","start":71,"end":75,"id":11},{"text":"full","start":76,"end":80,"id":12},{"text":",","start":80,"end":81,"id":13},{"text":"high","start":82,"end":86,"id":14},{"text":"-","start":86,"end":87,"id":15},{"text":"resolution","start":87,"end":97,"id":16},{"text":"images","start":98,"end":104,"id":17},{"text":"can","start":105,"end":108,"id":18},{"text":"be","start":109,"end":111,"id":19},{"text":"approximated","start":112,"end":124,"id":20},{"text":"for","start":125,"end":128,"id":21},{"text":"the","start":129,"end":132,"id":22},{"text":"first","start":133,"end":138,"id":23},{"text":"time","start":139,"end":143,"id":24},{"text":",","start":143,"end":144,"id":25},{"text":"solving","start":145,"end":152,"id":26},{"text":"a","start":153,"end":154,"id":27},{"text":"variational","start":155,"end":166,"id":28},{"text":"optimization","start":167,"end":179,"id":29},{"text":"problem","start":180,"end":187,"id":30},{"text":"which","start":188,"end":193,"id":31},{"text":"is","start":194,"end":196,"id":32},{"text":"convex","start":197,"end":203,"id":33},{"text":"iff","start":204,"end":207,"id":34},{"text":"posterior","start":208,"end":217,"id":35},{"text":"mode","start":218,"end":222,"id":36},{"text":"finding","start":223,"end":230,"id":37},{"text":"is","start":231,"end":233,"id":38},{"text":"convex","start":234,"end":240,"id":39},{"text":".","start":240,"end":241,"id":40}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":56,"end":59,"token_start":9,"token_end":9,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"These methods successfully drive the optimization of sampling trajectories for real-world magnetic resonance imaging through Bayesian experimental design, which has not been attempted before.","_input_hash":-1437027727,"_task_hash":884314657,"tokens":[{"text":"These","start":0,"end":5,"id":0},{"text":"methods","start":6,"end":13,"id":1},{"text":"successfully","start":14,"end":26,"id":2},{"text":"drive","start":27,"end":32,"id":3},{"text":"the","start":33,"end":36,"id":4},{"text":"optimization","start":37,"end":49,"id":5},{"text":"of","start":50,"end":52,"id":6},{"text":"sampling","start":53,"end":61,"id":7},{"text":"trajectories","start":62,"end":74,"id":8},{"text":"for","start":75,"end":78,"id":9},{"text":"real","start":79,"end":83,"id":10},{"text":"-","start":83,"end":84,"id":11},{"text":"world","start":84,"end":89,"id":12},{"text":"magnetic","start":90,"end":98,"id":13},{"text":"resonance","start":99,"end":108,"id":14},{"text":"imaging","start":109,"end":116,"id":15},{"text":"through","start":117,"end":124,"id":16},{"text":"Bayesian","start":125,"end":133,"id":17},{"text":"experimental","start":134,"end":146,"id":18},{"text":"design","start":147,"end":153,"id":19},{"text":",","start":153,"end":154,"id":20},{"text":"which","start":155,"end":160,"id":21},{"text":"has","start":161,"end":164,"id":22},{"text":"not","start":165,"end":168,"id":23},{"text":"been","start":169,"end":173,"id":24},{"text":"attempted","start":174,"end":183,"id":25},{"text":"before","start":184,"end":190,"id":26},{"text":".","start":190,"end":191,"id":27}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Our methodology provides new insight into similarities and differences between sparse reconstruction and approximate Bayesian inference, and has important implications for compressive sensing of real-world images.","_input_hash":85836900,"_task_hash":1595739516,"tokens":[{"text":"Our","start":0,"end":3,"id":0},{"text":"methodology","start":4,"end":15,"id":1},{"text":"provides","start":16,"end":24,"id":2},{"text":"new","start":25,"end":28,"id":3},{"text":"insight","start":29,"end":36,"id":4},{"text":"into","start":37,"end":41,"id":5},{"text":"similarities","start":42,"end":54,"id":6},{"text":"and","start":55,"end":58,"id":7},{"text":"differences","start":59,"end":70,"id":8},{"text":"between","start":71,"end":78,"id":9},{"text":"sparse","start":79,"end":85,"id":10},{"text":"reconstruction","start":86,"end":100,"id":11},{"text":"and","start":101,"end":104,"id":12},{"text":"approximate","start":105,"end":116,"id":13},{"text":"Bayesian","start":117,"end":125,"id":14},{"text":"inference","start":126,"end":135,"id":15},{"text":",","start":135,"end":136,"id":16},{"text":"and","start":137,"end":140,"id":17},{"text":"has","start":141,"end":144,"id":18},{"text":"important","start":145,"end":154,"id":19},{"text":"implications","start":155,"end":167,"id":20},{"text":"for","start":168,"end":171,"id":21},{"text":"compressive","start":172,"end":183,"id":22},{"text":"sensing","start":184,"end":191,"id":23},{"text":"of","start":192,"end":194,"id":24},{"text":"real","start":195,"end":199,"id":25},{"text":"-","start":199,"end":200,"id":26},{"text":"world","start":200,"end":205,"id":27},{"text":"images","start":206,"end":212,"id":28},{"text":".","start":212,"end":213,"id":29}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"This paper examines from an experimental perspective random forests, the increasingly used statistical method for classification and regression problems introduced by Leo Breiman in 2001.","_input_hash":-308113262,"_task_hash":-1920693465,"tokens":[{"text":"This","start":0,"end":4,"id":0},{"text":"paper","start":5,"end":10,"id":1},{"text":"examines","start":11,"end":19,"id":2},{"text":"from","start":20,"end":24,"id":3},{"text":"an","start":25,"end":27,"id":4},{"text":"experimental","start":28,"end":40,"id":5},{"text":"perspective","start":41,"end":52,"id":6},{"text":"random","start":53,"end":59,"id":7},{"text":"forests","start":60,"end":67,"id":8},{"text":",","start":67,"end":68,"id":9},{"text":"the","start":69,"end":72,"id":10},{"text":"increasingly","start":73,"end":85,"id":11},{"text":"used","start":86,"end":90,"id":12},{"text":"statistical","start":91,"end":102,"id":13},{"text":"method","start":103,"end":109,"id":14},{"text":"for","start":110,"end":113,"id":15},{"text":"classification","start":114,"end":128,"id":16},{"text":"and","start":129,"end":132,"id":17},{"text":"regression","start":133,"end":143,"id":18},{"text":"problems","start":144,"end":152,"id":19},{"text":"introduced","start":153,"end":163,"id":20},{"text":"by","start":164,"end":166,"id":21},{"text":"Leo","start":167,"end":170,"id":22},{"text":"Breiman","start":171,"end":178,"id":23},{"text":"in","start":179,"end":181,"id":24},{"text":"2001","start":182,"end":186,"id":25},{"text":".","start":186,"end":187,"id":26}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":53,"end":67,"token_start":7,"token_end":8,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"It first aims at confirming, known but sparse, advice for using random forests and at proposing some complementary remarks for both standard problems as well as high dimensional ones for which the number of variables hugely exceeds the sample size.","_input_hash":649819897,"_task_hash":-848801109,"tokens":[{"text":"It","start":0,"end":2,"id":0},{"text":"first","start":3,"end":8,"id":1},{"text":"aims","start":9,"end":13,"id":2},{"text":"at","start":14,"end":16,"id":3},{"text":"confirming","start":17,"end":27,"id":4},{"text":",","start":27,"end":28,"id":5},{"text":"known","start":29,"end":34,"id":6},{"text":"but","start":35,"end":38,"id":7},{"text":"sparse","start":39,"end":45,"id":8},{"text":",","start":45,"end":46,"id":9},{"text":"advice","start":47,"end":53,"id":10},{"text":"for","start":54,"end":57,"id":11},{"text":"using","start":58,"end":63,"id":12},{"text":"random","start":64,"end":70,"id":13},{"text":"forests","start":71,"end":78,"id":14},{"text":"and","start":79,"end":82,"id":15},{"text":"at","start":83,"end":85,"id":16},{"text":"proposing","start":86,"end":95,"id":17},{"text":"some","start":96,"end":100,"id":18},{"text":"complementary","start":101,"end":114,"id":19},{"text":"remarks","start":115,"end":122,"id":20},{"text":"for","start":123,"end":126,"id":21},{"text":"both","start":127,"end":131,"id":22},{"text":"standard","start":132,"end":140,"id":23},{"text":"problems","start":141,"end":149,"id":24},{"text":"as","start":150,"end":152,"id":25},{"text":"well","start":153,"end":157,"id":26},{"text":"as","start":158,"end":160,"id":27},{"text":"high","start":161,"end":165,"id":28},{"text":"dimensional","start":166,"end":177,"id":29},{"text":"ones","start":178,"end":182,"id":30},{"text":"for","start":183,"end":186,"id":31},{"text":"which","start":187,"end":192,"id":32},{"text":"the","start":193,"end":196,"id":33},{"text":"number","start":197,"end":203,"id":34},{"text":"of","start":204,"end":206,"id":35},{"text":"variables","start":207,"end":216,"id":36},{"text":"hugely","start":217,"end":223,"id":37},{"text":"exceeds","start":224,"end":231,"id":38},{"text":"the","start":232,"end":235,"id":39},{"text":"sample","start":236,"end":242,"id":40},{"text":"size","start":243,"end":247,"id":41},{"text":".","start":247,"end":248,"id":42}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":64,"end":78,"token_start":13,"token_end":14,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"But the main contribution of this paper is twofold:","_input_hash":839304675,"_task_hash":946156102,"tokens":[{"text":"But","start":0,"end":3,"id":0},{"text":"the","start":4,"end":7,"id":1},{"text":"main","start":8,"end":12,"id":2},{"text":"contribution","start":13,"end":25,"id":3},{"text":"of","start":26,"end":28,"id":4},{"text":"this","start":29,"end":33,"id":5},{"text":"paper","start":34,"end":39,"id":6},{"text":"is","start":40,"end":42,"id":7},{"text":"twofold","start":43,"end":50,"id":8},{"text":":","start":50,"end":51,"id":9}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"to provide some insights about the behavior of the variable importance index based on random forests and in addition, to propose to investigate two classical issues of variable selection.","_input_hash":1956359793,"_task_hash":1819099401,"tokens":[{"text":"to","start":0,"end":2,"id":0},{"text":"provide","start":3,"end":10,"id":1},{"text":"some","start":11,"end":15,"id":2},{"text":"insights","start":16,"end":24,"id":3},{"text":"about","start":25,"end":30,"id":4},{"text":"the","start":31,"end":34,"id":5},{"text":"behavior","start":35,"end":43,"id":6},{"text":"of","start":44,"end":46,"id":7},{"text":"the","start":47,"end":50,"id":8},{"text":"variable","start":51,"end":59,"id":9},{"text":"importance","start":60,"end":70,"id":10},{"text":"index","start":71,"end":76,"id":11},{"text":"based","start":77,"end":82,"id":12},{"text":"on","start":83,"end":85,"id":13},{"text":"random","start":86,"end":92,"id":14},{"text":"forests","start":93,"end":100,"id":15},{"text":"and","start":101,"end":104,"id":16},{"text":"in","start":105,"end":107,"id":17},{"text":"addition","start":108,"end":116,"id":18},{"text":",","start":116,"end":117,"id":19},{"text":"to","start":118,"end":120,"id":20},{"text":"propose","start":121,"end":128,"id":21},{"text":"to","start":129,"end":131,"id":22},{"text":"investigate","start":132,"end":143,"id":23},{"text":"two","start":144,"end":147,"id":24},{"text":"classical","start":148,"end":157,"id":25},{"text":"issues","start":158,"end":164,"id":26},{"text":"of","start":165,"end":167,"id":27},{"text":"variable","start":168,"end":176,"id":28},{"text":"selection","start":177,"end":186,"id":29},{"text":".","start":186,"end":187,"id":30}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":86,"end":100,"token_start":14,"token_end":15,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"The first one is to find important variables for interpretation and the second one is more restrictive and try to design a good prediction model.","_input_hash":1826510268,"_task_hash":-748678460,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"first","start":4,"end":9,"id":1},{"text":"one","start":10,"end":13,"id":2},{"text":"is","start":14,"end":16,"id":3},{"text":"to","start":17,"end":19,"id":4},{"text":"find","start":20,"end":24,"id":5},{"text":"important","start":25,"end":34,"id":6},{"text":"variables","start":35,"end":44,"id":7},{"text":"for","start":45,"end":48,"id":8},{"text":"interpretation","start":49,"end":63,"id":9},{"text":"and","start":64,"end":67,"id":10},{"text":"the","start":68,"end":71,"id":11},{"text":"second","start":72,"end":78,"id":12},{"text":"one","start":79,"end":82,"id":13},{"text":"is","start":83,"end":85,"id":14},{"text":"more","start":86,"end":90,"id":15},{"text":"restrictive","start":91,"end":102,"id":16},{"text":"and","start":103,"end":106,"id":17},{"text":"try","start":107,"end":110,"id":18},{"text":"to","start":111,"end":113,"id":19},{"text":"design","start":114,"end":120,"id":20},{"text":"a","start":121,"end":122,"id":21},{"text":"good","start":123,"end":127,"id":22},{"text":"prediction","start":128,"end":138,"id":23},{"text":"model","start":139,"end":144,"id":24},{"text":".","start":144,"end":145,"id":25}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"The strategy involves a ranking of explanatory variables using the random forests score of importance and a stepwise ascending variable introduction strategy.","_input_hash":-1863389377,"_task_hash":874675346,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"strategy","start":4,"end":12,"id":1},{"text":"involves","start":13,"end":21,"id":2},{"text":"a","start":22,"end":23,"id":3},{"text":"ranking","start":24,"end":31,"id":4},{"text":"of","start":32,"end":34,"id":5},{"text":"explanatory","start":35,"end":46,"id":6},{"text":"variables","start":47,"end":56,"id":7},{"text":"using","start":57,"end":62,"id":8},{"text":"the","start":63,"end":66,"id":9},{"text":"random","start":67,"end":73,"id":10},{"text":"forests","start":74,"end":81,"id":11},{"text":"score","start":82,"end":87,"id":12},{"text":"of","start":88,"end":90,"id":13},{"text":"importance","start":91,"end":101,"id":14},{"text":"and","start":102,"end":105,"id":15},{"text":"a","start":106,"end":107,"id":16},{"text":"stepwise","start":108,"end":116,"id":17},{"text":"ascending","start":117,"end":126,"id":18},{"text":"variable","start":127,"end":135,"id":19},{"text":"introduction","start":136,"end":148,"id":20},{"text":"strategy","start":149,"end":157,"id":21},{"text":".","start":157,"end":158,"id":22}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":67,"end":81,"token_start":10,"token_end":11,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"We define a class of Euclidean distances on weighted graphs, enabling to perform thermodynamic soft graph clustering.","_input_hash":1698259657,"_task_hash":-462270973,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"define","start":3,"end":9,"id":1},{"text":"a","start":10,"end":11,"id":2},{"text":"class","start":12,"end":17,"id":3},{"text":"of","start":18,"end":20,"id":4},{"text":"Euclidean","start":21,"end":30,"id":5},{"text":"distances","start":31,"end":40,"id":6},{"text":"on","start":41,"end":43,"id":7},{"text":"weighted","start":44,"end":52,"id":8},{"text":"graphs","start":53,"end":59,"id":9},{"text":",","start":59,"end":60,"id":10},{"text":"enabling","start":61,"end":69,"id":11},{"text":"to","start":70,"end":72,"id":12},{"text":"perform","start":73,"end":80,"id":13},{"text":"thermodynamic","start":81,"end":94,"id":14},{"text":"soft","start":95,"end":99,"id":15},{"text":"graph","start":100,"end":105,"id":16},{"text":"clustering","start":106,"end":116,"id":17},{"text":".","start":116,"end":117,"id":18}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":0,"end":2,"token_start":0,"token_end":0,"label":"ALGO","answer":"reject"},{"start":3,"end":9,"token_start":1,"token_end":1,"label":"ALGO","answer":"reject"},{"start":10,"end":40,"token_start":2,"token_end":6,"label":"ALGO","answer":"reject"},{"start":41,"end":43,"token_start":7,"token_end":7,"label":"ALGO","answer":"reject"},{"start":44,"end":59,"token_start":8,"token_end":9,"label":"ALGO","answer":"reject"},{"start":59,"end":60,"token_start":10,"token_end":10,"label":"ALGO","answer":"reject"},{"start":61,"end":94,"token_start":11,"token_end":14,"label":"ALGO","answer":"reject"},{"start":106,"end":116,"token_start":17,"token_end":17,"label":"ALGO","answer":"reject"}],"answer":"reject"}
{"text":"The class can be constructed form the \"raw coordinates\" encountered in spectral clustering, and can be extended by means of higher-dimensional embeddings (Schoenberg transformations).","_input_hash":1711228091,"_task_hash":1658687354,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"class","start":4,"end":9,"id":1},{"text":"can","start":10,"end":13,"id":2},{"text":"be","start":14,"end":16,"id":3},{"text":"constructed","start":17,"end":28,"id":4},{"text":"form","start":29,"end":33,"id":5},{"text":"the","start":34,"end":37,"id":6},{"text":"\"","start":38,"end":39,"id":7},{"text":"raw","start":39,"end":42,"id":8},{"text":"coordinates","start":43,"end":54,"id":9},{"text":"\"","start":54,"end":55,"id":10},{"text":"encountered","start":56,"end":67,"id":11},{"text":"in","start":68,"end":70,"id":12},{"text":"spectral","start":71,"end":79,"id":13},{"text":"clustering","start":80,"end":90,"id":14},{"text":",","start":90,"end":91,"id":15},{"text":"and","start":92,"end":95,"id":16},{"text":"can","start":96,"end":99,"id":17},{"text":"be","start":100,"end":102,"id":18},{"text":"extended","start":103,"end":111,"id":19},{"text":"by","start":112,"end":114,"id":20},{"text":"means","start":115,"end":120,"id":21},{"text":"of","start":121,"end":123,"id":22},{"text":"higher","start":124,"end":130,"id":23},{"text":"-","start":130,"end":131,"id":24},{"text":"dimensional","start":131,"end":142,"id":25},{"text":"embeddings","start":143,"end":153,"id":26},{"text":"(","start":154,"end":155,"id":27},{"text":"Schoenberg","start":155,"end":165,"id":28},{"text":"transformations","start":166,"end":181,"id":29},{"text":")","start":181,"end":182,"id":30},{"text":".","start":182,"end":183,"id":31}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":0,"end":9,"token_start":0,"token_end":1,"label":"ALGO","answer":"reject"},{"start":10,"end":28,"token_start":2,"token_end":4,"label":"ALGO","answer":"reject"},{"start":29,"end":54,"token_start":5,"token_end":9,"label":"ALGO","answer":"reject"},{"start":56,"end":79,"token_start":11,"token_end":13,"label":"ALGO","answer":"reject"},{"start":80,"end":90,"token_start":14,"token_end":14,"label":"ALGO","answer":"reject"},{"start":92,"end":114,"token_start":16,"token_end":20,"label":"ALGO","answer":"reject"},{"start":131,"end":153,"token_start":25,"token_end":26,"label":"ALGO","answer":"reject"},{"start":155,"end":165,"token_start":28,"token_end":28,"label":"ALGO","answer":"reject"},{"start":166,"end":181,"token_start":29,"token_end":29,"label":"ALGO","answer":"reject"}],"answer":"reject"}
{"text":"Geographical flow data, properly conditioned, illustrate the procedure as well as visualization aspects.","_input_hash":184435809,"_task_hash":2001808480,"tokens":[{"text":"Geographical","start":0,"end":12,"id":0},{"text":"flow","start":13,"end":17,"id":1},{"text":"data","start":18,"end":22,"id":2},{"text":",","start":22,"end":23,"id":3},{"text":"properly","start":24,"end":32,"id":4},{"text":"conditioned","start":33,"end":44,"id":5},{"text":",","start":44,"end":45,"id":6},{"text":"illustrate","start":46,"end":56,"id":7},{"text":"the","start":57,"end":60,"id":8},{"text":"procedure","start":61,"end":70,"id":9},{"text":"as","start":71,"end":73,"id":10},{"text":"well","start":74,"end":78,"id":11},{"text":"as","start":79,"end":81,"id":12},{"text":"visualization","start":82,"end":95,"id":13},{"text":"aspects","start":96,"end":103,"id":14},{"text":".","start":103,"end":104,"id":15}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"reject"}
{"text":"A collaborative convex framework for factoring a data matrix $X$ into a non-negative product $AS$, with a sparse coefficient matrix $S$, is proposed.","_input_hash":-1362834805,"_task_hash":1394793232,"tokens":[{"text":"A","start":0,"end":1,"id":0},{"text":"collaborative","start":2,"end":15,"id":1},{"text":"convex","start":16,"end":22,"id":2},{"text":"framework","start":23,"end":32,"id":3},{"text":"for","start":33,"end":36,"id":4},{"text":"factoring","start":37,"end":46,"id":5},{"text":"a","start":47,"end":48,"id":6},{"text":"data","start":49,"end":53,"id":7},{"text":"matrix","start":54,"end":60,"id":8},{"text":"$","start":61,"end":62,"id":9},{"text":"X$","start":62,"end":64,"id":10},{"text":"into","start":65,"end":69,"id":11},{"text":"a","start":70,"end":71,"id":12},{"text":"non","start":72,"end":75,"id":13},{"text":"-","start":75,"end":76,"id":14},{"text":"negative","start":76,"end":84,"id":15},{"text":"product","start":85,"end":92,"id":16},{"text":"$","start":93,"end":94,"id":17},{"text":"AS$","start":94,"end":97,"id":18},{"text":",","start":97,"end":98,"id":19},{"text":"with","start":99,"end":103,"id":20},{"text":"a","start":104,"end":105,"id":21},{"text":"sparse","start":106,"end":112,"id":22},{"text":"coefficient","start":113,"end":124,"id":23},{"text":"matrix","start":125,"end":131,"id":24},{"text":"$","start":132,"end":133,"id":25},{"text":"S$","start":133,"end":135,"id":26},{"text":",","start":135,"end":136,"id":27},{"text":"is","start":137,"end":139,"id":28},{"text":"proposed","start":140,"end":148,"id":29},{"text":".","start":148,"end":149,"id":30}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"We restrict the columns of the dictionary matrix $A$ to coincide with certain columns of the data matrix $X$, thereby guaranteeing a physically meaningful dictionary and dimensionality reduction.","_input_hash":64996308,"_task_hash":-845835014,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"restrict","start":3,"end":11,"id":1},{"text":"the","start":12,"end":15,"id":2},{"text":"columns","start":16,"end":23,"id":3},{"text":"of","start":24,"end":26,"id":4},{"text":"the","start":27,"end":30,"id":5},{"text":"dictionary","start":31,"end":41,"id":6},{"text":"matrix","start":42,"end":48,"id":7},{"text":"$","start":49,"end":50,"id":8},{"text":"A$","start":50,"end":52,"id":9},{"text":"to","start":53,"end":55,"id":10},{"text":"coincide","start":56,"end":64,"id":11},{"text":"with","start":65,"end":69,"id":12},{"text":"certain","start":70,"end":77,"id":13},{"text":"columns","start":78,"end":85,"id":14},{"text":"of","start":86,"end":88,"id":15},{"text":"the","start":89,"end":92,"id":16},{"text":"data","start":93,"end":97,"id":17},{"text":"matrix","start":98,"end":104,"id":18},{"text":"$","start":105,"end":106,"id":19},{"text":"X$","start":106,"end":108,"id":20},{"text":",","start":108,"end":109,"id":21},{"text":"thereby","start":110,"end":117,"id":22},{"text":"guaranteeing","start":118,"end":130,"id":23},{"text":"a","start":131,"end":132,"id":24},{"text":"physically","start":133,"end":143,"id":25},{"text":"meaningful","start":144,"end":154,"id":26},{"text":"dictionary","start":155,"end":165,"id":27},{"text":"and","start":166,"end":169,"id":28},{"text":"dimensionality","start":170,"end":184,"id":29},{"text":"reduction","start":185,"end":194,"id":30},{"text":".","start":194,"end":195,"id":31}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"We use $l_{1,\\infty}$ regularization to select the dictionary from the data and show this leads to an exact convex relaxation of $l_0$ in the case of distinct noise free data.","_input_hash":2112593420,"_task_hash":-847604359,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"use","start":3,"end":6,"id":1},{"text":"$","start":7,"end":8,"id":2},{"text":"l_{1,\\infty}$","start":8,"end":21,"id":3},{"text":"regularization","start":22,"end":36,"id":4},{"text":"to","start":37,"end":39,"id":5},{"text":"select","start":40,"end":46,"id":6},{"text":"the","start":47,"end":50,"id":7},{"text":"dictionary","start":51,"end":61,"id":8},{"text":"from","start":62,"end":66,"id":9},{"text":"the","start":67,"end":70,"id":10},{"text":"data","start":71,"end":75,"id":11},{"text":"and","start":76,"end":79,"id":12},{"text":"show","start":80,"end":84,"id":13},{"text":"this","start":85,"end":89,"id":14},{"text":"leads","start":90,"end":95,"id":15},{"text":"to","start":96,"end":98,"id":16},{"text":"an","start":99,"end":101,"id":17},{"text":"exact","start":102,"end":107,"id":18},{"text":"convex","start":108,"end":114,"id":19},{"text":"relaxation","start":115,"end":125,"id":20},{"text":"of","start":126,"end":128,"id":21},{"text":"$","start":129,"end":130,"id":22},{"text":"l_0","start":130,"end":133,"id":23},{"text":"$","start":133,"end":134,"id":24},{"text":"in","start":135,"end":137,"id":25},{"text":"the","start":138,"end":141,"id":26},{"text":"case","start":142,"end":146,"id":27},{"text":"of","start":147,"end":149,"id":28},{"text":"distinct","start":150,"end":158,"id":29},{"text":"noise","start":159,"end":164,"id":30},{"text":"free","start":165,"end":169,"id":31},{"text":"data","start":170,"end":174,"id":32},{"text":".","start":174,"end":175,"id":33}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"We also show how to relax the restriction-to-$X$ constraint by initializing an alternating minimization approach with the solution of the convex model, obtaining a dictionary close to but not necessarily in $X$. We focus on applications of the proposed framework to hyperspectral endmember and abundances identification and also show an application to blind source separation of NMR data.","_input_hash":-87228133,"_task_hash":806421167,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"also","start":3,"end":7,"id":1},{"text":"show","start":8,"end":12,"id":2},{"text":"how","start":13,"end":16,"id":3},{"text":"to","start":17,"end":19,"id":4},{"text":"relax","start":20,"end":25,"id":5},{"text":"the","start":26,"end":29,"id":6},{"text":"restriction","start":30,"end":41,"id":7},{"text":"-","start":41,"end":42,"id":8},{"text":"to-$X$","start":42,"end":48,"id":9},{"text":"constraint","start":49,"end":59,"id":10},{"text":"by","start":60,"end":62,"id":11},{"text":"initializing","start":63,"end":75,"id":12},{"text":"an","start":76,"end":78,"id":13},{"text":"alternating","start":79,"end":90,"id":14},{"text":"minimization","start":91,"end":103,"id":15},{"text":"approach","start":104,"end":112,"id":16},{"text":"with","start":113,"end":117,"id":17},{"text":"the","start":118,"end":121,"id":18},{"text":"solution","start":122,"end":130,"id":19},{"text":"of","start":131,"end":133,"id":20},{"text":"the","start":134,"end":137,"id":21},{"text":"convex","start":138,"end":144,"id":22},{"text":"model","start":145,"end":150,"id":23},{"text":",","start":150,"end":151,"id":24},{"text":"obtaining","start":152,"end":161,"id":25},{"text":"a","start":162,"end":163,"id":26},{"text":"dictionary","start":164,"end":174,"id":27},{"text":"close","start":175,"end":180,"id":28},{"text":"to","start":181,"end":183,"id":29},{"text":"but","start":184,"end":187,"id":30},{"text":"not","start":188,"end":191,"id":31},{"text":"necessarily","start":192,"end":203,"id":32},{"text":"in","start":204,"end":206,"id":33},{"text":"$","start":207,"end":208,"id":34},{"text":"X$.","start":208,"end":211,"id":35},{"text":"We","start":212,"end":214,"id":36},{"text":"focus","start":215,"end":220,"id":37},{"text":"on","start":221,"end":223,"id":38},{"text":"applications","start":224,"end":236,"id":39},{"text":"of","start":237,"end":239,"id":40},{"text":"the","start":240,"end":243,"id":41},{"text":"proposed","start":244,"end":252,"id":42},{"text":"framework","start":253,"end":262,"id":43},{"text":"to","start":263,"end":265,"id":44},{"text":"hyperspectral","start":266,"end":279,"id":45},{"text":"endmember","start":280,"end":289,"id":46},{"text":"and","start":290,"end":293,"id":47},{"text":"abundances","start":294,"end":304,"id":48},{"text":"identification","start":305,"end":319,"id":49},{"text":"and","start":320,"end":323,"id":50},{"text":"also","start":324,"end":328,"id":51},{"text":"show","start":329,"end":333,"id":52},{"text":"an","start":334,"end":336,"id":53},{"text":"application","start":337,"end":348,"id":54},{"text":"to","start":349,"end":351,"id":55},{"text":"blind","start":352,"end":357,"id":56},{"text":"source","start":358,"end":364,"id":57},{"text":"separation","start":365,"end":375,"id":58},{"text":"of","start":376,"end":378,"id":59},{"text":"NMR","start":379,"end":382,"id":60},{"text":"data","start":383,"end":387,"id":61},{"text":".","start":387,"end":388,"id":62}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"Most methods for decision-theoretic online learning are based on the Hedge algorithm, which takes a parameter called the learning rate.","_input_hash":815845396,"_task_hash":84045941,"tokens":[{"text":"Most","start":0,"end":4,"id":0},{"text":"methods","start":5,"end":12,"id":1},{"text":"for","start":13,"end":16,"id":2},{"text":"decision","start":17,"end":25,"id":3},{"text":"-","start":25,"end":26,"id":4},{"text":"theoretic","start":26,"end":35,"id":5},{"text":"online","start":36,"end":42,"id":6},{"text":"learning","start":43,"end":51,"id":7},{"text":"are","start":52,"end":55,"id":8},{"text":"based","start":56,"end":61,"id":9},{"text":"on","start":62,"end":64,"id":10},{"text":"the","start":65,"end":68,"id":11},{"text":"Hedge","start":69,"end":74,"id":12},{"text":"algorithm","start":75,"end":84,"id":13},{"text":",","start":84,"end":85,"id":14},{"text":"which","start":86,"end":91,"id":15},{"text":"takes","start":92,"end":97,"id":16},{"text":"a","start":98,"end":99,"id":17},{"text":"parameter","start":100,"end":109,"id":18},{"text":"called","start":110,"end":116,"id":19},{"text":"the","start":117,"end":120,"id":20},{"text":"learning","start":121,"end":129,"id":21},{"text":"rate","start":130,"end":134,"id":22},{"text":".","start":134,"end":135,"id":23}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":69,"end":74,"token_start":12,"token_end":12,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"In most previous analyses the learning rate was carefully tuned to obtain optimal worst-case performance, leading to suboptimal performance on easy instances, for example when there exists an action that is significantly better than all others.","_input_hash":1709040877,"_task_hash":377935168,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"most","start":3,"end":7,"id":1},{"text":"previous","start":8,"end":16,"id":2},{"text":"analyses","start":17,"end":25,"id":3},{"text":"the","start":26,"end":29,"id":4},{"text":"learning","start":30,"end":38,"id":5},{"text":"rate","start":39,"end":43,"id":6},{"text":"was","start":44,"end":47,"id":7},{"text":"carefully","start":48,"end":57,"id":8},{"text":"tuned","start":58,"end":63,"id":9},{"text":"to","start":64,"end":66,"id":10},{"text":"obtain","start":67,"end":73,"id":11},{"text":"optimal","start":74,"end":81,"id":12},{"text":"worst","start":82,"end":87,"id":13},{"text":"-","start":87,"end":88,"id":14},{"text":"case","start":88,"end":92,"id":15},{"text":"performance","start":93,"end":104,"id":16},{"text":",","start":104,"end":105,"id":17},{"text":"leading","start":106,"end":113,"id":18},{"text":"to","start":114,"end":116,"id":19},{"text":"suboptimal","start":117,"end":127,"id":20},{"text":"performance","start":128,"end":139,"id":21},{"text":"on","start":140,"end":142,"id":22},{"text":"easy","start":143,"end":147,"id":23},{"text":"instances","start":148,"end":157,"id":24},{"text":",","start":157,"end":158,"id":25},{"text":"for","start":159,"end":162,"id":26},{"text":"example","start":163,"end":170,"id":27},{"text":"when","start":171,"end":175,"id":28},{"text":"there","start":176,"end":181,"id":29},{"text":"exists","start":182,"end":188,"id":30},{"text":"an","start":189,"end":191,"id":31},{"text":"action","start":192,"end":198,"id":32},{"text":"that","start":199,"end":203,"id":33},{"text":"is","start":204,"end":206,"id":34},{"text":"significantly","start":207,"end":220,"id":35},{"text":"better","start":221,"end":227,"id":36},{"text":"than","start":228,"end":232,"id":37},{"text":"all","start":233,"end":236,"id":38},{"text":"others","start":237,"end":243,"id":39},{"text":".","start":243,"end":244,"id":40}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We propose a new way of setting the learning rate, which adapts to the difficulty of the learning problem:","_input_hash":1965890718,"_task_hash":226684671,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"propose","start":3,"end":10,"id":1},{"text":"a","start":11,"end":12,"id":2},{"text":"new","start":13,"end":16,"id":3},{"text":"way","start":17,"end":20,"id":4},{"text":"of","start":21,"end":23,"id":5},{"text":"setting","start":24,"end":31,"id":6},{"text":"the","start":32,"end":35,"id":7},{"text":"learning","start":36,"end":44,"id":8},{"text":"rate","start":45,"end":49,"id":9},{"text":",","start":49,"end":50,"id":10},{"text":"which","start":51,"end":56,"id":11},{"text":"adapts","start":57,"end":63,"id":12},{"text":"to","start":64,"end":66,"id":13},{"text":"the","start":67,"end":70,"id":14},{"text":"difficulty","start":71,"end":81,"id":15},{"text":"of","start":82,"end":84,"id":16},{"text":"the","start":85,"end":88,"id":17},{"text":"learning","start":89,"end":97,"id":18},{"text":"problem","start":98,"end":105,"id":19},{"text":":","start":105,"end":106,"id":20}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"in the worst case our procedure still guarantees optimal performance, but on easy instances it achieves much smaller regret.","_input_hash":542498393,"_task_hash":1411192048,"tokens":[{"text":"in","start":0,"end":2,"id":0},{"text":"the","start":3,"end":6,"id":1},{"text":"worst","start":7,"end":12,"id":2},{"text":"case","start":13,"end":17,"id":3},{"text":"our","start":18,"end":21,"id":4},{"text":"procedure","start":22,"end":31,"id":5},{"text":"still","start":32,"end":37,"id":6},{"text":"guarantees","start":38,"end":48,"id":7},{"text":"optimal","start":49,"end":56,"id":8},{"text":"performance","start":57,"end":68,"id":9},{"text":",","start":68,"end":69,"id":10},{"text":"but","start":70,"end":73,"id":11},{"text":"on","start":74,"end":76,"id":12},{"text":"easy","start":77,"end":81,"id":13},{"text":"instances","start":82,"end":91,"id":14},{"text":"it","start":92,"end":94,"id":15},{"text":"achieves","start":95,"end":103,"id":16},{"text":"much","start":104,"end":108,"id":17},{"text":"smaller","start":109,"end":116,"id":18},{"text":"regret","start":117,"end":123,"id":19},{"text":".","start":123,"end":124,"id":20}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"In particular, our adaptive method achieves constant regret in a probabilistic setting, when there exists an action that on average obtains strictly smaller loss than all other actions.","_input_hash":-697385510,"_task_hash":-1648302992,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"particular","start":3,"end":13,"id":1},{"text":",","start":13,"end":14,"id":2},{"text":"our","start":15,"end":18,"id":3},{"text":"adaptive","start":19,"end":27,"id":4},{"text":"method","start":28,"end":34,"id":5},{"text":"achieves","start":35,"end":43,"id":6},{"text":"constant","start":44,"end":52,"id":7},{"text":"regret","start":53,"end":59,"id":8},{"text":"in","start":60,"end":62,"id":9},{"text":"a","start":63,"end":64,"id":10},{"text":"probabilistic","start":65,"end":78,"id":11},{"text":"setting","start":79,"end":86,"id":12},{"text":",","start":86,"end":87,"id":13},{"text":"when","start":88,"end":92,"id":14},{"text":"there","start":93,"end":98,"id":15},{"text":"exists","start":99,"end":105,"id":16},{"text":"an","start":106,"end":108,"id":17},{"text":"action","start":109,"end":115,"id":18},{"text":"that","start":116,"end":120,"id":19},{"text":"on","start":121,"end":123,"id":20},{"text":"average","start":124,"end":131,"id":21},{"text":"obtains","start":132,"end":139,"id":22},{"text":"strictly","start":140,"end":148,"id":23},{"text":"smaller","start":149,"end":156,"id":24},{"text":"loss","start":157,"end":161,"id":25},{"text":"than","start":162,"end":166,"id":26},{"text":"all","start":167,"end":170,"id":27},{"text":"other","start":171,"end":176,"id":28},{"text":"actions","start":177,"end":184,"id":29},{"text":".","start":184,"end":185,"id":30}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We also provide a simulation study comparing our approach to existing methods.","_input_hash":486350779,"_task_hash":513307991,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"also","start":3,"end":7,"id":1},{"text":"provide","start":8,"end":15,"id":2},{"text":"a","start":16,"end":17,"id":3},{"text":"simulation","start":18,"end":28,"id":4},{"text":"study","start":29,"end":34,"id":5},{"text":"comparing","start":35,"end":44,"id":6},{"text":"our","start":45,"end":48,"id":7},{"text":"approach","start":49,"end":57,"id":8},{"text":"to","start":58,"end":60,"id":9},{"text":"existing","start":61,"end":69,"id":10},{"text":"methods","start":70,"end":77,"id":11},{"text":".","start":77,"end":78,"id":12}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"In many situations where the interest lies in identifying clusters one might expect that not all available variables carry information about these groups.","_input_hash":-1138814907,"_task_hash":1729261316,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"many","start":3,"end":7,"id":1},{"text":"situations","start":8,"end":18,"id":2},{"text":"where","start":19,"end":24,"id":3},{"text":"the","start":25,"end":28,"id":4},{"text":"interest","start":29,"end":37,"id":5},{"text":"lies","start":38,"end":42,"id":6},{"text":"in","start":43,"end":45,"id":7},{"text":"identifying","start":46,"end":57,"id":8},{"text":"clusters","start":58,"end":66,"id":9},{"text":"one","start":67,"end":70,"id":10},{"text":"might","start":71,"end":76,"id":11},{"text":"expect","start":77,"end":83,"id":12},{"text":"that","start":84,"end":88,"id":13},{"text":"not","start":89,"end":92,"id":14},{"text":"all","start":93,"end":96,"id":15},{"text":"available","start":97,"end":106,"id":16},{"text":"variables","start":107,"end":116,"id":17},{"text":"carry","start":117,"end":122,"id":18},{"text":"information","start":123,"end":134,"id":19},{"text":"about","start":135,"end":140,"id":20},{"text":"these","start":141,"end":146,"id":21},{"text":"groups","start":147,"end":153,"id":22},{"text":".","start":153,"end":154,"id":23}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Furthermore, data quality (e.g. outliers or missing entries) might present a serious and sometimes hard-to-assess problem for large and complex datasets.","_input_hash":596089947,"_task_hash":-56079210,"tokens":[{"text":"Furthermore","start":0,"end":11,"id":0},{"text":",","start":11,"end":12,"id":1},{"text":"data","start":13,"end":17,"id":2},{"text":"quality","start":18,"end":25,"id":3},{"text":"(","start":26,"end":27,"id":4},{"text":"e.g.","start":27,"end":31,"id":5},{"text":"outliers","start":32,"end":40,"id":6},{"text":"or","start":41,"end":43,"id":7},{"text":"missing","start":44,"end":51,"id":8},{"text":"entries","start":52,"end":59,"id":9},{"text":")","start":59,"end":60,"id":10},{"text":"might","start":61,"end":66,"id":11},{"text":"present","start":67,"end":74,"id":12},{"text":"a","start":75,"end":76,"id":13},{"text":"serious","start":77,"end":84,"id":14},{"text":"and","start":85,"end":88,"id":15},{"text":"sometimes","start":89,"end":98,"id":16},{"text":"hard","start":99,"end":103,"id":17},{"text":"-","start":103,"end":104,"id":18},{"text":"to","start":104,"end":106,"id":19},{"text":"-","start":106,"end":107,"id":20},{"text":"assess","start":107,"end":113,"id":21},{"text":"problem","start":114,"end":121,"id":22},{"text":"for","start":122,"end":125,"id":23},{"text":"large","start":126,"end":131,"id":24},{"text":"and","start":132,"end":135,"id":25},{"text":"complex","start":136,"end":143,"id":26},{"text":"datasets","start":144,"end":152,"id":27},{"text":".","start":152,"end":153,"id":28}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"In this paper we show that a small proportion of atypical observations might have serious adverse effects on the solutions found by the sparse clustering algorithm of Witten and Tibshirani (2010).","_input_hash":1754256157,"_task_hash":1117362821,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"this","start":3,"end":7,"id":1},{"text":"paper","start":8,"end":13,"id":2},{"text":"we","start":14,"end":16,"id":3},{"text":"show","start":17,"end":21,"id":4},{"text":"that","start":22,"end":26,"id":5},{"text":"a","start":27,"end":28,"id":6},{"text":"small","start":29,"end":34,"id":7},{"text":"proportion","start":35,"end":45,"id":8},{"text":"of","start":46,"end":48,"id":9},{"text":"atypical","start":49,"end":57,"id":10},{"text":"observations","start":58,"end":70,"id":11},{"text":"might","start":71,"end":76,"id":12},{"text":"have","start":77,"end":81,"id":13},{"text":"serious","start":82,"end":89,"id":14},{"text":"adverse","start":90,"end":97,"id":15},{"text":"effects","start":98,"end":105,"id":16},{"text":"on","start":106,"end":108,"id":17},{"text":"the","start":109,"end":112,"id":18},{"text":"solutions","start":113,"end":122,"id":19},{"text":"found","start":123,"end":128,"id":20},{"text":"by","start":129,"end":131,"id":21},{"text":"the","start":132,"end":135,"id":22},{"text":"sparse","start":136,"end":142,"id":23},{"text":"clustering","start":143,"end":153,"id":24},{"text":"algorithm","start":154,"end":163,"id":25},{"text":"of","start":164,"end":166,"id":26},{"text":"Witten","start":167,"end":173,"id":27},{"text":"and","start":174,"end":177,"id":28},{"text":"Tibshirani","start":178,"end":188,"id":29},{"text":"(","start":189,"end":190,"id":30},{"text":"2010","start":190,"end":194,"id":31},{"text":")","start":194,"end":195,"id":32},{"text":".","start":195,"end":196,"id":33}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":136,"end":153,"token_start":23,"token_end":24,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"We propose a robustification of their sparse K-means algorithm based on the trimmed K-means algorithm of Cuesta-Albertos et al. (","_input_hash":-1361413297,"_task_hash":-1518734659,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"propose","start":3,"end":10,"id":1},{"text":"a","start":11,"end":12,"id":2},{"text":"robustification","start":13,"end":28,"id":3},{"text":"of","start":29,"end":31,"id":4},{"text":"their","start":32,"end":37,"id":5},{"text":"sparse","start":38,"end":44,"id":6},{"text":"K","start":45,"end":46,"id":7},{"text":"-","start":46,"end":47,"id":8},{"text":"means","start":47,"end":52,"id":9},{"text":"algorithm","start":53,"end":62,"id":10},{"text":"based","start":63,"end":68,"id":11},{"text":"on","start":69,"end":71,"id":12},{"text":"the","start":72,"end":75,"id":13},{"text":"trimmed","start":76,"end":83,"id":14},{"text":"K","start":84,"end":85,"id":15},{"text":"-","start":85,"end":86,"id":16},{"text":"means","start":86,"end":91,"id":17},{"text":"algorithm","start":92,"end":101,"id":18},{"text":"of","start":102,"end":104,"id":19},{"text":"Cuesta","start":105,"end":111,"id":20},{"text":"-","start":111,"end":112,"id":21},{"text":"Albertos","start":112,"end":120,"id":22},{"text":"et","start":121,"end":123,"id":23},{"text":"al","start":124,"end":126,"id":24},{"text":".","start":126,"end":127,"id":25},{"text":"(","start":128,"end":129,"id":26}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":38,"end":52,"token_start":6,"token_end":9,"label":"ALGO","answer":"accept"},{"start":76,"end":91,"token_start":14,"token_end":17,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"1997) Our proposal is also able to handle datasets with missing values.","_input_hash":-1868328804,"_task_hash":452769615,"tokens":[{"text":"1997","start":0,"end":4,"id":0},{"text":")","start":4,"end":5,"id":1},{"text":"Our","start":6,"end":9,"id":2},{"text":"proposal","start":10,"end":18,"id":3},{"text":"is","start":19,"end":21,"id":4},{"text":"also","start":22,"end":26,"id":5},{"text":"able","start":27,"end":31,"id":6},{"text":"to","start":32,"end":34,"id":7},{"text":"handle","start":35,"end":41,"id":8},{"text":"datasets","start":42,"end":50,"id":9},{"text":"with","start":51,"end":55,"id":10},{"text":"missing","start":56,"end":63,"id":11},{"text":"values","start":64,"end":70,"id":12},{"text":".","start":70,"end":71,"id":13}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We illustrate the use of our method on microarray data for cancer patients where we are able to identify strong biological clusters with a much reduced number of genes.","_input_hash":1763949877,"_task_hash":-828445320,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"illustrate","start":3,"end":13,"id":1},{"text":"the","start":14,"end":17,"id":2},{"text":"use","start":18,"end":21,"id":3},{"text":"of","start":22,"end":24,"id":4},{"text":"our","start":25,"end":28,"id":5},{"text":"method","start":29,"end":35,"id":6},{"text":"on","start":36,"end":38,"id":7},{"text":"microarray","start":39,"end":49,"id":8},{"text":"data","start":50,"end":54,"id":9},{"text":"for","start":55,"end":58,"id":10},{"text":"cancer","start":59,"end":65,"id":11},{"text":"patients","start":66,"end":74,"id":12},{"text":"where","start":75,"end":80,"id":13},{"text":"we","start":81,"end":83,"id":14},{"text":"are","start":84,"end":87,"id":15},{"text":"able","start":88,"end":92,"id":16},{"text":"to","start":93,"end":95,"id":17},{"text":"identify","start":96,"end":104,"id":18},{"text":"strong","start":105,"end":111,"id":19},{"text":"biological","start":112,"end":122,"id":20},{"text":"clusters","start":123,"end":131,"id":21},{"text":"with","start":132,"end":136,"id":22},{"text":"a","start":137,"end":138,"id":23},{"text":"much","start":139,"end":143,"id":24},{"text":"reduced","start":144,"end":151,"id":25},{"text":"number","start":152,"end":158,"id":26},{"text":"of","start":159,"end":161,"id":27},{"text":"genes","start":162,"end":167,"id":28},{"text":".","start":167,"end":168,"id":29}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Our simulation studies show that, when there are outliers in the data, our robust sparse K-means algorithm performs better than other competing methods both in terms of the selection of features and also the identified clusters.","_input_hash":-1878234098,"_task_hash":-1548248644,"tokens":[{"text":"Our","start":0,"end":3,"id":0},{"text":"simulation","start":4,"end":14,"id":1},{"text":"studies","start":15,"end":22,"id":2},{"text":"show","start":23,"end":27,"id":3},{"text":"that","start":28,"end":32,"id":4},{"text":",","start":32,"end":33,"id":5},{"text":"when","start":34,"end":38,"id":6},{"text":"there","start":39,"end":44,"id":7},{"text":"are","start":45,"end":48,"id":8},{"text":"outliers","start":49,"end":57,"id":9},{"text":"in","start":58,"end":60,"id":10},{"text":"the","start":61,"end":64,"id":11},{"text":"data","start":65,"end":69,"id":12},{"text":",","start":69,"end":70,"id":13},{"text":"our","start":71,"end":74,"id":14},{"text":"robust","start":75,"end":81,"id":15},{"text":"sparse","start":82,"end":88,"id":16},{"text":"K","start":89,"end":90,"id":17},{"text":"-","start":90,"end":91,"id":18},{"text":"means","start":91,"end":96,"id":19},{"text":"algorithm","start":97,"end":106,"id":20},{"text":"performs","start":107,"end":115,"id":21},{"text":"better","start":116,"end":122,"id":22},{"text":"than","start":123,"end":127,"id":23},{"text":"other","start":128,"end":133,"id":24},{"text":"competing","start":134,"end":143,"id":25},{"text":"methods","start":144,"end":151,"id":26},{"text":"both","start":152,"end":156,"id":27},{"text":"in","start":157,"end":159,"id":28},{"text":"terms","start":160,"end":165,"id":29},{"text":"of","start":166,"end":168,"id":30},{"text":"the","start":169,"end":172,"id":31},{"text":"selection","start":173,"end":182,"id":32},{"text":"of","start":183,"end":185,"id":33},{"text":"features","start":186,"end":194,"id":34},{"text":"and","start":195,"end":198,"id":35},{"text":"also","start":199,"end":203,"id":36},{"text":"the","start":204,"end":207,"id":37},{"text":"identified","start":208,"end":218,"id":38},{"text":"clusters","start":219,"end":227,"id":39},{"text":".","start":227,"end":228,"id":40}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":75,"end":96,"token_start":15,"token_end":19,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"This robust sparse K-means algorithm is implemented in the R package RSKC which is publicly available from the CRAN repository.","_input_hash":-1959444845,"_task_hash":-1806963067,"tokens":[{"text":"This","start":0,"end":4,"id":0},{"text":"robust","start":5,"end":11,"id":1},{"text":"sparse","start":12,"end":18,"id":2},{"text":"K","start":19,"end":20,"id":3},{"text":"-","start":20,"end":21,"id":4},{"text":"means","start":21,"end":26,"id":5},{"text":"algorithm","start":27,"end":36,"id":6},{"text":"is","start":37,"end":39,"id":7},{"text":"implemented","start":40,"end":51,"id":8},{"text":"in","start":52,"end":54,"id":9},{"text":"the","start":55,"end":58,"id":10},{"text":"R","start":59,"end":60,"id":11},{"text":"package","start":61,"end":68,"id":12},{"text":"RSKC","start":69,"end":73,"id":13},{"text":"which","start":74,"end":79,"id":14},{"text":"is","start":80,"end":82,"id":15},{"text":"publicly","start":83,"end":91,"id":16},{"text":"available","start":92,"end":101,"id":17},{"text":"from","start":102,"end":106,"id":18},{"text":"the","start":107,"end":110,"id":19},{"text":"CRAN","start":111,"end":115,"id":20},{"text":"repository","start":116,"end":126,"id":21},{"text":".","start":126,"end":127,"id":22}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":5,"end":26,"token_start":1,"token_end":5,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"We consider the problem of jointly estimating the parameters as well as the structure of binary valued Markov Random Fields, in contrast to earlier work that focus on one of the two problems.","_input_hash":680968016,"_task_hash":-1466320610,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"consider","start":3,"end":11,"id":1},{"text":"the","start":12,"end":15,"id":2},{"text":"problem","start":16,"end":23,"id":3},{"text":"of","start":24,"end":26,"id":4},{"text":"jointly","start":27,"end":34,"id":5},{"text":"estimating","start":35,"end":45,"id":6},{"text":"the","start":46,"end":49,"id":7},{"text":"parameters","start":50,"end":60,"id":8},{"text":"as","start":61,"end":63,"id":9},{"text":"well","start":64,"end":68,"id":10},{"text":"as","start":69,"end":71,"id":11},{"text":"the","start":72,"end":75,"id":12},{"text":"structure","start":76,"end":85,"id":13},{"text":"of","start":86,"end":88,"id":14},{"text":"binary","start":89,"end":95,"id":15},{"text":"valued","start":96,"end":102,"id":16},{"text":"Markov","start":103,"end":109,"id":17},{"text":"Random","start":110,"end":116,"id":18},{"text":"Fields","start":117,"end":123,"id":19},{"text":",","start":123,"end":124,"id":20},{"text":"in","start":125,"end":127,"id":21},{"text":"contrast","start":128,"end":136,"id":22},{"text":"to","start":137,"end":139,"id":23},{"text":"earlier","start":140,"end":147,"id":24},{"text":"work","start":148,"end":152,"id":25},{"text":"that","start":153,"end":157,"id":26},{"text":"focus","start":158,"end":163,"id":27},{"text":"on","start":164,"end":166,"id":28},{"text":"one","start":167,"end":170,"id":29},{"text":"of","start":171,"end":173,"id":30},{"text":"the","start":174,"end":177,"id":31},{"text":"two","start":178,"end":181,"id":32},{"text":"problems","start":182,"end":190,"id":33},{"text":".","start":190,"end":191,"id":34}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":103,"end":123,"token_start":17,"token_end":19,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"We formulate the problem as a maximization of $\\ell_1$-regularized surrogate likelihood that allows us to find a sparse solution.","_input_hash":255427274,"_task_hash":-1941332186,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"formulate","start":3,"end":12,"id":1},{"text":"the","start":13,"end":16,"id":2},{"text":"problem","start":17,"end":24,"id":3},{"text":"as","start":25,"end":27,"id":4},{"text":"a","start":28,"end":29,"id":5},{"text":"maximization","start":30,"end":42,"id":6},{"text":"of","start":43,"end":45,"id":7},{"text":"$","start":46,"end":47,"id":8},{"text":"\\ell_1$-regularized","start":47,"end":66,"id":9},{"text":"surrogate","start":67,"end":76,"id":10},{"text":"likelihood","start":77,"end":87,"id":11},{"text":"that","start":88,"end":92,"id":12},{"text":"allows","start":93,"end":99,"id":13},{"text":"us","start":100,"end":102,"id":14},{"text":"to","start":103,"end":105,"id":15},{"text":"find","start":106,"end":110,"id":16},{"text":"a","start":111,"end":112,"id":17},{"text":"sparse","start":113,"end":119,"id":18},{"text":"solution","start":120,"end":128,"id":19},{"text":".","start":128,"end":129,"id":20}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Our optimization technique efficiently incorporates the cutting-plane algorithm in order to obtain a tighter outer bound on the marginal polytope, which results in improvement of both parameter estimates and approximation to marginals.","_input_hash":150698891,"_task_hash":2031746315,"tokens":[{"text":"Our","start":0,"end":3,"id":0},{"text":"optimization","start":4,"end":16,"id":1},{"text":"technique","start":17,"end":26,"id":2},{"text":"efficiently","start":27,"end":38,"id":3},{"text":"incorporates","start":39,"end":51,"id":4},{"text":"the","start":52,"end":55,"id":5},{"text":"cutting","start":56,"end":63,"id":6},{"text":"-","start":63,"end":64,"id":7},{"text":"plane","start":64,"end":69,"id":8},{"text":"algorithm","start":70,"end":79,"id":9},{"text":"in","start":80,"end":82,"id":10},{"text":"order","start":83,"end":88,"id":11},{"text":"to","start":89,"end":91,"id":12},{"text":"obtain","start":92,"end":98,"id":13},{"text":"a","start":99,"end":100,"id":14},{"text":"tighter","start":101,"end":108,"id":15},{"text":"outer","start":109,"end":114,"id":16},{"text":"bound","start":115,"end":120,"id":17},{"text":"on","start":121,"end":123,"id":18},{"text":"the","start":124,"end":127,"id":19},{"text":"marginal","start":128,"end":136,"id":20},{"text":"polytope","start":137,"end":145,"id":21},{"text":",","start":145,"end":146,"id":22},{"text":"which","start":147,"end":152,"id":23},{"text":"results","start":153,"end":160,"id":24},{"text":"in","start":161,"end":163,"id":25},{"text":"improvement","start":164,"end":175,"id":26},{"text":"of","start":176,"end":178,"id":27},{"text":"both","start":179,"end":183,"id":28},{"text":"parameter","start":184,"end":193,"id":29},{"text":"estimates","start":194,"end":203,"id":30},{"text":"and","start":204,"end":207,"id":31},{"text":"approximation","start":208,"end":221,"id":32},{"text":"to","start":222,"end":224,"id":33},{"text":"marginals","start":225,"end":234,"id":34},{"text":".","start":234,"end":235,"id":35}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"On synthetic data, we compare our algorithm on the two estimation tasks to the other existing methods.","_input_hash":517898554,"_task_hash":-1080598850,"tokens":[{"text":"On","start":0,"end":2,"id":0},{"text":"synthetic","start":3,"end":12,"id":1},{"text":"data","start":13,"end":17,"id":2},{"text":",","start":17,"end":18,"id":3},{"text":"we","start":19,"end":21,"id":4},{"text":"compare","start":22,"end":29,"id":5},{"text":"our","start":30,"end":33,"id":6},{"text":"algorithm","start":34,"end":43,"id":7},{"text":"on","start":44,"end":46,"id":8},{"text":"the","start":47,"end":50,"id":9},{"text":"two","start":51,"end":54,"id":10},{"text":"estimation","start":55,"end":65,"id":11},{"text":"tasks","start":66,"end":71,"id":12},{"text":"to","start":72,"end":74,"id":13},{"text":"the","start":75,"end":78,"id":14},{"text":"other","start":79,"end":84,"id":15},{"text":"existing","start":85,"end":93,"id":16},{"text":"methods","start":94,"end":101,"id":17},{"text":".","start":101,"end":102,"id":18}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We analyze the method in the high-dimensional setting, where the number of dimensions $p$ is allowed to grow with the number of observations $n$. The rate of convergence of the estimate is demonstrated to depend explicitly on the sparsity of the underlying graph.","_input_hash":418561057,"_task_hash":812657583,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"analyze","start":3,"end":10,"id":1},{"text":"the","start":11,"end":14,"id":2},{"text":"method","start":15,"end":21,"id":3},{"text":"in","start":22,"end":24,"id":4},{"text":"the","start":25,"end":28,"id":5},{"text":"high","start":29,"end":33,"id":6},{"text":"-","start":33,"end":34,"id":7},{"text":"dimensional","start":34,"end":45,"id":8},{"text":"setting","start":46,"end":53,"id":9},{"text":",","start":53,"end":54,"id":10},{"text":"where","start":55,"end":60,"id":11},{"text":"the","start":61,"end":64,"id":12},{"text":"number","start":65,"end":71,"id":13},{"text":"of","start":72,"end":74,"id":14},{"text":"dimensions","start":75,"end":85,"id":15},{"text":"$","start":86,"end":87,"id":16},{"text":"p$","start":87,"end":89,"id":17},{"text":"is","start":90,"end":92,"id":18},{"text":"allowed","start":93,"end":100,"id":19},{"text":"to","start":101,"end":103,"id":20},{"text":"grow","start":104,"end":108,"id":21},{"text":"with","start":109,"end":113,"id":22},{"text":"the","start":114,"end":117,"id":23},{"text":"number","start":118,"end":124,"id":24},{"text":"of","start":125,"end":127,"id":25},{"text":"observations","start":128,"end":140,"id":26},{"text":"$","start":141,"end":142,"id":27},{"text":"n$.","start":142,"end":145,"id":28},{"text":"The","start":146,"end":149,"id":29},{"text":"rate","start":150,"end":154,"id":30},{"text":"of","start":155,"end":157,"id":31},{"text":"convergence","start":158,"end":169,"id":32},{"text":"of","start":170,"end":172,"id":33},{"text":"the","start":173,"end":176,"id":34},{"text":"estimate","start":177,"end":185,"id":35},{"text":"is","start":186,"end":188,"id":36},{"text":"demonstrated","start":189,"end":201,"id":37},{"text":"to","start":202,"end":204,"id":38},{"text":"depend","start":205,"end":211,"id":39},{"text":"explicitly","start":212,"end":222,"id":40},{"text":"on","start":223,"end":225,"id":41},{"text":"the","start":226,"end":229,"id":42},{"text":"sparsity","start":230,"end":238,"id":43},{"text":"of","start":239,"end":241,"id":44},{"text":"the","start":242,"end":245,"id":45},{"text":"underlying","start":246,"end":256,"id":46},{"text":"graph","start":257,"end":262,"id":47},{"text":".","start":262,"end":263,"id":48}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We propose a method called ideal regression for approximating an arbitrary system of polynomial equations by a system of a particular type.","_input_hash":-100275009,"_task_hash":-2063659578,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"propose","start":3,"end":10,"id":1},{"text":"a","start":11,"end":12,"id":2},{"text":"method","start":13,"end":19,"id":3},{"text":"called","start":20,"end":26,"id":4},{"text":"ideal","start":27,"end":32,"id":5},{"text":"regression","start":33,"end":43,"id":6},{"text":"for","start":44,"end":47,"id":7},{"text":"approximating","start":48,"end":61,"id":8},{"text":"an","start":62,"end":64,"id":9},{"text":"arbitrary","start":65,"end":74,"id":10},{"text":"system","start":75,"end":81,"id":11},{"text":"of","start":82,"end":84,"id":12},{"text":"polynomial","start":85,"end":95,"id":13},{"text":"equations","start":96,"end":105,"id":14},{"text":"by","start":106,"end":108,"id":15},{"text":"a","start":109,"end":110,"id":16},{"text":"system","start":111,"end":117,"id":17},{"text":"of","start":118,"end":120,"id":18},{"text":"a","start":121,"end":122,"id":19},{"text":"particular","start":123,"end":133,"id":20},{"text":"type","start":134,"end":138,"id":21},{"text":".","start":138,"end":139,"id":22}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":27,"end":43,"token_start":5,"token_end":6,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"Using techniques from approximate computational algebraic geometry, we show how we can solve ideal regression directly without resorting to numerical optimization.","_input_hash":-852509665,"_task_hash":346192240,"tokens":[{"text":"Using","start":0,"end":5,"id":0},{"text":"techniques","start":6,"end":16,"id":1},{"text":"from","start":17,"end":21,"id":2},{"text":"approximate","start":22,"end":33,"id":3},{"text":"computational","start":34,"end":47,"id":4},{"text":"algebraic","start":48,"end":57,"id":5},{"text":"geometry","start":58,"end":66,"id":6},{"text":",","start":66,"end":67,"id":7},{"text":"we","start":68,"end":70,"id":8},{"text":"show","start":71,"end":75,"id":9},{"text":"how","start":76,"end":79,"id":10},{"text":"we","start":80,"end":82,"id":11},{"text":"can","start":83,"end":86,"id":12},{"text":"solve","start":87,"end":92,"id":13},{"text":"ideal","start":93,"end":98,"id":14},{"text":"regression","start":99,"end":109,"id":15},{"text":"directly","start":110,"end":118,"id":16},{"text":"without","start":119,"end":126,"id":17},{"text":"resorting","start":127,"end":136,"id":18},{"text":"to","start":137,"end":139,"id":19},{"text":"numerical","start":140,"end":149,"id":20},{"text":"optimization","start":150,"end":162,"id":21},{"text":".","start":162,"end":163,"id":22}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":93,"end":109,"token_start":14,"token_end":15,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"Ideal regression is useful whenever the solution to a learning problem can be described by a system of polynomial equations.","_input_hash":-145000670,"_task_hash":1238196211,"tokens":[{"text":"Ideal","start":0,"end":5,"id":0},{"text":"regression","start":6,"end":16,"id":1},{"text":"is","start":17,"end":19,"id":2},{"text":"useful","start":20,"end":26,"id":3},{"text":"whenever","start":27,"end":35,"id":4},{"text":"the","start":36,"end":39,"id":5},{"text":"solution","start":40,"end":48,"id":6},{"text":"to","start":49,"end":51,"id":7},{"text":"a","start":52,"end":53,"id":8},{"text":"learning","start":54,"end":62,"id":9},{"text":"problem","start":63,"end":70,"id":10},{"text":"can","start":71,"end":74,"id":11},{"text":"be","start":75,"end":77,"id":12},{"text":"described","start":78,"end":87,"id":13},{"text":"by","start":88,"end":90,"id":14},{"text":"a","start":91,"end":92,"id":15},{"text":"system","start":93,"end":99,"id":16},{"text":"of","start":100,"end":102,"id":17},{"text":"polynomial","start":103,"end":113,"id":18},{"text":"equations","start":114,"end":123,"id":19},{"text":".","start":123,"end":124,"id":20}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":0,"end":16,"token_start":0,"token_end":1,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"As an example, we demonstrate how to formulate Stationary Subspace Analysis (SSA), a source separation problem, in terms of ideal regression, which also yields a consistent estimator for SSA.","_input_hash":-1781051767,"_task_hash":1609341603,"tokens":[{"text":"As","start":0,"end":2,"id":0},{"text":"an","start":3,"end":5,"id":1},{"text":"example","start":6,"end":13,"id":2},{"text":",","start":13,"end":14,"id":3},{"text":"we","start":15,"end":17,"id":4},{"text":"demonstrate","start":18,"end":29,"id":5},{"text":"how","start":30,"end":33,"id":6},{"text":"to","start":34,"end":36,"id":7},{"text":"formulate","start":37,"end":46,"id":8},{"text":"Stationary","start":47,"end":57,"id":9},{"text":"Subspace","start":58,"end":66,"id":10},{"text":"Analysis","start":67,"end":75,"id":11},{"text":"(","start":76,"end":77,"id":12},{"text":"SSA","start":77,"end":80,"id":13},{"text":")","start":80,"end":81,"id":14},{"text":",","start":81,"end":82,"id":15},{"text":"a","start":83,"end":84,"id":16},{"text":"source","start":85,"end":91,"id":17},{"text":"separation","start":92,"end":102,"id":18},{"text":"problem","start":103,"end":110,"id":19},{"text":",","start":110,"end":111,"id":20},{"text":"in","start":112,"end":114,"id":21},{"text":"terms","start":115,"end":120,"id":22},{"text":"of","start":121,"end":123,"id":23},{"text":"ideal","start":124,"end":129,"id":24},{"text":"regression","start":130,"end":140,"id":25},{"text":",","start":140,"end":141,"id":26},{"text":"which","start":142,"end":147,"id":27},{"text":"also","start":148,"end":152,"id":28},{"text":"yields","start":153,"end":159,"id":29},{"text":"a","start":160,"end":161,"id":30},{"text":"consistent","start":162,"end":172,"id":31},{"text":"estimator","start":173,"end":182,"id":32},{"text":"for","start":183,"end":186,"id":33},{"text":"SSA","start":187,"end":190,"id":34},{"text":".","start":190,"end":191,"id":35}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":124,"end":140,"token_start":24,"token_end":25,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"We then compare this estimator in simulations with previous optimization-based approaches for SSA.","_input_hash":-125558085,"_task_hash":1424006275,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"then","start":3,"end":7,"id":1},{"text":"compare","start":8,"end":15,"id":2},{"text":"this","start":16,"end":20,"id":3},{"text":"estimator","start":21,"end":30,"id":4},{"text":"in","start":31,"end":33,"id":5},{"text":"simulations","start":34,"end":45,"id":6},{"text":"with","start":46,"end":50,"id":7},{"text":"previous","start":51,"end":59,"id":8},{"text":"optimization","start":60,"end":72,"id":9},{"text":"-","start":72,"end":73,"id":10},{"text":"based","start":73,"end":78,"id":11},{"text":"approaches","start":79,"end":89,"id":12},{"text":"for","start":90,"end":93,"id":13},{"text":"SSA","start":94,"end":97,"id":14},{"text":".","start":97,"end":98,"id":15}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We present in this work a new family of kernels to compare positive measures on arbitrary spaces $\\Xcal$ endowed with a positive kernel $\\kappa$, which translates naturally into kernels between histograms or clouds of points.","_input_hash":1811341578,"_task_hash":1470975420,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"present","start":3,"end":10,"id":1},{"text":"in","start":11,"end":13,"id":2},{"text":"this","start":14,"end":18,"id":3},{"text":"work","start":19,"end":23,"id":4},{"text":"a","start":24,"end":25,"id":5},{"text":"new","start":26,"end":29,"id":6},{"text":"family","start":30,"end":36,"id":7},{"text":"of","start":37,"end":39,"id":8},{"text":"kernels","start":40,"end":47,"id":9},{"text":"to","start":48,"end":50,"id":10},{"text":"compare","start":51,"end":58,"id":11},{"text":"positive","start":59,"end":67,"id":12},{"text":"measures","start":68,"end":76,"id":13},{"text":"on","start":77,"end":79,"id":14},{"text":"arbitrary","start":80,"end":89,"id":15},{"text":"spaces","start":90,"end":96,"id":16},{"text":"$","start":97,"end":98,"id":17},{"text":"\\Xcal$","start":98,"end":104,"id":18},{"text":"endowed","start":105,"end":112,"id":19},{"text":"with","start":113,"end":117,"id":20},{"text":"a","start":118,"end":119,"id":21},{"text":"positive","start":120,"end":128,"id":22},{"text":"kernel","start":129,"end":135,"id":23},{"text":"$","start":136,"end":137,"id":24},{"text":"\\kappa$","start":137,"end":144,"id":25},{"text":",","start":144,"end":145,"id":26},{"text":"which","start":146,"end":151,"id":27},{"text":"translates","start":152,"end":162,"id":28},{"text":"naturally","start":163,"end":172,"id":29},{"text":"into","start":173,"end":177,"id":30},{"text":"kernels","start":178,"end":185,"id":31},{"text":"between","start":186,"end":193,"id":32},{"text":"histograms","start":194,"end":204,"id":33},{"text":"or","start":205,"end":207,"id":34},{"text":"clouds","start":208,"end":214,"id":35},{"text":"of","start":215,"end":217,"id":36},{"text":"points","start":218,"end":224,"id":37},{"text":".","start":224,"end":225,"id":38}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"We first cover the case where $\\Xcal$ is Euclidian, and focus on kernels which take into account the variance matrix of the mixture of two measures to compute their similarity.","_input_hash":1864943426,"_task_hash":1466318706,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"first","start":3,"end":8,"id":1},{"text":"cover","start":9,"end":14,"id":2},{"text":"the","start":15,"end":18,"id":3},{"text":"case","start":19,"end":23,"id":4},{"text":"where","start":24,"end":29,"id":5},{"text":"$","start":30,"end":31,"id":6},{"text":"\\Xcal$","start":31,"end":37,"id":7},{"text":"is","start":38,"end":40,"id":8},{"text":"Euclidian","start":41,"end":50,"id":9},{"text":",","start":50,"end":51,"id":10},{"text":"and","start":52,"end":55,"id":11},{"text":"focus","start":56,"end":61,"id":12},{"text":"on","start":62,"end":64,"id":13},{"text":"kernels","start":65,"end":72,"id":14},{"text":"which","start":73,"end":78,"id":15},{"text":"take","start":79,"end":83,"id":16},{"text":"into","start":84,"end":88,"id":17},{"text":"account","start":89,"end":96,"id":18},{"text":"the","start":97,"end":100,"id":19},{"text":"variance","start":101,"end":109,"id":20},{"text":"matrix","start":110,"end":116,"id":21},{"text":"of","start":117,"end":119,"id":22},{"text":"the","start":120,"end":123,"id":23},{"text":"mixture","start":124,"end":131,"id":24},{"text":"of","start":132,"end":134,"id":25},{"text":"two","start":135,"end":138,"id":26},{"text":"measures","start":139,"end":147,"id":27},{"text":"to","start":148,"end":150,"id":28},{"text":"compute","start":151,"end":158,"id":29},{"text":"their","start":159,"end":164,"id":30},{"text":"similarity","start":165,"end":175,"id":31},{"text":".","start":175,"end":176,"id":32}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"The kernels we define are semigroup kernels in the sense that they only use the sum of two measures to compare them, and spectral in the sense that they only use the eigenspectrum of the variance matrix of this mixture.","_input_hash":1847661463,"_task_hash":-1645034374,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"kernels","start":4,"end":11,"id":1},{"text":"we","start":12,"end":14,"id":2},{"text":"define","start":15,"end":21,"id":3},{"text":"are","start":22,"end":25,"id":4},{"text":"semigroup","start":26,"end":35,"id":5},{"text":"kernels","start":36,"end":43,"id":6},{"text":"in","start":44,"end":46,"id":7},{"text":"the","start":47,"end":50,"id":8},{"text":"sense","start":51,"end":56,"id":9},{"text":"that","start":57,"end":61,"id":10},{"text":"they","start":62,"end":66,"id":11},{"text":"only","start":67,"end":71,"id":12},{"text":"use","start":72,"end":75,"id":13},{"text":"the","start":76,"end":79,"id":14},{"text":"sum","start":80,"end":83,"id":15},{"text":"of","start":84,"end":86,"id":16},{"text":"two","start":87,"end":90,"id":17},{"text":"measures","start":91,"end":99,"id":18},{"text":"to","start":100,"end":102,"id":19},{"text":"compare","start":103,"end":110,"id":20},{"text":"them","start":111,"end":115,"id":21},{"text":",","start":115,"end":116,"id":22},{"text":"and","start":117,"end":120,"id":23},{"text":"spectral","start":121,"end":129,"id":24},{"text":"in","start":130,"end":132,"id":25},{"text":"the","start":133,"end":136,"id":26},{"text":"sense","start":137,"end":142,"id":27},{"text":"that","start":143,"end":147,"id":28},{"text":"they","start":148,"end":152,"id":29},{"text":"only","start":153,"end":157,"id":30},{"text":"use","start":158,"end":161,"id":31},{"text":"the","start":162,"end":165,"id":32},{"text":"eigenspectrum","start":166,"end":179,"id":33},{"text":"of","start":180,"end":182,"id":34},{"text":"the","start":183,"end":186,"id":35},{"text":"variance","start":187,"end":195,"id":36},{"text":"matrix","start":196,"end":202,"id":37},{"text":"of","start":203,"end":205,"id":38},{"text":"this","start":206,"end":210,"id":39},{"text":"mixture","start":211,"end":218,"id":40},{"text":".","start":218,"end":219,"id":41}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"We show that such a family of kernels has close bonds with the laplace transforms of nonnegative-valued functions defined on the cone of positive semidefinite matrices, and we present some closed formulas that can be derived as special cases of such integral expressions.","_input_hash":-672109701,"_task_hash":-95035663,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"show","start":3,"end":7,"id":1},{"text":"that","start":8,"end":12,"id":2},{"text":"such","start":13,"end":17,"id":3},{"text":"a","start":18,"end":19,"id":4},{"text":"family","start":20,"end":26,"id":5},{"text":"of","start":27,"end":29,"id":6},{"text":"kernels","start":30,"end":37,"id":7},{"text":"has","start":38,"end":41,"id":8},{"text":"close","start":42,"end":47,"id":9},{"text":"bonds","start":48,"end":53,"id":10},{"text":"with","start":54,"end":58,"id":11},{"text":"the","start":59,"end":62,"id":12},{"text":"laplace","start":63,"end":70,"id":13},{"text":"transforms","start":71,"end":81,"id":14},{"text":"of","start":82,"end":84,"id":15},{"text":"nonnegative","start":85,"end":96,"id":16},{"text":"-","start":96,"end":97,"id":17},{"text":"valued","start":97,"end":103,"id":18},{"text":"functions","start":104,"end":113,"id":19},{"text":"defined","start":114,"end":121,"id":20},{"text":"on","start":122,"end":124,"id":21},{"text":"the","start":125,"end":128,"id":22},{"text":"cone","start":129,"end":133,"id":23},{"text":"of","start":134,"end":136,"id":24},{"text":"positive","start":137,"end":145,"id":25},{"text":"semidefinite","start":146,"end":158,"id":26},{"text":"matrices","start":159,"end":167,"id":27},{"text":",","start":167,"end":168,"id":28},{"text":"and","start":169,"end":172,"id":29},{"text":"we","start":173,"end":175,"id":30},{"text":"present","start":176,"end":183,"id":31},{"text":"some","start":184,"end":188,"id":32},{"text":"closed","start":189,"end":195,"id":33},{"text":"formulas","start":196,"end":204,"id":34},{"text":"that","start":205,"end":209,"id":35},{"text":"can","start":210,"end":213,"id":36},{"text":"be","start":214,"end":216,"id":37},{"text":"derived","start":217,"end":224,"id":38},{"text":"as","start":225,"end":227,"id":39},{"text":"special","start":228,"end":235,"id":40},{"text":"cases","start":236,"end":241,"id":41},{"text":"of","start":242,"end":244,"id":42},{"text":"such","start":245,"end":249,"id":43},{"text":"integral","start":250,"end":258,"id":44},{"text":"expressions","start":259,"end":270,"id":45},{"text":".","start":270,"end":271,"id":46}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"By focusing further on functions which are invariant to the addition of a null eigenvalue to the spectrum of the variance matrix, we can define kernels between atomic measures on arbitrary spaces $\\Xcal$ endowed with a kernel $\\kappa$ by using directly the eigenvalues of the centered Gram matrix of the joined support of the compared measures.","_input_hash":-1208808103,"_task_hash":-878755707,"tokens":[{"text":"By","start":0,"end":2,"id":0},{"text":"focusing","start":3,"end":11,"id":1},{"text":"further","start":12,"end":19,"id":2},{"text":"on","start":20,"end":22,"id":3},{"text":"functions","start":23,"end":32,"id":4},{"text":"which","start":33,"end":38,"id":5},{"text":"are","start":39,"end":42,"id":6},{"text":"invariant","start":43,"end":52,"id":7},{"text":"to","start":53,"end":55,"id":8},{"text":"the","start":56,"end":59,"id":9},{"text":"addition","start":60,"end":68,"id":10},{"text":"of","start":69,"end":71,"id":11},{"text":"a","start":72,"end":73,"id":12},{"text":"null","start":74,"end":78,"id":13},{"text":"eigenvalue","start":79,"end":89,"id":14},{"text":"to","start":90,"end":92,"id":15},{"text":"the","start":93,"end":96,"id":16},{"text":"spectrum","start":97,"end":105,"id":17},{"text":"of","start":106,"end":108,"id":18},{"text":"the","start":109,"end":112,"id":19},{"text":"variance","start":113,"end":121,"id":20},{"text":"matrix","start":122,"end":128,"id":21},{"text":",","start":128,"end":129,"id":22},{"text":"we","start":130,"end":132,"id":23},{"text":"can","start":133,"end":136,"id":24},{"text":"define","start":137,"end":143,"id":25},{"text":"kernels","start":144,"end":151,"id":26},{"text":"between","start":152,"end":159,"id":27},{"text":"atomic","start":160,"end":166,"id":28},{"text":"measures","start":167,"end":175,"id":29},{"text":"on","start":176,"end":178,"id":30},{"text":"arbitrary","start":179,"end":188,"id":31},{"text":"spaces","start":189,"end":195,"id":32},{"text":"$","start":196,"end":197,"id":33},{"text":"\\Xcal$","start":197,"end":203,"id":34},{"text":"endowed","start":204,"end":211,"id":35},{"text":"with","start":212,"end":216,"id":36},{"text":"a","start":217,"end":218,"id":37},{"text":"kernel","start":219,"end":225,"id":38},{"text":"$","start":226,"end":227,"id":39},{"text":"\\kappa$","start":227,"end":234,"id":40},{"text":"by","start":235,"end":237,"id":41},{"text":"using","start":238,"end":243,"id":42},{"text":"directly","start":244,"end":252,"id":43},{"text":"the","start":253,"end":256,"id":44},{"text":"eigenvalues","start":257,"end":268,"id":45},{"text":"of","start":269,"end":271,"id":46},{"text":"the","start":272,"end":275,"id":47},{"text":"centered","start":276,"end":284,"id":48},{"text":"Gram","start":285,"end":289,"id":49},{"text":"matrix","start":290,"end":296,"id":50},{"text":"of","start":297,"end":299,"id":51},{"text":"the","start":300,"end":303,"id":52},{"text":"joined","start":304,"end":310,"id":53},{"text":"support","start":311,"end":318,"id":54},{"text":"of","start":319,"end":321,"id":55},{"text":"the","start":322,"end":325,"id":56},{"text":"compared","start":326,"end":334,"id":57},{"text":"measures","start":335,"end":343,"id":58},{"text":".","start":343,"end":344,"id":59}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"We provide explicit formulas suited for applications and present preliminary experiments to illustrate the interest of the approach.","_input_hash":-2125450756,"_task_hash":1774286172,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"provide","start":3,"end":10,"id":1},{"text":"explicit","start":11,"end":19,"id":2},{"text":"formulas","start":20,"end":28,"id":3},{"text":"suited","start":29,"end":35,"id":4},{"text":"for","start":36,"end":39,"id":5},{"text":"applications","start":40,"end":52,"id":6},{"text":"and","start":53,"end":56,"id":7},{"text":"present","start":57,"end":64,"id":8},{"text":"preliminary","start":65,"end":76,"id":9},{"text":"experiments","start":77,"end":88,"id":10},{"text":"to","start":89,"end":91,"id":11},{"text":"illustrate","start":92,"end":102,"id":12},{"text":"the","start":103,"end":106,"id":13},{"text":"interest","start":107,"end":115,"id":14},{"text":"of","start":116,"end":118,"id":15},{"text":"the","start":119,"end":122,"id":16},{"text":"approach","start":123,"end":131,"id":17},{"text":".","start":131,"end":132,"id":18}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"When response variables are nominal and populations are cross-classified with respect to multiple polytomies, questions often arise about the degree of association of the responses with explanatory variables.","_input_hash":109433603,"_task_hash":881190394,"tokens":[{"text":"When","start":0,"end":4,"id":0},{"text":"response","start":5,"end":13,"id":1},{"text":"variables","start":14,"end":23,"id":2},{"text":"are","start":24,"end":27,"id":3},{"text":"nominal","start":28,"end":35,"id":4},{"text":"and","start":36,"end":39,"id":5},{"text":"populations","start":40,"end":51,"id":6},{"text":"are","start":52,"end":55,"id":7},{"text":"cross","start":56,"end":61,"id":8},{"text":"-","start":61,"end":62,"id":9},{"text":"classified","start":62,"end":72,"id":10},{"text":"with","start":73,"end":77,"id":11},{"text":"respect","start":78,"end":85,"id":12},{"text":"to","start":86,"end":88,"id":13},{"text":"multiple","start":89,"end":97,"id":14},{"text":"polytomies","start":98,"end":108,"id":15},{"text":",","start":108,"end":109,"id":16},{"text":"questions","start":110,"end":119,"id":17},{"text":"often","start":120,"end":125,"id":18},{"text":"arise","start":126,"end":131,"id":19},{"text":"about","start":132,"end":137,"id":20},{"text":"the","start":138,"end":141,"id":21},{"text":"degree","start":142,"end":148,"id":22},{"text":"of","start":149,"end":151,"id":23},{"text":"association","start":152,"end":163,"id":24},{"text":"of","start":164,"end":166,"id":25},{"text":"the","start":167,"end":170,"id":26},{"text":"responses","start":171,"end":180,"id":27},{"text":"with","start":181,"end":185,"id":28},{"text":"explanatory","start":186,"end":197,"id":29},{"text":"variables","start":198,"end":207,"id":30},{"text":".","start":207,"end":208,"id":31}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"When populations are known, we introduce a nominal association vector and matrix to evaluate the dependence of a response variable with an explanatory variable.","_input_hash":-1101378973,"_task_hash":180446190,"tokens":[{"text":"When","start":0,"end":4,"id":0},{"text":"populations","start":5,"end":16,"id":1},{"text":"are","start":17,"end":20,"id":2},{"text":"known","start":21,"end":26,"id":3},{"text":",","start":26,"end":27,"id":4},{"text":"we","start":28,"end":30,"id":5},{"text":"introduce","start":31,"end":40,"id":6},{"text":"a","start":41,"end":42,"id":7},{"text":"nominal","start":43,"end":50,"id":8},{"text":"association","start":51,"end":62,"id":9},{"text":"vector","start":63,"end":69,"id":10},{"text":"and","start":70,"end":73,"id":11},{"text":"matrix","start":74,"end":80,"id":12},{"text":"to","start":81,"end":83,"id":13},{"text":"evaluate","start":84,"end":92,"id":14},{"text":"the","start":93,"end":96,"id":15},{"text":"dependence","start":97,"end":107,"id":16},{"text":"of","start":108,"end":110,"id":17},{"text":"a","start":111,"end":112,"id":18},{"text":"response","start":113,"end":121,"id":19},{"text":"variable","start":122,"end":130,"id":20},{"text":"with","start":131,"end":135,"id":21},{"text":"an","start":136,"end":138,"id":22},{"text":"explanatory","start":139,"end":150,"id":23},{"text":"variable","start":151,"end":159,"id":24},{"text":".","start":159,"end":160,"id":25}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"These measures provide detailed evaluations of nominal associations at both local and global levels.","_input_hash":-245361434,"_task_hash":-82952563,"tokens":[{"text":"These","start":0,"end":5,"id":0},{"text":"measures","start":6,"end":14,"id":1},{"text":"provide","start":15,"end":22,"id":2},{"text":"detailed","start":23,"end":31,"id":3},{"text":"evaluations","start":32,"end":43,"id":4},{"text":"of","start":44,"end":46,"id":5},{"text":"nominal","start":47,"end":54,"id":6},{"text":"associations","start":55,"end":67,"id":7},{"text":"at","start":68,"end":70,"id":8},{"text":"both","start":71,"end":75,"id":9},{"text":"local","start":76,"end":81,"id":10},{"text":"and","start":82,"end":85,"id":11},{"text":"global","start":86,"end":92,"id":12},{"text":"levels","start":93,"end":99,"id":13},{"text":".","start":99,"end":100,"id":14}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"We also define a general class of global association measures which embraces the well known association measure by Goodman-Kruskal (1954).","_input_hash":-426113995,"_task_hash":2005894109,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"also","start":3,"end":7,"id":1},{"text":"define","start":8,"end":14,"id":2},{"text":"a","start":15,"end":16,"id":3},{"text":"general","start":17,"end":24,"id":4},{"text":"class","start":25,"end":30,"id":5},{"text":"of","start":31,"end":33,"id":6},{"text":"global","start":34,"end":40,"id":7},{"text":"association","start":41,"end":52,"id":8},{"text":"measures","start":53,"end":61,"id":9},{"text":"which","start":62,"end":67,"id":10},{"text":"embraces","start":68,"end":76,"id":11},{"text":"the","start":77,"end":80,"id":12},{"text":"well","start":81,"end":85,"id":13},{"text":"known","start":86,"end":91,"id":14},{"text":"association","start":92,"end":103,"id":15},{"text":"measure","start":104,"end":111,"id":16},{"text":"by","start":112,"end":114,"id":17},{"text":"Goodman","start":115,"end":122,"id":18},{"text":"-","start":122,"end":123,"id":19},{"text":"Kruskal","start":123,"end":130,"id":20},{"text":"(","start":131,"end":132,"id":21},{"text":"1954","start":132,"end":136,"id":22},{"text":")","start":136,"end":137,"id":23},{"text":".","start":137,"end":138,"id":24}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"The proposed association matrix also gives rise to the expected generalized confusion matrix in classification.","_input_hash":1450997022,"_task_hash":-495283411,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"proposed","start":4,"end":12,"id":1},{"text":"association","start":13,"end":24,"id":2},{"text":"matrix","start":25,"end":31,"id":3},{"text":"also","start":32,"end":36,"id":4},{"text":"gives","start":37,"end":42,"id":5},{"text":"rise","start":43,"end":47,"id":6},{"text":"to","start":48,"end":50,"id":7},{"text":"the","start":51,"end":54,"id":8},{"text":"expected","start":55,"end":63,"id":9},{"text":"generalized","start":64,"end":75,"id":10},{"text":"confusion","start":76,"end":85,"id":11},{"text":"matrix","start":86,"end":92,"id":12},{"text":"in","start":93,"end":95,"id":13},{"text":"classification","start":96,"end":110,"id":14},{"text":".","start":110,"end":111,"id":15}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"The hierarchy of equivalence relations defined by the association vector and matrix are also shown.","_input_hash":-1553608384,"_task_hash":2107212476,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"hierarchy","start":4,"end":13,"id":1},{"text":"of","start":14,"end":16,"id":2},{"text":"equivalence","start":17,"end":28,"id":3},{"text":"relations","start":29,"end":38,"id":4},{"text":"defined","start":39,"end":46,"id":5},{"text":"by","start":47,"end":49,"id":6},{"text":"the","start":50,"end":53,"id":7},{"text":"association","start":54,"end":65,"id":8},{"text":"vector","start":66,"end":72,"id":9},{"text":"and","start":73,"end":76,"id":10},{"text":"matrix","start":77,"end":83,"id":11},{"text":"are","start":84,"end":87,"id":12},{"text":"also","start":88,"end":92,"id":13},{"text":"shown","start":93,"end":98,"id":14},{"text":".","start":98,"end":99,"id":15}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"This survey is an introduction to positive definite kernels and the set of methods they have inspired in the machine learning literature, namely kernel methods.","_input_hash":-1965380037,"_task_hash":1194215130,"tokens":[{"text":"This","start":0,"end":4,"id":0},{"text":"survey","start":5,"end":11,"id":1},{"text":"is","start":12,"end":14,"id":2},{"text":"an","start":15,"end":17,"id":3},{"text":"introduction","start":18,"end":30,"id":4},{"text":"to","start":31,"end":33,"id":5},{"text":"positive","start":34,"end":42,"id":6},{"text":"definite","start":43,"end":51,"id":7},{"text":"kernels","start":52,"end":59,"id":8},{"text":"and","start":60,"end":63,"id":9},{"text":"the","start":64,"end":67,"id":10},{"text":"set","start":68,"end":71,"id":11},{"text":"of","start":72,"end":74,"id":12},{"text":"methods","start":75,"end":82,"id":13},{"text":"they","start":83,"end":87,"id":14},{"text":"have","start":88,"end":92,"id":15},{"text":"inspired","start":93,"end":101,"id":16},{"text":"in","start":102,"end":104,"id":17},{"text":"the","start":105,"end":108,"id":18},{"text":"machine","start":109,"end":116,"id":19},{"text":"learning","start":117,"end":125,"id":20},{"text":"literature","start":126,"end":136,"id":21},{"text":",","start":136,"end":137,"id":22},{"text":"namely","start":138,"end":144,"id":23},{"text":"kernel","start":145,"end":151,"id":24},{"text":"methods","start":152,"end":159,"id":25},{"text":".","start":159,"end":160,"id":26}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We first discuss some properties of positive definite kernels as well as reproducing kernel Hibert spaces, the natural extension of the set of functions $\\{k(x,\\cdot),x\\in\\mathcal{X}\\}$ associated with a kernel $k$ defined on a space $\\mathcal{X}$. We discuss at length the construction of kernel functions that take advantage of well-known statistical models.","_input_hash":-198045816,"_task_hash":1582338646,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"first","start":3,"end":8,"id":1},{"text":"discuss","start":9,"end":16,"id":2},{"text":"some","start":17,"end":21,"id":3},{"text":"properties","start":22,"end":32,"id":4},{"text":"of","start":33,"end":35,"id":5},{"text":"positive","start":36,"end":44,"id":6},{"text":"definite","start":45,"end":53,"id":7},{"text":"kernels","start":54,"end":61,"id":8},{"text":"as","start":62,"end":64,"id":9},{"text":"well","start":65,"end":69,"id":10},{"text":"as","start":70,"end":72,"id":11},{"text":"reproducing","start":73,"end":84,"id":12},{"text":"kernel","start":85,"end":91,"id":13},{"text":"Hibert","start":92,"end":98,"id":14},{"text":"spaces","start":99,"end":105,"id":15},{"text":",","start":105,"end":106,"id":16},{"text":"the","start":107,"end":110,"id":17},{"text":"natural","start":111,"end":118,"id":18},{"text":"extension","start":119,"end":128,"id":19},{"text":"of","start":129,"end":131,"id":20},{"text":"the","start":132,"end":135,"id":21},{"text":"set","start":136,"end":139,"id":22},{"text":"of","start":140,"end":142,"id":23},{"text":"functions","start":143,"end":152,"id":24},{"text":"$","start":153,"end":154,"id":25},{"text":"\\{k(x,\\cdot),x\\in\\mathcal{X}\\}$","start":154,"end":185,"id":26},{"text":"associated","start":186,"end":196,"id":27},{"text":"with","start":197,"end":201,"id":28},{"text":"a","start":202,"end":203,"id":29},{"text":"kernel","start":204,"end":210,"id":30},{"text":"$","start":211,"end":212,"id":31},{"text":"k$","start":212,"end":214,"id":32},{"text":"defined","start":215,"end":222,"id":33},{"text":"on","start":223,"end":225,"id":34},{"text":"a","start":226,"end":227,"id":35},{"text":"space","start":228,"end":233,"id":36},{"text":"$","start":234,"end":235,"id":37},{"text":"\\mathcal{X}$.","start":235,"end":248,"id":38},{"text":"We","start":249,"end":251,"id":39},{"text":"discuss","start":252,"end":259,"id":40},{"text":"at","start":260,"end":262,"id":41},{"text":"length","start":263,"end":269,"id":42},{"text":"the","start":270,"end":273,"id":43},{"text":"construction","start":274,"end":286,"id":44},{"text":"of","start":287,"end":289,"id":45},{"text":"kernel","start":290,"end":296,"id":46},{"text":"functions","start":297,"end":306,"id":47},{"text":"that","start":307,"end":311,"id":48},{"text":"take","start":312,"end":316,"id":49},{"text":"advantage","start":317,"end":326,"id":50},{"text":"of","start":327,"end":329,"id":51},{"text":"well","start":330,"end":334,"id":52},{"text":"-","start":334,"end":335,"id":53},{"text":"known","start":335,"end":340,"id":54},{"text":"statistical","start":341,"end":352,"id":55},{"text":"models","start":353,"end":359,"id":56},{"text":".","start":359,"end":360,"id":57}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":85,"end":105,"token_start":13,"token_end":15,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"We provide an overview of numerous data-analysis methods which take advantage of reproducing kernel Hilbert spaces and discuss the idea of combining several kernels to improve the performance on certain tasks.","_input_hash":982284119,"_task_hash":-1034410034,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"provide","start":3,"end":10,"id":1},{"text":"an","start":11,"end":13,"id":2},{"text":"overview","start":14,"end":22,"id":3},{"text":"of","start":23,"end":25,"id":4},{"text":"numerous","start":26,"end":34,"id":5},{"text":"data","start":35,"end":39,"id":6},{"text":"-","start":39,"end":40,"id":7},{"text":"analysis","start":40,"end":48,"id":8},{"text":"methods","start":49,"end":56,"id":9},{"text":"which","start":57,"end":62,"id":10},{"text":"take","start":63,"end":67,"id":11},{"text":"advantage","start":68,"end":77,"id":12},{"text":"of","start":78,"end":80,"id":13},{"text":"reproducing","start":81,"end":92,"id":14},{"text":"kernel","start":93,"end":99,"id":15},{"text":"Hilbert","start":100,"end":107,"id":16},{"text":"spaces","start":108,"end":114,"id":17},{"text":"and","start":115,"end":118,"id":18},{"text":"discuss","start":119,"end":126,"id":19},{"text":"the","start":127,"end":130,"id":20},{"text":"idea","start":131,"end":135,"id":21},{"text":"of","start":136,"end":138,"id":22},{"text":"combining","start":139,"end":148,"id":23},{"text":"several","start":149,"end":156,"id":24},{"text":"kernels","start":157,"end":164,"id":25},{"text":"to","start":165,"end":167,"id":26},{"text":"improve","start":168,"end":175,"id":27},{"text":"the","start":176,"end":179,"id":28},{"text":"performance","start":180,"end":191,"id":29},{"text":"on","start":192,"end":194,"id":30},{"text":"certain","start":195,"end":202,"id":31},{"text":"tasks","start":203,"end":208,"id":32},{"text":".","start":208,"end":209,"id":33}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":93,"end":114,"token_start":15,"token_end":17,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"We also provide a short cookbook of different kernels which are particularly useful for certain data-types such as images, graphs or speech segments.","_input_hash":-2019130877,"_task_hash":1483528114,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"also","start":3,"end":7,"id":1},{"text":"provide","start":8,"end":15,"id":2},{"text":"a","start":16,"end":17,"id":3},{"text":"short","start":18,"end":23,"id":4},{"text":"cookbook","start":24,"end":32,"id":5},{"text":"of","start":33,"end":35,"id":6},{"text":"different","start":36,"end":45,"id":7},{"text":"kernels","start":46,"end":53,"id":8},{"text":"which","start":54,"end":59,"id":9},{"text":"are","start":60,"end":63,"id":10},{"text":"particularly","start":64,"end":76,"id":11},{"text":"useful","start":77,"end":83,"id":12},{"text":"for","start":84,"end":87,"id":13},{"text":"certain","start":88,"end":95,"id":14},{"text":"data","start":96,"end":100,"id":15},{"text":"-","start":100,"end":101,"id":16},{"text":"types","start":101,"end":106,"id":17},{"text":"such","start":107,"end":111,"id":18},{"text":"as","start":112,"end":114,"id":19},{"text":"images","start":115,"end":121,"id":20},{"text":",","start":121,"end":122,"id":21},{"text":"graphs","start":123,"end":129,"id":22},{"text":"or","start":130,"end":132,"id":23},{"text":"speech","start":133,"end":139,"id":24},{"text":"segments","start":140,"end":148,"id":25},{"text":".","start":148,"end":149,"id":26}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Gaussian Process (GP) models are often used as mathematical approximations of computationally expensive experiments.","_input_hash":670247834,"_task_hash":170050133,"tokens":[{"text":"Gaussian","start":0,"end":8,"id":0},{"text":"Process","start":9,"end":16,"id":1},{"text":"(","start":17,"end":18,"id":2},{"text":"GP","start":18,"end":20,"id":3},{"text":")","start":20,"end":21,"id":4},{"text":"models","start":22,"end":28,"id":5},{"text":"are","start":29,"end":32,"id":6},{"text":"often","start":33,"end":38,"id":7},{"text":"used","start":39,"end":43,"id":8},{"text":"as","start":44,"end":46,"id":9},{"text":"mathematical","start":47,"end":59,"id":10},{"text":"approximations","start":60,"end":74,"id":11},{"text":"of","start":75,"end":77,"id":12},{"text":"computationally","start":78,"end":93,"id":13},{"text":"expensive","start":94,"end":103,"id":14},{"text":"experiments","start":104,"end":115,"id":15},{"text":".","start":115,"end":116,"id":16}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":0,"end":16,"token_start":0,"token_end":1,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"Provided that its kernel is suitably chosen and that enough data is available to obtain a reasonable fit of the simulator, a GP model can beneficially be used for tasks such as prediction, optimization, or Monte-Carlo-based quantification of uncertainty.","_input_hash":-976644952,"_task_hash":-601296688,"tokens":[{"text":"Provided","start":0,"end":8,"id":0},{"text":"that","start":9,"end":13,"id":1},{"text":"its","start":14,"end":17,"id":2},{"text":"kernel","start":18,"end":24,"id":3},{"text":"is","start":25,"end":27,"id":4},{"text":"suitably","start":28,"end":36,"id":5},{"text":"chosen","start":37,"end":43,"id":6},{"text":"and","start":44,"end":47,"id":7},{"text":"that","start":48,"end":52,"id":8},{"text":"enough","start":53,"end":59,"id":9},{"text":"data","start":60,"end":64,"id":10},{"text":"is","start":65,"end":67,"id":11},{"text":"available","start":68,"end":77,"id":12},{"text":"to","start":78,"end":80,"id":13},{"text":"obtain","start":81,"end":87,"id":14},{"text":"a","start":88,"end":89,"id":15},{"text":"reasonable","start":90,"end":100,"id":16},{"text":"fit","start":101,"end":104,"id":17},{"text":"of","start":105,"end":107,"id":18},{"text":"the","start":108,"end":111,"id":19},{"text":"simulator","start":112,"end":121,"id":20},{"text":",","start":121,"end":122,"id":21},{"text":"a","start":123,"end":124,"id":22},{"text":"GP","start":125,"end":127,"id":23},{"text":"model","start":128,"end":133,"id":24},{"text":"can","start":134,"end":137,"id":25},{"text":"beneficially","start":138,"end":150,"id":26},{"text":"be","start":151,"end":153,"id":27},{"text":"used","start":154,"end":158,"id":28},{"text":"for","start":159,"end":162,"id":29},{"text":"tasks","start":163,"end":168,"id":30},{"text":"such","start":169,"end":173,"id":31},{"text":"as","start":174,"end":176,"id":32},{"text":"prediction","start":177,"end":187,"id":33},{"text":",","start":187,"end":188,"id":34},{"text":"optimization","start":189,"end":201,"id":35},{"text":",","start":201,"end":202,"id":36},{"text":"or","start":203,"end":205,"id":37},{"text":"Monte","start":206,"end":211,"id":38},{"text":"-","start":211,"end":212,"id":39},{"text":"Carlo","start":212,"end":217,"id":40},{"text":"-","start":217,"end":218,"id":41},{"text":"based","start":218,"end":223,"id":42},{"text":"quantification","start":224,"end":238,"id":43},{"text":"of","start":239,"end":241,"id":44},{"text":"uncertainty","start":242,"end":253,"id":45},{"text":".","start":253,"end":254,"id":46}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":125,"end":127,"token_start":23,"token_end":23,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"However, the former conditions become unrealistic when using classical GPs as the dimension of input increases.","_input_hash":-1863853720,"_task_hash":-326074505,"tokens":[{"text":"However","start":0,"end":7,"id":0},{"text":",","start":7,"end":8,"id":1},{"text":"the","start":9,"end":12,"id":2},{"text":"former","start":13,"end":19,"id":3},{"text":"conditions","start":20,"end":30,"id":4},{"text":"become","start":31,"end":37,"id":5},{"text":"unrealistic","start":38,"end":49,"id":6},{"text":"when","start":50,"end":54,"id":7},{"text":"using","start":55,"end":60,"id":8},{"text":"classical","start":61,"end":70,"id":9},{"text":"GPs","start":71,"end":74,"id":10},{"text":"as","start":75,"end":77,"id":11},{"text":"the","start":78,"end":81,"id":12},{"text":"dimension","start":82,"end":91,"id":13},{"text":"of","start":92,"end":94,"id":14},{"text":"input","start":95,"end":100,"id":15},{"text":"increases","start":101,"end":110,"id":16},{"text":".","start":110,"end":111,"id":17}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"One popular alternative is then to turn to Generalized Additive Models (GAMs), relying on the assumption that the simulator's response can approximately be decomposed as a sum of univariate functions.","_input_hash":-392172104,"_task_hash":-1263157791,"tokens":[{"text":"One","start":0,"end":3,"id":0},{"text":"popular","start":4,"end":11,"id":1},{"text":"alternative","start":12,"end":23,"id":2},{"text":"is","start":24,"end":26,"id":3},{"text":"then","start":27,"end":31,"id":4},{"text":"to","start":32,"end":34,"id":5},{"text":"turn","start":35,"end":39,"id":6},{"text":"to","start":40,"end":42,"id":7},{"text":"Generalized","start":43,"end":54,"id":8},{"text":"Additive","start":55,"end":63,"id":9},{"text":"Models","start":64,"end":70,"id":10},{"text":"(","start":71,"end":72,"id":11},{"text":"GAMs","start":72,"end":76,"id":12},{"text":")","start":76,"end":77,"id":13},{"text":",","start":77,"end":78,"id":14},{"text":"relying","start":79,"end":86,"id":15},{"text":"on","start":87,"end":89,"id":16},{"text":"the","start":90,"end":93,"id":17},{"text":"assumption","start":94,"end":104,"id":18},{"text":"that","start":105,"end":109,"id":19},{"text":"the","start":110,"end":113,"id":20},{"text":"simulator","start":114,"end":123,"id":21},{"text":"'s","start":123,"end":125,"id":22},{"text":"response","start":126,"end":134,"id":23},{"text":"can","start":135,"end":138,"id":24},{"text":"approximately","start":139,"end":152,"id":25},{"text":"be","start":153,"end":155,"id":26},{"text":"decomposed","start":156,"end":166,"id":27},{"text":"as","start":167,"end":169,"id":28},{"text":"a","start":170,"end":171,"id":29},{"text":"sum","start":172,"end":175,"id":30},{"text":"of","start":176,"end":178,"id":31},{"text":"univariate","start":179,"end":189,"id":32},{"text":"functions","start":190,"end":199,"id":33},{"text":".","start":199,"end":200,"id":34}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":43,"end":63,"token_start":8,"token_end":9,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"If such an approach has been successfully applied in approximation, it is nevertheless not completely compatible with the GP framework and its versatile applications.","_input_hash":971029681,"_task_hash":-394280523,"tokens":[{"text":"If","start":0,"end":2,"id":0},{"text":"such","start":3,"end":7,"id":1},{"text":"an","start":8,"end":10,"id":2},{"text":"approach","start":11,"end":19,"id":3},{"text":"has","start":20,"end":23,"id":4},{"text":"been","start":24,"end":28,"id":5},{"text":"successfully","start":29,"end":41,"id":6},{"text":"applied","start":42,"end":49,"id":7},{"text":"in","start":50,"end":52,"id":8},{"text":"approximation","start":53,"end":66,"id":9},{"text":",","start":66,"end":67,"id":10},{"text":"it","start":68,"end":70,"id":11},{"text":"is","start":71,"end":73,"id":12},{"text":"nevertheless","start":74,"end":86,"id":13},{"text":"not","start":87,"end":90,"id":14},{"text":"completely","start":91,"end":101,"id":15},{"text":"compatible","start":102,"end":112,"id":16},{"text":"with","start":113,"end":117,"id":17},{"text":"the","start":118,"end":121,"id":18},{"text":"GP","start":122,"end":124,"id":19},{"text":"framework","start":125,"end":134,"id":20},{"text":"and","start":135,"end":138,"id":21},{"text":"its","start":139,"end":142,"id":22},{"text":"versatile","start":143,"end":152,"id":23},{"text":"applications","start":153,"end":165,"id":24},{"text":".","start":165,"end":166,"id":25}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"The ambition of the present work is to give an insight into the use of GPs for additive models by integrating additivity within the kernel, and proposing a parsimonious numerical method for data-driven parameter estimation.","_input_hash":1306578922,"_task_hash":-948948934,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"ambition","start":4,"end":12,"id":1},{"text":"of","start":13,"end":15,"id":2},{"text":"the","start":16,"end":19,"id":3},{"text":"present","start":20,"end":27,"id":4},{"text":"work","start":28,"end":32,"id":5},{"text":"is","start":33,"end":35,"id":6},{"text":"to","start":36,"end":38,"id":7},{"text":"give","start":39,"end":43,"id":8},{"text":"an","start":44,"end":46,"id":9},{"text":"insight","start":47,"end":54,"id":10},{"text":"into","start":55,"end":59,"id":11},{"text":"the","start":60,"end":63,"id":12},{"text":"use","start":64,"end":67,"id":13},{"text":"of","start":68,"end":70,"id":14},{"text":"GPs","start":71,"end":74,"id":15},{"text":"for","start":75,"end":78,"id":16},{"text":"additive","start":79,"end":87,"id":17},{"text":"models","start":88,"end":94,"id":18},{"text":"by","start":95,"end":97,"id":19},{"text":"integrating","start":98,"end":109,"id":20},{"text":"additivity","start":110,"end":120,"id":21},{"text":"within","start":121,"end":127,"id":22},{"text":"the","start":128,"end":131,"id":23},{"text":"kernel","start":132,"end":138,"id":24},{"text":",","start":138,"end":139,"id":25},{"text":"and","start":140,"end":143,"id":26},{"text":"proposing","start":144,"end":153,"id":27},{"text":"a","start":154,"end":155,"id":28},{"text":"parsimonious","start":156,"end":168,"id":29},{"text":"numerical","start":169,"end":178,"id":30},{"text":"method","start":179,"end":185,"id":31},{"text":"for","start":186,"end":189,"id":32},{"text":"data","start":190,"end":194,"id":33},{"text":"-","start":194,"end":195,"id":34},{"text":"driven","start":195,"end":201,"id":35},{"text":"parameter","start":202,"end":211,"id":36},{"text":"estimation","start":212,"end":222,"id":37},{"text":".","start":222,"end":223,"id":38}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":79,"end":87,"token_start":17,"token_end":17,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"The first part of this article deals with the kernels naturally associated to additive processes and the properties of the GP models based on such kernels.","_input_hash":1746562662,"_task_hash":-1208247135,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"first","start":4,"end":9,"id":1},{"text":"part","start":10,"end":14,"id":2},{"text":"of","start":15,"end":17,"id":3},{"text":"this","start":18,"end":22,"id":4},{"text":"article","start":23,"end":30,"id":5},{"text":"deals","start":31,"end":36,"id":6},{"text":"with","start":37,"end":41,"id":7},{"text":"the","start":42,"end":45,"id":8},{"text":"kernels","start":46,"end":53,"id":9},{"text":"naturally","start":54,"end":63,"id":10},{"text":"associated","start":64,"end":74,"id":11},{"text":"to","start":75,"end":77,"id":12},{"text":"additive","start":78,"end":86,"id":13},{"text":"processes","start":87,"end":96,"id":14},{"text":"and","start":97,"end":100,"id":15},{"text":"the","start":101,"end":104,"id":16},{"text":"properties","start":105,"end":115,"id":17},{"text":"of","start":116,"end":118,"id":18},{"text":"the","start":119,"end":122,"id":19},{"text":"GP","start":123,"end":125,"id":20},{"text":"models","start":126,"end":132,"id":21},{"text":"based","start":133,"end":138,"id":22},{"text":"on","start":139,"end":141,"id":23},{"text":"such","start":142,"end":146,"id":24},{"text":"kernels","start":147,"end":154,"id":25},{"text":".","start":154,"end":155,"id":26}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":123,"end":125,"token_start":20,"token_end":20,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"The second part is dedicated to a numerical procedure based on relaxation for additive kernel parameter estimation.","_input_hash":-782054155,"_task_hash":873609877,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"second","start":4,"end":10,"id":1},{"text":"part","start":11,"end":15,"id":2},{"text":"is","start":16,"end":18,"id":3},{"text":"dedicated","start":19,"end":28,"id":4},{"text":"to","start":29,"end":31,"id":5},{"text":"a","start":32,"end":33,"id":6},{"text":"numerical","start":34,"end":43,"id":7},{"text":"procedure","start":44,"end":53,"id":8},{"text":"based","start":54,"end":59,"id":9},{"text":"on","start":60,"end":62,"id":10},{"text":"relaxation","start":63,"end":73,"id":11},{"text":"for","start":74,"end":77,"id":12},{"text":"additive","start":78,"end":86,"id":13},{"text":"kernel","start":87,"end":93,"id":14},{"text":"parameter","start":94,"end":103,"id":15},{"text":"estimation","start":104,"end":114,"id":16},{"text":".","start":114,"end":115,"id":17}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Finally, the efficiency of the proposed method is illustrated and compared to other approaches on Sobol's g-function.","_input_hash":635936544,"_task_hash":1360671616,"tokens":[{"text":"Finally","start":0,"end":7,"id":0},{"text":",","start":7,"end":8,"id":1},{"text":"the","start":9,"end":12,"id":2},{"text":"efficiency","start":13,"end":23,"id":3},{"text":"of","start":24,"end":26,"id":4},{"text":"the","start":27,"end":30,"id":5},{"text":"proposed","start":31,"end":39,"id":6},{"text":"method","start":40,"end":46,"id":7},{"text":"is","start":47,"end":49,"id":8},{"text":"illustrated","start":50,"end":61,"id":9},{"text":"and","start":62,"end":65,"id":10},{"text":"compared","start":66,"end":74,"id":11},{"text":"to","start":75,"end":77,"id":12},{"text":"other","start":78,"end":83,"id":13},{"text":"approaches","start":84,"end":94,"id":14},{"text":"on","start":95,"end":97,"id":15},{"text":"Sobol","start":98,"end":103,"id":16},{"text":"'s","start":103,"end":105,"id":17},{"text":"g","start":106,"end":107,"id":18},{"text":"-","start":107,"end":108,"id":19},{"text":"function","start":108,"end":116,"id":20},{"text":".","start":116,"end":117,"id":21}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Often we wish to predict a large number of variables that depend on each other as well as on other observed variables.","_input_hash":1800825620,"_task_hash":439794955,"tokens":[{"text":"Often","start":0,"end":5,"id":0},{"text":"we","start":6,"end":8,"id":1},{"text":"wish","start":9,"end":13,"id":2},{"text":"to","start":14,"end":16,"id":3},{"text":"predict","start":17,"end":24,"id":4},{"text":"a","start":25,"end":26,"id":5},{"text":"large","start":27,"end":32,"id":6},{"text":"number","start":33,"end":39,"id":7},{"text":"of","start":40,"end":42,"id":8},{"text":"variables","start":43,"end":52,"id":9},{"text":"that","start":53,"end":57,"id":10},{"text":"depend","start":58,"end":64,"id":11},{"text":"on","start":65,"end":67,"id":12},{"text":"each","start":68,"end":72,"id":13},{"text":"other","start":73,"end":78,"id":14},{"text":"as","start":79,"end":81,"id":15},{"text":"well","start":82,"end":86,"id":16},{"text":"as","start":87,"end":89,"id":17},{"text":"on","start":90,"end":92,"id":18},{"text":"other","start":93,"end":98,"id":19},{"text":"observed","start":99,"end":107,"id":20},{"text":"variables","start":108,"end":117,"id":21},{"text":".","start":117,"end":118,"id":22}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Structured prediction methods are essentially a combination of classification and graphical modeling, combining the ability of graphical models to compactly model multivariate data with the ability of classification methods to perform prediction using large sets of input features.","_input_hash":-707939180,"_task_hash":-764039719,"tokens":[{"text":"Structured","start":0,"end":10,"id":0},{"text":"prediction","start":11,"end":21,"id":1},{"text":"methods","start":22,"end":29,"id":2},{"text":"are","start":30,"end":33,"id":3},{"text":"essentially","start":34,"end":45,"id":4},{"text":"a","start":46,"end":47,"id":5},{"text":"combination","start":48,"end":59,"id":6},{"text":"of","start":60,"end":62,"id":7},{"text":"classification","start":63,"end":77,"id":8},{"text":"and","start":78,"end":81,"id":9},{"text":"graphical","start":82,"end":91,"id":10},{"text":"modeling","start":92,"end":100,"id":11},{"text":",","start":100,"end":101,"id":12},{"text":"combining","start":102,"end":111,"id":13},{"text":"the","start":112,"end":115,"id":14},{"text":"ability","start":116,"end":123,"id":15},{"text":"of","start":124,"end":126,"id":16},{"text":"graphical","start":127,"end":136,"id":17},{"text":"models","start":137,"end":143,"id":18},{"text":"to","start":144,"end":146,"id":19},{"text":"compactly","start":147,"end":156,"id":20},{"text":"model","start":157,"end":162,"id":21},{"text":"multivariate","start":163,"end":175,"id":22},{"text":"data","start":176,"end":180,"id":23},{"text":"with","start":181,"end":185,"id":24},{"text":"the","start":186,"end":189,"id":25},{"text":"ability","start":190,"end":197,"id":26},{"text":"of","start":198,"end":200,"id":27},{"text":"classification","start":201,"end":215,"id":28},{"text":"methods","start":216,"end":223,"id":29},{"text":"to","start":224,"end":226,"id":30},{"text":"perform","start":227,"end":234,"id":31},{"text":"prediction","start":235,"end":245,"id":32},{"text":"using","start":246,"end":251,"id":33},{"text":"large","start":252,"end":257,"id":34},{"text":"sets","start":258,"end":262,"id":35},{"text":"of","start":263,"end":265,"id":36},{"text":"input","start":266,"end":271,"id":37},{"text":"features","start":272,"end":280,"id":38},{"text":".","start":280,"end":281,"id":39}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"This tutorial describes conditional random fields, a popular probabilistic method for structured prediction.","_input_hash":394919922,"_task_hash":-869781256,"tokens":[{"text":"This","start":0,"end":4,"id":0},{"text":"tutorial","start":5,"end":13,"id":1},{"text":"describes","start":14,"end":23,"id":2},{"text":"conditional","start":24,"end":35,"id":3},{"text":"random","start":36,"end":42,"id":4},{"text":"fields","start":43,"end":49,"id":5},{"text":",","start":49,"end":50,"id":6},{"text":"a","start":51,"end":52,"id":7},{"text":"popular","start":53,"end":60,"id":8},{"text":"probabilistic","start":61,"end":74,"id":9},{"text":"method","start":75,"end":81,"id":10},{"text":"for","start":82,"end":85,"id":11},{"text":"structured","start":86,"end":96,"id":12},{"text":"prediction","start":97,"end":107,"id":13},{"text":".","start":107,"end":108,"id":14}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":24,"end":49,"token_start":3,"token_end":5,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"CRFs have seen wide application in natural language processing, computer vision, and bioinformatics.","_input_hash":44361548,"_task_hash":-849679333,"tokens":[{"text":"CRFs","start":0,"end":4,"id":0},{"text":"have","start":5,"end":9,"id":1},{"text":"seen","start":10,"end":14,"id":2},{"text":"wide","start":15,"end":19,"id":3},{"text":"application","start":20,"end":31,"id":4},{"text":"in","start":32,"end":34,"id":5},{"text":"natural","start":35,"end":42,"id":6},{"text":"language","start":43,"end":51,"id":7},{"text":"processing","start":52,"end":62,"id":8},{"text":",","start":62,"end":63,"id":9},{"text":"computer","start":64,"end":72,"id":10},{"text":"vision","start":73,"end":79,"id":11},{"text":",","start":79,"end":80,"id":12},{"text":"and","start":81,"end":84,"id":13},{"text":"bioinformatics","start":85,"end":99,"id":14},{"text":".","start":99,"end":100,"id":15}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":35,"end":62,"token_start":6,"token_end":8,"label":"ALGO","answer":"accept"},{"start":64,"end":79,"token_start":10,"token_end":11,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"We describe methods for inference and parameter estimation for CRFs, including practical issues for implementing large scale CRFs.","_input_hash":1519532255,"_task_hash":1964512663,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"describe","start":3,"end":11,"id":1},{"text":"methods","start":12,"end":19,"id":2},{"text":"for","start":20,"end":23,"id":3},{"text":"inference","start":24,"end":33,"id":4},{"text":"and","start":34,"end":37,"id":5},{"text":"parameter","start":38,"end":47,"id":6},{"text":"estimation","start":48,"end":58,"id":7},{"text":"for","start":59,"end":62,"id":8},{"text":"CRFs","start":63,"end":67,"id":9},{"text":",","start":67,"end":68,"id":10},{"text":"including","start":69,"end":78,"id":11},{"text":"practical","start":79,"end":88,"id":12},{"text":"issues","start":89,"end":95,"id":13},{"text":"for","start":96,"end":99,"id":14},{"text":"implementing","start":100,"end":112,"id":15},{"text":"large","start":113,"end":118,"id":16},{"text":"scale","start":119,"end":124,"id":17},{"text":"CRFs","start":125,"end":129,"id":18},{"text":".","start":129,"end":130,"id":19}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We do not assume previous knowledge of graphical modeling, so this tutorial is intended to be useful to practitioners in a wide variety of fields.","_input_hash":-677887820,"_task_hash":1466617882,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"do","start":3,"end":5,"id":1},{"text":"not","start":6,"end":9,"id":2},{"text":"assume","start":10,"end":16,"id":3},{"text":"previous","start":17,"end":25,"id":4},{"text":"knowledge","start":26,"end":35,"id":5},{"text":"of","start":36,"end":38,"id":6},{"text":"graphical","start":39,"end":48,"id":7},{"text":"modeling","start":49,"end":57,"id":8},{"text":",","start":57,"end":58,"id":9},{"text":"so","start":59,"end":61,"id":10},{"text":"this","start":62,"end":66,"id":11},{"text":"tutorial","start":67,"end":75,"id":12},{"text":"is","start":76,"end":78,"id":13},{"text":"intended","start":79,"end":87,"id":14},{"text":"to","start":88,"end":90,"id":15},{"text":"be","start":91,"end":93,"id":16},{"text":"useful","start":94,"end":100,"id":17},{"text":"to","start":101,"end":103,"id":18},{"text":"practitioners","start":104,"end":117,"id":19},{"text":"in","start":118,"end":120,"id":20},{"text":"a","start":121,"end":122,"id":21},{"text":"wide","start":123,"end":127,"id":22},{"text":"variety","start":128,"end":135,"id":23},{"text":"of","start":136,"end":138,"id":24},{"text":"fields","start":139,"end":145,"id":25},{"text":".","start":145,"end":146,"id":26}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"A number of recent work studied the effectiveness of feature selection using Lasso.","_input_hash":1958959253,"_task_hash":139633786,"tokens":[{"text":"A","start":0,"end":1,"id":0},{"text":"number","start":2,"end":8,"id":1},{"text":"of","start":9,"end":11,"id":2},{"text":"recent","start":12,"end":18,"id":3},{"text":"work","start":19,"end":23,"id":4},{"text":"studied","start":24,"end":31,"id":5},{"text":"the","start":32,"end":35,"id":6},{"text":"effectiveness","start":36,"end":49,"id":7},{"text":"of","start":50,"end":52,"id":8},{"text":"feature","start":53,"end":60,"id":9},{"text":"selection","start":61,"end":70,"id":10},{"text":"using","start":71,"end":76,"id":11},{"text":"Lasso","start":77,"end":82,"id":12},{"text":".","start":82,"end":83,"id":13}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":77,"end":82,"token_start":12,"token_end":12,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"It is known that under the restricted isometry properties (RIP), Lasso does not generally lead to the exact recovery of the set of nonzero coefficients, due to the looseness of convex relaxation.","_input_hash":426287258,"_task_hash":937716002,"tokens":[{"text":"It","start":0,"end":2,"id":0},{"text":"is","start":3,"end":5,"id":1},{"text":"known","start":6,"end":11,"id":2},{"text":"that","start":12,"end":16,"id":3},{"text":"under","start":17,"end":22,"id":4},{"text":"the","start":23,"end":26,"id":5},{"text":"restricted","start":27,"end":37,"id":6},{"text":"isometry","start":38,"end":46,"id":7},{"text":"properties","start":47,"end":57,"id":8},{"text":"(","start":58,"end":59,"id":9},{"text":"RIP","start":59,"end":62,"id":10},{"text":")","start":62,"end":63,"id":11},{"text":",","start":63,"end":64,"id":12},{"text":"Lasso","start":65,"end":70,"id":13},{"text":"does","start":71,"end":75,"id":14},{"text":"not","start":76,"end":79,"id":15},{"text":"generally","start":80,"end":89,"id":16},{"text":"lead","start":90,"end":94,"id":17},{"text":"to","start":95,"end":97,"id":18},{"text":"the","start":98,"end":101,"id":19},{"text":"exact","start":102,"end":107,"id":20},{"text":"recovery","start":108,"end":116,"id":21},{"text":"of","start":117,"end":119,"id":22},{"text":"the","start":120,"end":123,"id":23},{"text":"set","start":124,"end":127,"id":24},{"text":"of","start":128,"end":130,"id":25},{"text":"nonzero","start":131,"end":138,"id":26},{"text":"coefficients","start":139,"end":151,"id":27},{"text":",","start":151,"end":152,"id":28},{"text":"due","start":153,"end":156,"id":29},{"text":"to","start":157,"end":159,"id":30},{"text":"the","start":160,"end":163,"id":31},{"text":"looseness","start":164,"end":173,"id":32},{"text":"of","start":174,"end":176,"id":33},{"text":"convex","start":177,"end":183,"id":34},{"text":"relaxation","start":184,"end":194,"id":35},{"text":".","start":194,"end":195,"id":36}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":65,"end":70,"token_start":13,"token_end":13,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"This paper considers the feature selection property of nonconvex regularization, where the solution is given by a multi-stage convex relaxation scheme.","_input_hash":-1222205579,"_task_hash":-114923835,"tokens":[{"text":"This","start":0,"end":4,"id":0},{"text":"paper","start":5,"end":10,"id":1},{"text":"considers","start":11,"end":20,"id":2},{"text":"the","start":21,"end":24,"id":3},{"text":"feature","start":25,"end":32,"id":4},{"text":"selection","start":33,"end":42,"id":5},{"text":"property","start":43,"end":51,"id":6},{"text":"of","start":52,"end":54,"id":7},{"text":"nonconvex","start":55,"end":64,"id":8},{"text":"regularization","start":65,"end":79,"id":9},{"text":",","start":79,"end":80,"id":10},{"text":"where","start":81,"end":86,"id":11},{"text":"the","start":87,"end":90,"id":12},{"text":"solution","start":91,"end":99,"id":13},{"text":"is","start":100,"end":102,"id":14},{"text":"given","start":103,"end":108,"id":15},{"text":"by","start":109,"end":111,"id":16},{"text":"a","start":112,"end":113,"id":17},{"text":"multi","start":114,"end":119,"id":18},{"text":"-","start":119,"end":120,"id":19},{"text":"stage","start":120,"end":125,"id":20},{"text":"convex","start":126,"end":132,"id":21},{"text":"relaxation","start":133,"end":143,"id":22},{"text":"scheme","start":144,"end":150,"id":23},{"text":".","start":150,"end":151,"id":24}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Under appropriate conditions, we show that the local solution obtained by this procedure recovers the set of nonzero coefficients without suffering from the bias of Lasso relaxation, which complements parameter estimation results of this procedure.","_input_hash":-2115300693,"_task_hash":-658052624,"tokens":[{"text":"Under","start":0,"end":5,"id":0},{"text":"appropriate","start":6,"end":17,"id":1},{"text":"conditions","start":18,"end":28,"id":2},{"text":",","start":28,"end":29,"id":3},{"text":"we","start":30,"end":32,"id":4},{"text":"show","start":33,"end":37,"id":5},{"text":"that","start":38,"end":42,"id":6},{"text":"the","start":43,"end":46,"id":7},{"text":"local","start":47,"end":52,"id":8},{"text":"solution","start":53,"end":61,"id":9},{"text":"obtained","start":62,"end":70,"id":10},{"text":"by","start":71,"end":73,"id":11},{"text":"this","start":74,"end":78,"id":12},{"text":"procedure","start":79,"end":88,"id":13},{"text":"recovers","start":89,"end":97,"id":14},{"text":"the","start":98,"end":101,"id":15},{"text":"set","start":102,"end":105,"id":16},{"text":"of","start":106,"end":108,"id":17},{"text":"nonzero","start":109,"end":116,"id":18},{"text":"coefficients","start":117,"end":129,"id":19},{"text":"without","start":130,"end":137,"id":20},{"text":"suffering","start":138,"end":147,"id":21},{"text":"from","start":148,"end":152,"id":22},{"text":"the","start":153,"end":156,"id":23},{"text":"bias","start":157,"end":161,"id":24},{"text":"of","start":162,"end":164,"id":25},{"text":"Lasso","start":165,"end":170,"id":26},{"text":"relaxation","start":171,"end":181,"id":27},{"text":",","start":181,"end":182,"id":28},{"text":"which","start":183,"end":188,"id":29},{"text":"complements","start":189,"end":200,"id":30},{"text":"parameter","start":201,"end":210,"id":31},{"text":"estimation","start":211,"end":221,"id":32},{"text":"results","start":222,"end":229,"id":33},{"text":"of","start":230,"end":232,"id":34},{"text":"this","start":233,"end":237,"id":35},{"text":"procedure","start":238,"end":247,"id":36},{"text":".","start":247,"end":248,"id":37}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":165,"end":170,"token_start":26,"token_end":26,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"Supervised linear feature extraction can be achieved by fitting a reduced rank multivariate model.","_input_hash":-1866299422,"_task_hash":-1189508971,"tokens":[{"text":"Supervised","start":0,"end":10,"id":0},{"text":"linear","start":11,"end":17,"id":1},{"text":"feature","start":18,"end":25,"id":2},{"text":"extraction","start":26,"end":36,"id":3},{"text":"can","start":37,"end":40,"id":4},{"text":"be","start":41,"end":43,"id":5},{"text":"achieved","start":44,"end":52,"id":6},{"text":"by","start":53,"end":55,"id":7},{"text":"fitting","start":56,"end":63,"id":8},{"text":"a","start":64,"end":65,"id":9},{"text":"reduced","start":66,"end":73,"id":10},{"text":"rank","start":74,"end":78,"id":11},{"text":"multivariate","start":79,"end":91,"id":12},{"text":"model","start":92,"end":97,"id":13},{"text":".","start":97,"end":98,"id":14}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":66,"end":91,"token_start":10,"token_end":12,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"This paper studies rank penalized and rank constrained vector generalized linear models.","_input_hash":1737078853,"_task_hash":-1954958637,"tokens":[{"text":"This","start":0,"end":4,"id":0},{"text":"paper","start":5,"end":10,"id":1},{"text":"studies","start":11,"end":18,"id":2},{"text":"rank","start":19,"end":23,"id":3},{"text":"penalized","start":24,"end":33,"id":4},{"text":"and","start":34,"end":37,"id":5},{"text":"rank","start":38,"end":42,"id":6},{"text":"constrained","start":43,"end":54,"id":7},{"text":"vector","start":55,"end":61,"id":8},{"text":"generalized","start":62,"end":73,"id":9},{"text":"linear","start":74,"end":80,"id":10},{"text":"models","start":81,"end":87,"id":11},{"text":".","start":87,"end":88,"id":12}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":38,"end":80,"token_start":6,"token_end":10,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"From the perspective of thresholding rules, we build a framework for fitting singular value penalized models and use it for feature extraction.","_input_hash":-2099256721,"_task_hash":514562421,"tokens":[{"text":"From","start":0,"end":4,"id":0},{"text":"the","start":5,"end":8,"id":1},{"text":"perspective","start":9,"end":20,"id":2},{"text":"of","start":21,"end":23,"id":3},{"text":"thresholding","start":24,"end":36,"id":4},{"text":"rules","start":37,"end":42,"id":5},{"text":",","start":42,"end":43,"id":6},{"text":"we","start":44,"end":46,"id":7},{"text":"build","start":47,"end":52,"id":8},{"text":"a","start":53,"end":54,"id":9},{"text":"framework","start":55,"end":64,"id":10},{"text":"for","start":65,"end":68,"id":11},{"text":"fitting","start":69,"end":76,"id":12},{"text":"singular","start":77,"end":85,"id":13},{"text":"value","start":86,"end":91,"id":14},{"text":"penalized","start":92,"end":101,"id":15},{"text":"models","start":102,"end":108,"id":16},{"text":"and","start":109,"end":112,"id":17},{"text":"use","start":113,"end":116,"id":18},{"text":"it","start":117,"end":119,"id":19},{"text":"for","start":120,"end":123,"id":20},{"text":"feature","start":124,"end":131,"id":21},{"text":"extraction","start":132,"end":142,"id":22},{"text":".","start":142,"end":143,"id":23}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Through solving the rank constraint form of the problem, we propose progressive feature space reduction for fast computation in high dimensions with little performance loss.","_input_hash":-350548578,"_task_hash":-1144956439,"tokens":[{"text":"Through","start":0,"end":7,"id":0},{"text":"solving","start":8,"end":15,"id":1},{"text":"the","start":16,"end":19,"id":2},{"text":"rank","start":20,"end":24,"id":3},{"text":"constraint","start":25,"end":35,"id":4},{"text":"form","start":36,"end":40,"id":5},{"text":"of","start":41,"end":43,"id":6},{"text":"the","start":44,"end":47,"id":7},{"text":"problem","start":48,"end":55,"id":8},{"text":",","start":55,"end":56,"id":9},{"text":"we","start":57,"end":59,"id":10},{"text":"propose","start":60,"end":67,"id":11},{"text":"progressive","start":68,"end":79,"id":12},{"text":"feature","start":80,"end":87,"id":13},{"text":"space","start":88,"end":93,"id":14},{"text":"reduction","start":94,"end":103,"id":15},{"text":"for","start":104,"end":107,"id":16},{"text":"fast","start":108,"end":112,"id":17},{"text":"computation","start":113,"end":124,"id":18},{"text":"in","start":125,"end":127,"id":19},{"text":"high","start":128,"end":132,"id":20},{"text":"dimensions","start":133,"end":143,"id":21},{"text":"with","start":144,"end":148,"id":22},{"text":"little","start":149,"end":155,"id":23},{"text":"performance","start":156,"end":167,"id":24},{"text":"loss","start":168,"end":172,"id":25},{"text":".","start":172,"end":173,"id":26}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"A novel projective cross-validation is proposed for parameter tuning in such nonconvex setups.","_input_hash":-2125718302,"_task_hash":-56366845,"tokens":[{"text":"A","start":0,"end":1,"id":0},{"text":"novel","start":2,"end":7,"id":1},{"text":"projective","start":8,"end":18,"id":2},{"text":"cross","start":19,"end":24,"id":3},{"text":"-","start":24,"end":25,"id":4},{"text":"validation","start":25,"end":35,"id":5},{"text":"is","start":36,"end":38,"id":6},{"text":"proposed","start":39,"end":47,"id":7},{"text":"for","start":48,"end":51,"id":8},{"text":"parameter","start":52,"end":61,"id":9},{"text":"tuning","start":62,"end":68,"id":10},{"text":"in","start":69,"end":71,"id":11},{"text":"such","start":72,"end":76,"id":12},{"text":"nonconvex","start":77,"end":86,"id":13},{"text":"setups","start":87,"end":93,"id":14},{"text":".","start":93,"end":94,"id":15}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Real data applications are given to show the power of the methodology in supervised dimension reduction and feature extraction.","_input_hash":-1475094938,"_task_hash":1808237124,"tokens":[{"text":"Real","start":0,"end":4,"id":0},{"text":"data","start":5,"end":9,"id":1},{"text":"applications","start":10,"end":22,"id":2},{"text":"are","start":23,"end":26,"id":3},{"text":"given","start":27,"end":32,"id":4},{"text":"to","start":33,"end":35,"id":5},{"text":"show","start":36,"end":40,"id":6},{"text":"the","start":41,"end":44,"id":7},{"text":"power","start":45,"end":50,"id":8},{"text":"of","start":51,"end":53,"id":9},{"text":"the","start":54,"end":57,"id":10},{"text":"methodology","start":58,"end":69,"id":11},{"text":"in","start":70,"end":72,"id":12},{"text":"supervised","start":73,"end":83,"id":13},{"text":"dimension","start":84,"end":93,"id":14},{"text":"reduction","start":94,"end":103,"id":15},{"text":"and","start":104,"end":107,"id":16},{"text":"feature","start":108,"end":115,"id":17},{"text":"extraction","start":116,"end":126,"id":18},{"text":".","start":126,"end":127,"id":19}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Dimensionality reduction is a topic of recent interest.","_input_hash":2135991398,"_task_hash":90492257,"tokens":[{"text":"Dimensionality","start":0,"end":14,"id":0},{"text":"reduction","start":15,"end":24,"id":1},{"text":"is","start":25,"end":27,"id":2},{"text":"a","start":28,"end":29,"id":3},{"text":"topic","start":30,"end":35,"id":4},{"text":"of","start":36,"end":38,"id":5},{"text":"recent","start":39,"end":45,"id":6},{"text":"interest","start":46,"end":54,"id":7},{"text":".","start":54,"end":55,"id":8}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"In this paper, we present the classification constrained dimensionality reduction (CCDR) algorithm to account for label information.","_input_hash":-837527872,"_task_hash":1040060962,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"this","start":3,"end":7,"id":1},{"text":"paper","start":8,"end":13,"id":2},{"text":",","start":13,"end":14,"id":3},{"text":"we","start":15,"end":17,"id":4},{"text":"present","start":18,"end":25,"id":5},{"text":"the","start":26,"end":29,"id":6},{"text":"classification","start":30,"end":44,"id":7},{"text":"constrained","start":45,"end":56,"id":8},{"text":"dimensionality","start":57,"end":71,"id":9},{"text":"reduction","start":72,"end":81,"id":10},{"text":"(","start":82,"end":83,"id":11},{"text":"CCDR","start":83,"end":87,"id":12},{"text":")","start":87,"end":88,"id":13},{"text":"algorithm","start":89,"end":98,"id":14},{"text":"to","start":99,"end":101,"id":15},{"text":"account","start":102,"end":109,"id":16},{"text":"for","start":110,"end":113,"id":17},{"text":"label","start":114,"end":119,"id":18},{"text":"information","start":120,"end":131,"id":19},{"text":".","start":131,"end":132,"id":20}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":30,"end":81,"token_start":7,"token_end":10,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"The algorithm can account for multiple classes as well as the semi-supervised setting.","_input_hash":-1517052669,"_task_hash":-985925882,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"algorithm","start":4,"end":13,"id":1},{"text":"can","start":14,"end":17,"id":2},{"text":"account","start":18,"end":25,"id":3},{"text":"for","start":26,"end":29,"id":4},{"text":"multiple","start":30,"end":38,"id":5},{"text":"classes","start":39,"end":46,"id":6},{"text":"as","start":47,"end":49,"id":7},{"text":"well","start":50,"end":54,"id":8},{"text":"as","start":55,"end":57,"id":9},{"text":"the","start":58,"end":61,"id":10},{"text":"semi","start":62,"end":66,"id":11},{"text":"-","start":66,"end":67,"id":12},{"text":"supervised","start":67,"end":77,"id":13},{"text":"setting","start":78,"end":85,"id":14},{"text":".","start":85,"end":86,"id":15}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We present an out-of-sample expressions for both labeled and unlabeled data.","_input_hash":2024165145,"_task_hash":1186591962,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"present","start":3,"end":10,"id":1},{"text":"an","start":11,"end":13,"id":2},{"text":"out","start":14,"end":17,"id":3},{"text":"-","start":17,"end":18,"id":4},{"text":"of","start":18,"end":20,"id":5},{"text":"-","start":20,"end":21,"id":6},{"text":"sample","start":21,"end":27,"id":7},{"text":"expressions","start":28,"end":39,"id":8},{"text":"for","start":40,"end":43,"id":9},{"text":"both","start":44,"end":48,"id":10},{"text":"labeled","start":49,"end":56,"id":11},{"text":"and","start":57,"end":60,"id":12},{"text":"unlabeled","start":61,"end":70,"id":13},{"text":"data","start":71,"end":75,"id":14},{"text":".","start":75,"end":76,"id":15}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"For unlabeled data, we introduce a method of embedding a new point as preprocessing to a classifier.","_input_hash":1850829439,"_task_hash":963755807,"tokens":[{"text":"For","start":0,"end":3,"id":0},{"text":"unlabeled","start":4,"end":13,"id":1},{"text":"data","start":14,"end":18,"id":2},{"text":",","start":18,"end":19,"id":3},{"text":"we","start":20,"end":22,"id":4},{"text":"introduce","start":23,"end":32,"id":5},{"text":"a","start":33,"end":34,"id":6},{"text":"method","start":35,"end":41,"id":7},{"text":"of","start":42,"end":44,"id":8},{"text":"embedding","start":45,"end":54,"id":9},{"text":"a","start":55,"end":56,"id":10},{"text":"new","start":57,"end":60,"id":11},{"text":"point","start":61,"end":66,"id":12},{"text":"as","start":67,"end":69,"id":13},{"text":"preprocessing","start":70,"end":83,"id":14},{"text":"to","start":84,"end":86,"id":15},{"text":"a","start":87,"end":88,"id":16},{"text":"classifier","start":89,"end":99,"id":17},{"text":".","start":99,"end":100,"id":18}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"For labeled data, we introduce a method that improves the embedding during the training phase using the out-of-sample extension.","_input_hash":1108733217,"_task_hash":992685221,"tokens":[{"text":"For","start":0,"end":3,"id":0},{"text":"labeled","start":4,"end":11,"id":1},{"text":"data","start":12,"end":16,"id":2},{"text":",","start":16,"end":17,"id":3},{"text":"we","start":18,"end":20,"id":4},{"text":"introduce","start":21,"end":30,"id":5},{"text":"a","start":31,"end":32,"id":6},{"text":"method","start":33,"end":39,"id":7},{"text":"that","start":40,"end":44,"id":8},{"text":"improves","start":45,"end":53,"id":9},{"text":"the","start":54,"end":57,"id":10},{"text":"embedding","start":58,"end":67,"id":11},{"text":"during","start":68,"end":74,"id":12},{"text":"the","start":75,"end":78,"id":13},{"text":"training","start":79,"end":87,"id":14},{"text":"phase","start":88,"end":93,"id":15},{"text":"using","start":94,"end":99,"id":16},{"text":"the","start":100,"end":103,"id":17},{"text":"out","start":104,"end":107,"id":18},{"text":"-","start":107,"end":108,"id":19},{"text":"of","start":108,"end":110,"id":20},{"text":"-","start":110,"end":111,"id":21},{"text":"sample","start":111,"end":117,"id":22},{"text":"extension","start":118,"end":127,"id":23},{"text":".","start":127,"end":128,"id":24}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We investigate classification performance using the CCDR algorithm on hyper-spectral satellite imagery data.","_input_hash":-1472662451,"_task_hash":573464386,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"investigate","start":3,"end":14,"id":1},{"text":"classification","start":15,"end":29,"id":2},{"text":"performance","start":30,"end":41,"id":3},{"text":"using","start":42,"end":47,"id":4},{"text":"the","start":48,"end":51,"id":5},{"text":"CCDR","start":52,"end":56,"id":6},{"text":"algorithm","start":57,"end":66,"id":7},{"text":"on","start":67,"end":69,"id":8},{"text":"hyper","start":70,"end":75,"id":9},{"text":"-","start":75,"end":76,"id":10},{"text":"spectral","start":76,"end":84,"id":11},{"text":"satellite","start":85,"end":94,"id":12},{"text":"imagery","start":95,"end":102,"id":13},{"text":"data","start":103,"end":107,"id":14},{"text":".","start":107,"end":108,"id":15}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":52,"end":56,"token_start":6,"token_end":6,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"We demonstrate the performance gain for both local and global classifiers and demonstrate a 10% improvement of the $k$-nearest neighbors algorithm performance.","_input_hash":-1173540332,"_task_hash":949256519,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"demonstrate","start":3,"end":14,"id":1},{"text":"the","start":15,"end":18,"id":2},{"text":"performance","start":19,"end":30,"id":3},{"text":"gain","start":31,"end":35,"id":4},{"text":"for","start":36,"end":39,"id":5},{"text":"both","start":40,"end":44,"id":6},{"text":"local","start":45,"end":50,"id":7},{"text":"and","start":51,"end":54,"id":8},{"text":"global","start":55,"end":61,"id":9},{"text":"classifiers","start":62,"end":73,"id":10},{"text":"and","start":74,"end":77,"id":11},{"text":"demonstrate","start":78,"end":89,"id":12},{"text":"a","start":90,"end":91,"id":13},{"text":"10","start":92,"end":94,"id":14},{"text":"%","start":94,"end":95,"id":15},{"text":"improvement","start":96,"end":107,"id":16},{"text":"of","start":108,"end":110,"id":17},{"text":"the","start":111,"end":114,"id":18},{"text":"$","start":115,"end":116,"id":19},{"text":"k$-nearest","start":116,"end":126,"id":20},{"text":"neighbors","start":127,"end":136,"id":21},{"text":"algorithm","start":137,"end":146,"id":22},{"text":"performance","start":147,"end":158,"id":23},{"text":".","start":158,"end":159,"id":24}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":115,"end":136,"token_start":19,"token_end":21,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"We present a connection between intrinsic dimension estimation and the optimal embedding dimension obtained using the CCDR algorithm.","_input_hash":-812107236,"_task_hash":1990113264,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"present","start":3,"end":10,"id":1},{"text":"a","start":11,"end":12,"id":2},{"text":"connection","start":13,"end":23,"id":3},{"text":"between","start":24,"end":31,"id":4},{"text":"intrinsic","start":32,"end":41,"id":5},{"text":"dimension","start":42,"end":51,"id":6},{"text":"estimation","start":52,"end":62,"id":7},{"text":"and","start":63,"end":66,"id":8},{"text":"the","start":67,"end":70,"id":9},{"text":"optimal","start":71,"end":78,"id":10},{"text":"embedding","start":79,"end":88,"id":11},{"text":"dimension","start":89,"end":98,"id":12},{"text":"obtained","start":99,"end":107,"id":13},{"text":"using","start":108,"end":113,"id":14},{"text":"the","start":114,"end":117,"id":15},{"text":"CCDR","start":118,"end":122,"id":16},{"text":"algorithm","start":123,"end":132,"id":17},{"text":".","start":132,"end":133,"id":18}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":118,"end":122,"token_start":16,"token_end":16,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"Flow cytometry is often used to characterize the malignant cells in leukemia and lymphoma patients, traced to the level of the individual cell.","_input_hash":-186932865,"_task_hash":2014982531,"tokens":[{"text":"Flow","start":0,"end":4,"id":0},{"text":"cytometry","start":5,"end":14,"id":1},{"text":"is","start":15,"end":17,"id":2},{"text":"often","start":18,"end":23,"id":3},{"text":"used","start":24,"end":28,"id":4},{"text":"to","start":29,"end":31,"id":5},{"text":"characterize","start":32,"end":44,"id":6},{"text":"the","start":45,"end":48,"id":7},{"text":"malignant","start":49,"end":58,"id":8},{"text":"cells","start":59,"end":64,"id":9},{"text":"in","start":65,"end":67,"id":10},{"text":"leukemia","start":68,"end":76,"id":11},{"text":"and","start":77,"end":80,"id":12},{"text":"lymphoma","start":81,"end":89,"id":13},{"text":"patients","start":90,"end":98,"id":14},{"text":",","start":98,"end":99,"id":15},{"text":"traced","start":100,"end":106,"id":16},{"text":"to","start":107,"end":109,"id":17},{"text":"the","start":110,"end":113,"id":18},{"text":"level","start":114,"end":119,"id":19},{"text":"of","start":120,"end":122,"id":20},{"text":"the","start":123,"end":126,"id":21},{"text":"individual","start":127,"end":137,"id":22},{"text":"cell","start":138,"end":142,"id":23},{"text":".","start":142,"end":143,"id":24}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Typically, flow cytometric data analysis is performed through a series of 2-dimensional projections onto the axes of the data set.","_input_hash":-1351284336,"_task_hash":-39802717,"tokens":[{"text":"Typically","start":0,"end":9,"id":0},{"text":",","start":9,"end":10,"id":1},{"text":"flow","start":11,"end":15,"id":2},{"text":"cytometric","start":16,"end":26,"id":3},{"text":"data","start":27,"end":31,"id":4},{"text":"analysis","start":32,"end":40,"id":5},{"text":"is","start":41,"end":43,"id":6},{"text":"performed","start":44,"end":53,"id":7},{"text":"through","start":54,"end":61,"id":8},{"text":"a","start":62,"end":63,"id":9},{"text":"series","start":64,"end":70,"id":10},{"text":"of","start":71,"end":73,"id":11},{"text":"2-dimensional","start":74,"end":87,"id":12},{"text":"projections","start":88,"end":99,"id":13},{"text":"onto","start":100,"end":104,"id":14},{"text":"the","start":105,"end":108,"id":15},{"text":"axes","start":109,"end":113,"id":16},{"text":"of","start":114,"end":116,"id":17},{"text":"the","start":117,"end":120,"id":18},{"text":"data","start":121,"end":125,"id":19},{"text":"set","start":126,"end":129,"id":20},{"text":".","start":129,"end":130,"id":21}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Through the years, clinicians have determined combinations of different fluorescent markers which generate relatively known expression patterns for specific subtypes of leukemia and lymphoma -- cancers of the hematopoietic system.","_input_hash":-770091940,"_task_hash":2008927478,"tokens":[{"text":"Through","start":0,"end":7,"id":0},{"text":"the","start":8,"end":11,"id":1},{"text":"years","start":12,"end":17,"id":2},{"text":",","start":17,"end":18,"id":3},{"text":"clinicians","start":19,"end":29,"id":4},{"text":"have","start":30,"end":34,"id":5},{"text":"determined","start":35,"end":45,"id":6},{"text":"combinations","start":46,"end":58,"id":7},{"text":"of","start":59,"end":61,"id":8},{"text":"different","start":62,"end":71,"id":9},{"text":"fluorescent","start":72,"end":83,"id":10},{"text":"markers","start":84,"end":91,"id":11},{"text":"which","start":92,"end":97,"id":12},{"text":"generate","start":98,"end":106,"id":13},{"text":"relatively","start":107,"end":117,"id":14},{"text":"known","start":118,"end":123,"id":15},{"text":"expression","start":124,"end":134,"id":16},{"text":"patterns","start":135,"end":143,"id":17},{"text":"for","start":144,"end":147,"id":18},{"text":"specific","start":148,"end":156,"id":19},{"text":"subtypes","start":157,"end":165,"id":20},{"text":"of","start":166,"end":168,"id":21},{"text":"leukemia","start":169,"end":177,"id":22},{"text":"and","start":178,"end":181,"id":23},{"text":"lymphoma","start":182,"end":190,"id":24},{"text":"--","start":191,"end":193,"id":25},{"text":"cancers","start":194,"end":201,"id":26},{"text":"of","start":202,"end":204,"id":27},{"text":"the","start":205,"end":208,"id":28},{"text":"hematopoietic","start":209,"end":222,"id":29},{"text":"system","start":223,"end":229,"id":30},{"text":".","start":229,"end":230,"id":31}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"By only viewing a series of 2-dimensional projections, the high-dimensional nature of the data is rarely exploited.","_input_hash":608820998,"_task_hash":452229493,"tokens":[{"text":"By","start":0,"end":2,"id":0},{"text":"only","start":3,"end":7,"id":1},{"text":"viewing","start":8,"end":15,"id":2},{"text":"a","start":16,"end":17,"id":3},{"text":"series","start":18,"end":24,"id":4},{"text":"of","start":25,"end":27,"id":5},{"text":"2-dimensional","start":28,"end":41,"id":6},{"text":"projections","start":42,"end":53,"id":7},{"text":",","start":53,"end":54,"id":8},{"text":"the","start":55,"end":58,"id":9},{"text":"high","start":59,"end":63,"id":10},{"text":"-","start":63,"end":64,"id":11},{"text":"dimensional","start":64,"end":75,"id":12},{"text":"nature","start":76,"end":82,"id":13},{"text":"of","start":83,"end":85,"id":14},{"text":"the","start":86,"end":89,"id":15},{"text":"data","start":90,"end":94,"id":16},{"text":"is","start":95,"end":97,"id":17},{"text":"rarely","start":98,"end":104,"id":18},{"text":"exploited","start":105,"end":114,"id":19},{"text":".","start":114,"end":115,"id":20}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"In this paper we present a means of determining a low-dimensional projection which maintains the high-dimensional relationships (i.e. information) between differing oncological data sets.","_input_hash":1027560018,"_task_hash":989776101,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"this","start":3,"end":7,"id":1},{"text":"paper","start":8,"end":13,"id":2},{"text":"we","start":14,"end":16,"id":3},{"text":"present","start":17,"end":24,"id":4},{"text":"a","start":25,"end":26,"id":5},{"text":"means","start":27,"end":32,"id":6},{"text":"of","start":33,"end":35,"id":7},{"text":"determining","start":36,"end":47,"id":8},{"text":"a","start":48,"end":49,"id":9},{"text":"low","start":50,"end":53,"id":10},{"text":"-","start":53,"end":54,"id":11},{"text":"dimensional","start":54,"end":65,"id":12},{"text":"projection","start":66,"end":76,"id":13},{"text":"which","start":77,"end":82,"id":14},{"text":"maintains","start":83,"end":92,"id":15},{"text":"the","start":93,"end":96,"id":16},{"text":"high","start":97,"end":101,"id":17},{"text":"-","start":101,"end":102,"id":18},{"text":"dimensional","start":102,"end":113,"id":19},{"text":"relationships","start":114,"end":127,"id":20},{"text":"(","start":128,"end":129,"id":21},{"text":"i.e.","start":129,"end":133,"id":22},{"text":"information","start":134,"end":145,"id":23},{"text":")","start":145,"end":146,"id":24},{"text":"between","start":147,"end":154,"id":25},{"text":"differing","start":155,"end":164,"id":26},{"text":"oncological","start":165,"end":176,"id":27},{"text":"data","start":177,"end":181,"id":28},{"text":"sets","start":182,"end":186,"id":29},{"text":".","start":186,"end":187,"id":30}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"By using machine learning techniques, we allow clinicians to visualize data in a low dimension defined by a linear combination of all of the available markers, rather than just 2 at a time.","_input_hash":-1723825170,"_task_hash":1629234304,"tokens":[{"text":"By","start":0,"end":2,"id":0},{"text":"using","start":3,"end":8,"id":1},{"text":"machine","start":9,"end":16,"id":2},{"text":"learning","start":17,"end":25,"id":3},{"text":"techniques","start":26,"end":36,"id":4},{"text":",","start":36,"end":37,"id":5},{"text":"we","start":38,"end":40,"id":6},{"text":"allow","start":41,"end":46,"id":7},{"text":"clinicians","start":47,"end":57,"id":8},{"text":"to","start":58,"end":60,"id":9},{"text":"visualize","start":61,"end":70,"id":10},{"text":"data","start":71,"end":75,"id":11},{"text":"in","start":76,"end":78,"id":12},{"text":"a","start":79,"end":80,"id":13},{"text":"low","start":81,"end":84,"id":14},{"text":"dimension","start":85,"end":94,"id":15},{"text":"defined","start":95,"end":102,"id":16},{"text":"by","start":103,"end":105,"id":17},{"text":"a","start":106,"end":107,"id":18},{"text":"linear","start":108,"end":114,"id":19},{"text":"combination","start":115,"end":126,"id":20},{"text":"of","start":127,"end":129,"id":21},{"text":"all","start":130,"end":133,"id":22},{"text":"of","start":134,"end":136,"id":23},{"text":"the","start":137,"end":140,"id":24},{"text":"available","start":141,"end":150,"id":25},{"text":"markers","start":151,"end":158,"id":26},{"text":",","start":158,"end":159,"id":27},{"text":"rather","start":160,"end":166,"id":28},{"text":"than","start":167,"end":171,"id":29},{"text":"just","start":172,"end":176,"id":30},{"text":"2","start":177,"end":178,"id":31},{"text":"at","start":179,"end":181,"id":32},{"text":"a","start":182,"end":183,"id":33},{"text":"time","start":184,"end":188,"id":34},{"text":".","start":188,"end":189,"id":35}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"This provides an aid in diagnosing similar forms of cancer, as well as a means for variable selection in exploratory flow cytometric research.","_input_hash":1247429372,"_task_hash":-623487225,"tokens":[{"text":"This","start":0,"end":4,"id":0},{"text":"provides","start":5,"end":13,"id":1},{"text":"an","start":14,"end":16,"id":2},{"text":"aid","start":17,"end":20,"id":3},{"text":"in","start":21,"end":23,"id":4},{"text":"diagnosing","start":24,"end":34,"id":5},{"text":"similar","start":35,"end":42,"id":6},{"text":"forms","start":43,"end":48,"id":7},{"text":"of","start":49,"end":51,"id":8},{"text":"cancer","start":52,"end":58,"id":9},{"text":",","start":58,"end":59,"id":10},{"text":"as","start":60,"end":62,"id":11},{"text":"well","start":63,"end":67,"id":12},{"text":"as","start":68,"end":70,"id":13},{"text":"a","start":71,"end":72,"id":14},{"text":"means","start":73,"end":78,"id":15},{"text":"for","start":79,"end":82,"id":16},{"text":"variable","start":83,"end":91,"id":17},{"text":"selection","start":92,"end":101,"id":18},{"text":"in","start":102,"end":104,"id":19},{"text":"exploratory","start":105,"end":116,"id":20},{"text":"flow","start":117,"end":121,"id":21},{"text":"cytometric","start":122,"end":132,"id":22},{"text":"research","start":133,"end":141,"id":23},{"text":".","start":141,"end":142,"id":24}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We refer to our method as Information Preserving Component Analysis (IPCA).","_input_hash":-455619717,"_task_hash":-212535663,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"refer","start":3,"end":8,"id":1},{"text":"to","start":9,"end":11,"id":2},{"text":"our","start":12,"end":15,"id":3},{"text":"method","start":16,"end":22,"id":4},{"text":"as","start":23,"end":25,"id":5},{"text":"Information","start":26,"end":37,"id":6},{"text":"Preserving","start":38,"end":48,"id":7},{"text":"Component","start":49,"end":58,"id":8},{"text":"Analysis","start":59,"end":67,"id":9},{"text":"(","start":68,"end":69,"id":10},{"text":"IPCA","start":69,"end":73,"id":11},{"text":")","start":73,"end":74,"id":12},{"text":".","start":74,"end":75,"id":13}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":26,"end":67,"token_start":6,"token_end":9,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"We define and discuss the first sparse coding algorithm based on closed-form EM updates and continuous latent variables.","_input_hash":-2021792788,"_task_hash":-701591155,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"define","start":3,"end":9,"id":1},{"text":"and","start":10,"end":13,"id":2},{"text":"discuss","start":14,"end":21,"id":3},{"text":"the","start":22,"end":25,"id":4},{"text":"first","start":26,"end":31,"id":5},{"text":"sparse","start":32,"end":38,"id":6},{"text":"coding","start":39,"end":45,"id":7},{"text":"algorithm","start":46,"end":55,"id":8},{"text":"based","start":56,"end":61,"id":9},{"text":"on","start":62,"end":64,"id":10},{"text":"closed","start":65,"end":71,"id":11},{"text":"-","start":71,"end":72,"id":12},{"text":"form","start":72,"end":76,"id":13},{"text":"EM","start":77,"end":79,"id":14},{"text":"updates","start":80,"end":87,"id":15},{"text":"and","start":88,"end":91,"id":16},{"text":"continuous","start":92,"end":102,"id":17},{"text":"latent","start":103,"end":109,"id":18},{"text":"variables","start":110,"end":119,"id":19},{"text":".","start":119,"end":120,"id":20}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":32,"end":45,"token_start":6,"token_end":7,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"The underlying generative model consists of a standard `spike-and-slab' prior and a Gaussian noise model.","_input_hash":755256388,"_task_hash":-258708138,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"underlying","start":4,"end":14,"id":1},{"text":"generative","start":15,"end":25,"id":2},{"text":"model","start":26,"end":31,"id":3},{"text":"consists","start":32,"end":40,"id":4},{"text":"of","start":41,"end":43,"id":5},{"text":"a","start":44,"end":45,"id":6},{"text":"standard","start":46,"end":54,"id":7},{"text":"`","start":55,"end":56,"id":8},{"text":"spike","start":56,"end":61,"id":9},{"text":"-","start":61,"end":62,"id":10},{"text":"and","start":62,"end":65,"id":11},{"text":"-","start":65,"end":66,"id":12},{"text":"slab","start":66,"end":70,"id":13},{"text":"'","start":70,"end":71,"id":14},{"text":"prior","start":72,"end":77,"id":15},{"text":"and","start":78,"end":81,"id":16},{"text":"a","start":82,"end":83,"id":17},{"text":"Gaussian","start":84,"end":92,"id":18},{"text":"noise","start":93,"end":98,"id":19},{"text":"model","start":99,"end":104,"id":20},{"text":".","start":104,"end":105,"id":21}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":84,"end":98,"token_start":18,"token_end":19,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"Closed-form solutions for E- and M-step equations are derived by generalizing probabilistic PCA.","_input_hash":-2098455611,"_task_hash":775793305,"tokens":[{"text":"Closed","start":0,"end":6,"id":0},{"text":"-","start":6,"end":7,"id":1},{"text":"form","start":7,"end":11,"id":2},{"text":"solutions","start":12,"end":21,"id":3},{"text":"for","start":22,"end":25,"id":4},{"text":"E-","start":26,"end":28,"id":5},{"text":"and","start":29,"end":32,"id":6},{"text":"M","start":33,"end":34,"id":7},{"text":"-","start":34,"end":35,"id":8},{"text":"step","start":35,"end":39,"id":9},{"text":"equations","start":40,"end":49,"id":10},{"text":"are","start":50,"end":53,"id":11},{"text":"derived","start":54,"end":61,"id":12},{"text":"by","start":62,"end":64,"id":13},{"text":"generalizing","start":65,"end":77,"id":14},{"text":"probabilistic","start":78,"end":91,"id":15},{"text":"PCA","start":92,"end":95,"id":16},{"text":".","start":95,"end":96,"id":17}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":78,"end":95,"token_start":15,"token_end":16,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"The resulting EM algorithm can take all modes of a potentially multi-modal posterior into account.","_input_hash":-1899666121,"_task_hash":2017732432,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"resulting","start":4,"end":13,"id":1},{"text":"EM","start":14,"end":16,"id":2},{"text":"algorithm","start":17,"end":26,"id":3},{"text":"can","start":27,"end":30,"id":4},{"text":"take","start":31,"end":35,"id":5},{"text":"all","start":36,"end":39,"id":6},{"text":"modes","start":40,"end":45,"id":7},{"text":"of","start":46,"end":48,"id":8},{"text":"a","start":49,"end":50,"id":9},{"text":"potentially","start":51,"end":62,"id":10},{"text":"multi","start":63,"end":68,"id":11},{"text":"-","start":68,"end":69,"id":12},{"text":"modal","start":69,"end":74,"id":13},{"text":"posterior","start":75,"end":84,"id":14},{"text":"into","start":85,"end":89,"id":15},{"text":"account","start":90,"end":97,"id":16},{"text":".","start":97,"end":98,"id":17}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":14,"end":16,"token_start":2,"token_end":2,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"The computational cost of the algorithm scales exponentially with the number of hidden dimensions.","_input_hash":-1620793016,"_task_hash":-1788290067,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"computational","start":4,"end":17,"id":1},{"text":"cost","start":18,"end":22,"id":2},{"text":"of","start":23,"end":25,"id":3},{"text":"the","start":26,"end":29,"id":4},{"text":"algorithm","start":30,"end":39,"id":5},{"text":"scales","start":40,"end":46,"id":6},{"text":"exponentially","start":47,"end":60,"id":7},{"text":"with","start":61,"end":65,"id":8},{"text":"the","start":66,"end":69,"id":9},{"text":"number","start":70,"end":76,"id":10},{"text":"of","start":77,"end":79,"id":11},{"text":"hidden","start":80,"end":86,"id":12},{"text":"dimensions","start":87,"end":97,"id":13},{"text":".","start":97,"end":98,"id":14}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"However, with current computational resources, it is still possible to efficiently learn model parameters for medium-scale problems.","_input_hash":1522437881,"_task_hash":855520508,"tokens":[{"text":"However","start":0,"end":7,"id":0},{"text":",","start":7,"end":8,"id":1},{"text":"with","start":9,"end":13,"id":2},{"text":"current","start":14,"end":21,"id":3},{"text":"computational","start":22,"end":35,"id":4},{"text":"resources","start":36,"end":45,"id":5},{"text":",","start":45,"end":46,"id":6},{"text":"it","start":47,"end":49,"id":7},{"text":"is","start":50,"end":52,"id":8},{"text":"still","start":53,"end":58,"id":9},{"text":"possible","start":59,"end":67,"id":10},{"text":"to","start":68,"end":70,"id":11},{"text":"efficiently","start":71,"end":82,"id":12},{"text":"learn","start":83,"end":88,"id":13},{"text":"model","start":89,"end":94,"id":14},{"text":"parameters","start":95,"end":105,"id":15},{"text":"for","start":106,"end":109,"id":16},{"text":"medium","start":110,"end":116,"id":17},{"text":"-","start":116,"end":117,"id":18},{"text":"scale","start":117,"end":122,"id":19},{"text":"problems","start":123,"end":131,"id":20},{"text":".","start":131,"end":132,"id":21}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Thus the model can be applied to the typical range of source separation tasks.","_input_hash":1875812889,"_task_hash":500647179,"tokens":[{"text":"Thus","start":0,"end":4,"id":0},{"text":"the","start":5,"end":8,"id":1},{"text":"model","start":9,"end":14,"id":2},{"text":"can","start":15,"end":18,"id":3},{"text":"be","start":19,"end":21,"id":4},{"text":"applied","start":22,"end":29,"id":5},{"text":"to","start":30,"end":32,"id":6},{"text":"the","start":33,"end":36,"id":7},{"text":"typical","start":37,"end":44,"id":8},{"text":"range","start":45,"end":50,"id":9},{"text":"of","start":51,"end":53,"id":10},{"text":"source","start":54,"end":60,"id":11},{"text":"separation","start":61,"end":71,"id":12},{"text":"tasks","start":72,"end":77,"id":13},{"text":".","start":77,"end":78,"id":14}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"In numerical experiments on artificial data we verify likelihood maximization and show that the derived algorithm recovers the sparse directions of standard sparse coding distributions.","_input_hash":-568508844,"_task_hash":99337722,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"numerical","start":3,"end":12,"id":1},{"text":"experiments","start":13,"end":24,"id":2},{"text":"on","start":25,"end":27,"id":3},{"text":"artificial","start":28,"end":38,"id":4},{"text":"data","start":39,"end":43,"id":5},{"text":"we","start":44,"end":46,"id":6},{"text":"verify","start":47,"end":53,"id":7},{"text":"likelihood","start":54,"end":64,"id":8},{"text":"maximization","start":65,"end":77,"id":9},{"text":"and","start":78,"end":81,"id":10},{"text":"show","start":82,"end":86,"id":11},{"text":"that","start":87,"end":91,"id":12},{"text":"the","start":92,"end":95,"id":13},{"text":"derived","start":96,"end":103,"id":14},{"text":"algorithm","start":104,"end":113,"id":15},{"text":"recovers","start":114,"end":122,"id":16},{"text":"the","start":123,"end":126,"id":17},{"text":"sparse","start":127,"end":133,"id":18},{"text":"directions","start":134,"end":144,"id":19},{"text":"of","start":145,"end":147,"id":20},{"text":"standard","start":148,"end":156,"id":21},{"text":"sparse","start":157,"end":163,"id":22},{"text":"coding","start":164,"end":170,"id":23},{"text":"distributions","start":171,"end":184,"id":24},{"text":".","start":184,"end":185,"id":25}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"On source separation benchmarks comprised of realistic data we show that the algorithm is competitive with other recent methods.","_input_hash":-1014127827,"_task_hash":262359737,"tokens":[{"text":"On","start":0,"end":2,"id":0},{"text":"source","start":3,"end":9,"id":1},{"text":"separation","start":10,"end":20,"id":2},{"text":"benchmarks","start":21,"end":31,"id":3},{"text":"comprised","start":32,"end":41,"id":4},{"text":"of","start":42,"end":44,"id":5},{"text":"realistic","start":45,"end":54,"id":6},{"text":"data","start":55,"end":59,"id":7},{"text":"we","start":60,"end":62,"id":8},{"text":"show","start":63,"end":67,"id":9},{"text":"that","start":68,"end":72,"id":10},{"text":"the","start":73,"end":76,"id":11},{"text":"algorithm","start":77,"end":86,"id":12},{"text":"is","start":87,"end":89,"id":13},{"text":"competitive","start":90,"end":101,"id":14},{"text":"with","start":102,"end":106,"id":15},{"text":"other","start":107,"end":112,"id":16},{"text":"recent","start":113,"end":119,"id":17},{"text":"methods","start":120,"end":127,"id":18},{"text":".","start":127,"end":128,"id":19}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"This paper reviews the functional aspects of statistical learning theory.","_input_hash":-164428646,"_task_hash":502455540,"tokens":[{"text":"This","start":0,"end":4,"id":0},{"text":"paper","start":5,"end":10,"id":1},{"text":"reviews","start":11,"end":18,"id":2},{"text":"the","start":19,"end":22,"id":3},{"text":"functional","start":23,"end":33,"id":4},{"text":"aspects","start":34,"end":41,"id":5},{"text":"of","start":42,"end":44,"id":6},{"text":"statistical","start":45,"end":56,"id":7},{"text":"learning","start":57,"end":65,"id":8},{"text":"theory","start":66,"end":72,"id":9},{"text":".","start":72,"end":73,"id":10}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"The main point under consideration is the nature of the hypothesis set when no prior information is available but data.","_input_hash":-1902021527,"_task_hash":118208701,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"main","start":4,"end":8,"id":1},{"text":"point","start":9,"end":14,"id":2},{"text":"under","start":15,"end":20,"id":3},{"text":"consideration","start":21,"end":34,"id":4},{"text":"is","start":35,"end":37,"id":5},{"text":"the","start":38,"end":41,"id":6},{"text":"nature","start":42,"end":48,"id":7},{"text":"of","start":49,"end":51,"id":8},{"text":"the","start":52,"end":55,"id":9},{"text":"hypothesis","start":56,"end":66,"id":10},{"text":"set","start":67,"end":70,"id":11},{"text":"when","start":71,"end":75,"id":12},{"text":"no","start":76,"end":78,"id":13},{"text":"prior","start":79,"end":84,"id":14},{"text":"information","start":85,"end":96,"id":15},{"text":"is","start":97,"end":99,"id":16},{"text":"available","start":100,"end":109,"id":17},{"text":"but","start":110,"end":113,"id":18},{"text":"data","start":114,"end":118,"id":19},{"text":".","start":118,"end":119,"id":20}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"Within this framework we first discuss about the hypothesis set:","_input_hash":1905021306,"_task_hash":666260503,"tokens":[{"text":"Within","start":0,"end":6,"id":0},{"text":"this","start":7,"end":11,"id":1},{"text":"framework","start":12,"end":21,"id":2},{"text":"we","start":22,"end":24,"id":3},{"text":"first","start":25,"end":30,"id":4},{"text":"discuss","start":31,"end":38,"id":5},{"text":"about","start":39,"end":44,"id":6},{"text":"the","start":45,"end":48,"id":7},{"text":"hypothesis","start":49,"end":59,"id":8},{"text":"set","start":60,"end":63,"id":9},{"text":":","start":63,"end":64,"id":10}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"it is a vectorial space, it is a set of pointwise defined functions, and the evaluation functional on this set is a continuous mapping.","_input_hash":-1724788611,"_task_hash":-514736408,"tokens":[{"text":"it","start":0,"end":2,"id":0},{"text":"is","start":3,"end":5,"id":1},{"text":"a","start":6,"end":7,"id":2},{"text":"vectorial","start":8,"end":17,"id":3},{"text":"space","start":18,"end":23,"id":4},{"text":",","start":23,"end":24,"id":5},{"text":"it","start":25,"end":27,"id":6},{"text":"is","start":28,"end":30,"id":7},{"text":"a","start":31,"end":32,"id":8},{"text":"set","start":33,"end":36,"id":9},{"text":"of","start":37,"end":39,"id":10},{"text":"pointwise","start":40,"end":49,"id":11},{"text":"defined","start":50,"end":57,"id":12},{"text":"functions","start":58,"end":67,"id":13},{"text":",","start":67,"end":68,"id":14},{"text":"and","start":69,"end":72,"id":15},{"text":"the","start":73,"end":76,"id":16},{"text":"evaluation","start":77,"end":87,"id":17},{"text":"functional","start":88,"end":98,"id":18},{"text":"on","start":99,"end":101,"id":19},{"text":"this","start":102,"end":106,"id":20},{"text":"set","start":107,"end":110,"id":21},{"text":"is","start":111,"end":113,"id":22},{"text":"a","start":114,"end":115,"id":23},{"text":"continuous","start":116,"end":126,"id":24},{"text":"mapping","start":127,"end":134,"id":25},{"text":".","start":134,"end":135,"id":26}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"Based on these principles an original theory is developed generalizing the notion of reproduction kernel Hilbert space to non hilbertian sets.","_input_hash":-680166752,"_task_hash":-812152068,"tokens":[{"text":"Based","start":0,"end":5,"id":0},{"text":"on","start":6,"end":8,"id":1},{"text":"these","start":9,"end":14,"id":2},{"text":"principles","start":15,"end":25,"id":3},{"text":"an","start":26,"end":28,"id":4},{"text":"original","start":29,"end":37,"id":5},{"text":"theory","start":38,"end":44,"id":6},{"text":"is","start":45,"end":47,"id":7},{"text":"developed","start":48,"end":57,"id":8},{"text":"generalizing","start":58,"end":70,"id":9},{"text":"the","start":71,"end":74,"id":10},{"text":"notion","start":75,"end":81,"id":11},{"text":"of","start":82,"end":84,"id":12},{"text":"reproduction","start":85,"end":97,"id":13},{"text":"kernel","start":98,"end":104,"id":14},{"text":"Hilbert","start":105,"end":112,"id":15},{"text":"space","start":113,"end":118,"id":16},{"text":"to","start":119,"end":121,"id":17},{"text":"non","start":122,"end":125,"id":18},{"text":"hilbertian","start":126,"end":136,"id":19},{"text":"sets","start":137,"end":141,"id":20},{"text":".","start":141,"end":142,"id":21}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"Then it is shown that the hypothesis set of any learning machine has to be a generalized reproducing set.","_input_hash":116611826,"_task_hash":1788150005,"tokens":[{"text":"Then","start":0,"end":4,"id":0},{"text":"it","start":5,"end":7,"id":1},{"text":"is","start":8,"end":10,"id":2},{"text":"shown","start":11,"end":16,"id":3},{"text":"that","start":17,"end":21,"id":4},{"text":"the","start":22,"end":25,"id":5},{"text":"hypothesis","start":26,"end":36,"id":6},{"text":"set","start":37,"end":40,"id":7},{"text":"of","start":41,"end":43,"id":8},{"text":"any","start":44,"end":47,"id":9},{"text":"learning","start":48,"end":56,"id":10},{"text":"machine","start":57,"end":64,"id":11},{"text":"has","start":65,"end":68,"id":12},{"text":"to","start":69,"end":71,"id":13},{"text":"be","start":72,"end":74,"id":14},{"text":"a","start":75,"end":76,"id":15},{"text":"generalized","start":77,"end":88,"id":16},{"text":"reproducing","start":89,"end":100,"id":17},{"text":"set","start":101,"end":104,"id":18},{"text":".","start":104,"end":105,"id":19}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"Therefore, thanks to a general \"representer theorem\", the solution of the learning problem is still a linear combination of a kernel.","_input_hash":-196811180,"_task_hash":-120128476,"tokens":[{"text":"Therefore","start":0,"end":9,"id":0},{"text":",","start":9,"end":10,"id":1},{"text":"thanks","start":11,"end":17,"id":2},{"text":"to","start":18,"end":20,"id":3},{"text":"a","start":21,"end":22,"id":4},{"text":"general","start":23,"end":30,"id":5},{"text":"\"","start":31,"end":32,"id":6},{"text":"representer","start":32,"end":43,"id":7},{"text":"theorem","start":44,"end":51,"id":8},{"text":"\"","start":51,"end":52,"id":9},{"text":",","start":52,"end":53,"id":10},{"text":"the","start":54,"end":57,"id":11},{"text":"solution","start":58,"end":66,"id":12},{"text":"of","start":67,"end":69,"id":13},{"text":"the","start":70,"end":73,"id":14},{"text":"learning","start":74,"end":82,"id":15},{"text":"problem","start":83,"end":90,"id":16},{"text":"is","start":91,"end":93,"id":17},{"text":"still","start":94,"end":99,"id":18},{"text":"a","start":100,"end":101,"id":19},{"text":"linear","start":102,"end":108,"id":20},{"text":"combination","start":109,"end":120,"id":21},{"text":"of","start":121,"end":123,"id":22},{"text":"a","start":124,"end":125,"id":23},{"text":"kernel","start":126,"end":132,"id":24},{"text":".","start":132,"end":133,"id":25}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"Furthermore, a way to design these kernels is given.","_input_hash":1566328038,"_task_hash":-390566754,"tokens":[{"text":"Furthermore","start":0,"end":11,"id":0},{"text":",","start":11,"end":12,"id":1},{"text":"a","start":13,"end":14,"id":2},{"text":"way","start":15,"end":18,"id":3},{"text":"to","start":19,"end":21,"id":4},{"text":"design","start":22,"end":28,"id":5},{"text":"these","start":29,"end":34,"id":6},{"text":"kernels","start":35,"end":42,"id":7},{"text":"is","start":43,"end":45,"id":8},{"text":"given","start":46,"end":51,"id":9},{"text":".","start":51,"end":52,"id":10}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"To illustrate this framework some examples of such reproducing sets and kernels are given.","_input_hash":870541094,"_task_hash":1857863763,"tokens":[{"text":"To","start":0,"end":2,"id":0},{"text":"illustrate","start":3,"end":13,"id":1},{"text":"this","start":14,"end":18,"id":2},{"text":"framework","start":19,"end":28,"id":3},{"text":"some","start":29,"end":33,"id":4},{"text":"examples","start":34,"end":42,"id":5},{"text":"of","start":43,"end":45,"id":6},{"text":"such","start":46,"end":50,"id":7},{"text":"reproducing","start":51,"end":62,"id":8},{"text":"sets","start":63,"end":67,"id":9},{"text":"and","start":68,"end":71,"id":10},{"text":"kernels","start":72,"end":79,"id":11},{"text":"are","start":80,"end":83,"id":12},{"text":"given","start":84,"end":89,"id":13},{"text":".","start":89,"end":90,"id":14}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"We present an extension of sparse PCA, or sparse dictionary learning, where the sparsity patterns of all dictionary elements are structured and constrained to belong to a prespecified set of shapes.","_input_hash":405834443,"_task_hash":1643159839,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"present","start":3,"end":10,"id":1},{"text":"an","start":11,"end":13,"id":2},{"text":"extension","start":14,"end":23,"id":3},{"text":"of","start":24,"end":26,"id":4},{"text":"sparse","start":27,"end":33,"id":5},{"text":"PCA","start":34,"end":37,"id":6},{"text":",","start":37,"end":38,"id":7},{"text":"or","start":39,"end":41,"id":8},{"text":"sparse","start":42,"end":48,"id":9},{"text":"dictionary","start":49,"end":59,"id":10},{"text":"learning","start":60,"end":68,"id":11},{"text":",","start":68,"end":69,"id":12},{"text":"where","start":70,"end":75,"id":13},{"text":"the","start":76,"end":79,"id":14},{"text":"sparsity","start":80,"end":88,"id":15},{"text":"patterns","start":89,"end":97,"id":16},{"text":"of","start":98,"end":100,"id":17},{"text":"all","start":101,"end":104,"id":18},{"text":"dictionary","start":105,"end":115,"id":19},{"text":"elements","start":116,"end":124,"id":20},{"text":"are","start":125,"end":128,"id":21},{"text":"structured","start":129,"end":139,"id":22},{"text":"and","start":140,"end":143,"id":23},{"text":"constrained","start":144,"end":155,"id":24},{"text":"to","start":156,"end":158,"id":25},{"text":"belong","start":159,"end":165,"id":26},{"text":"to","start":166,"end":168,"id":27},{"text":"a","start":169,"end":170,"id":28},{"text":"prespecified","start":171,"end":183,"id":29},{"text":"set","start":184,"end":187,"id":30},{"text":"of","start":188,"end":190,"id":31},{"text":"shapes","start":191,"end":197,"id":32},{"text":".","start":197,"end":198,"id":33}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":27,"end":37,"token_start":5,"token_end":6,"label":"ALGO","answer":"accept"},{"start":42,"end":68,"token_start":9,"token_end":11,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"This \\emph{structured sparse PCA} is based on a structured regularization recently introduced by [1].","_input_hash":353680850,"_task_hash":443923090,"tokens":[{"text":"This","start":0,"end":4,"id":0},{"text":"\\emph{structured","start":5,"end":21,"id":1},{"text":"sparse","start":22,"end":28,"id":2},{"text":"PCA","start":29,"end":32,"id":3},{"text":"}","start":32,"end":33,"id":4},{"text":"is","start":34,"end":36,"id":5},{"text":"based","start":37,"end":42,"id":6},{"text":"on","start":43,"end":45,"id":7},{"text":"a","start":46,"end":47,"id":8},{"text":"structured","start":48,"end":58,"id":9},{"text":"regularization","start":59,"end":73,"id":10},{"text":"recently","start":74,"end":82,"id":11},{"text":"introduced","start":83,"end":93,"id":12},{"text":"by","start":94,"end":96,"id":13},{"text":"[","start":97,"end":98,"id":14},{"text":"1","start":98,"end":99,"id":15},{"text":"]","start":99,"end":100,"id":16},{"text":".","start":100,"end":101,"id":17}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":22,"end":32,"token_start":2,"token_end":3,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"While classical sparse priors only deal with \\textit{cardinality}, the regularization we use encodes higher-order information about the data.","_input_hash":-1360787246,"_task_hash":732544823,"tokens":[{"text":"While","start":0,"end":5,"id":0},{"text":"classical","start":6,"end":15,"id":1},{"text":"sparse","start":16,"end":22,"id":2},{"text":"priors","start":23,"end":29,"id":3},{"text":"only","start":30,"end":34,"id":4},{"text":"deal","start":35,"end":39,"id":5},{"text":"with","start":40,"end":44,"id":6},{"text":"\\textit{cardinality","start":45,"end":64,"id":7},{"text":"}","start":64,"end":65,"id":8},{"text":",","start":65,"end":66,"id":9},{"text":"the","start":67,"end":70,"id":10},{"text":"regularization","start":71,"end":85,"id":11},{"text":"we","start":86,"end":88,"id":12},{"text":"use","start":89,"end":92,"id":13},{"text":"encodes","start":93,"end":100,"id":14},{"text":"higher","start":101,"end":107,"id":15},{"text":"-","start":107,"end":108,"id":16},{"text":"order","start":108,"end":113,"id":17},{"text":"information","start":114,"end":125,"id":18},{"text":"about","start":126,"end":131,"id":19},{"text":"the","start":132,"end":135,"id":20},{"text":"data","start":136,"end":140,"id":21},{"text":".","start":140,"end":141,"id":22}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We propose an efficient and simple optimization procedure to solve this problem.","_input_hash":-799536345,"_task_hash":1234176831,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"propose","start":3,"end":10,"id":1},{"text":"an","start":11,"end":13,"id":2},{"text":"efficient","start":14,"end":23,"id":3},{"text":"and","start":24,"end":27,"id":4},{"text":"simple","start":28,"end":34,"id":5},{"text":"optimization","start":35,"end":47,"id":6},{"text":"procedure","start":48,"end":57,"id":7},{"text":"to","start":58,"end":60,"id":8},{"text":"solve","start":61,"end":66,"id":9},{"text":"this","start":67,"end":71,"id":10},{"text":"problem","start":72,"end":79,"id":11},{"text":".","start":79,"end":80,"id":12}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Experiments with two practical tasks, face recognition and the study of the dynamics of a protein complex, demonstrate the benefits of the proposed structured approach over unstructured approaches.","_input_hash":2096971661,"_task_hash":1456351042,"tokens":[{"text":"Experiments","start":0,"end":11,"id":0},{"text":"with","start":12,"end":16,"id":1},{"text":"two","start":17,"end":20,"id":2},{"text":"practical","start":21,"end":30,"id":3},{"text":"tasks","start":31,"end":36,"id":4},{"text":",","start":36,"end":37,"id":5},{"text":"face","start":38,"end":42,"id":6},{"text":"recognition","start":43,"end":54,"id":7},{"text":"and","start":55,"end":58,"id":8},{"text":"the","start":59,"end":62,"id":9},{"text":"study","start":63,"end":68,"id":10},{"text":"of","start":69,"end":71,"id":11},{"text":"the","start":72,"end":75,"id":12},{"text":"dynamics","start":76,"end":84,"id":13},{"text":"of","start":85,"end":87,"id":14},{"text":"a","start":88,"end":89,"id":15},{"text":"protein","start":90,"end":97,"id":16},{"text":"complex","start":98,"end":105,"id":17},{"text":",","start":105,"end":106,"id":18},{"text":"demonstrate","start":107,"end":118,"id":19},{"text":"the","start":119,"end":122,"id":20},{"text":"benefits","start":123,"end":131,"id":21},{"text":"of","start":132,"end":134,"id":22},{"text":"the","start":135,"end":138,"id":23},{"text":"proposed","start":139,"end":147,"id":24},{"text":"structured","start":148,"end":158,"id":25},{"text":"approach","start":159,"end":167,"id":26},{"text":"over","start":168,"end":172,"id":27},{"text":"unstructured","start":173,"end":185,"id":28},{"text":"approaches","start":186,"end":196,"id":29},{"text":".","start":196,"end":197,"id":30}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We present the first tree-based regressor whose convergence rate depends only on the intrinsic dimension of the data, namely its Assouad dimension.","_input_hash":-1666717225,"_task_hash":-1725889582,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"present","start":3,"end":10,"id":1},{"text":"the","start":11,"end":14,"id":2},{"text":"first","start":15,"end":20,"id":3},{"text":"tree","start":21,"end":25,"id":4},{"text":"-","start":25,"end":26,"id":5},{"text":"based","start":26,"end":31,"id":6},{"text":"regressor","start":32,"end":41,"id":7},{"text":"whose","start":42,"end":47,"id":8},{"text":"convergence","start":48,"end":59,"id":9},{"text":"rate","start":60,"end":64,"id":10},{"text":"depends","start":65,"end":72,"id":11},{"text":"only","start":73,"end":77,"id":12},{"text":"on","start":78,"end":80,"id":13},{"text":"the","start":81,"end":84,"id":14},{"text":"intrinsic","start":85,"end":94,"id":15},{"text":"dimension","start":95,"end":104,"id":16},{"text":"of","start":105,"end":107,"id":17},{"text":"the","start":108,"end":111,"id":18},{"text":"data","start":112,"end":116,"id":19},{"text":",","start":116,"end":117,"id":20},{"text":"namely","start":118,"end":124,"id":21},{"text":"its","start":125,"end":128,"id":22},{"text":"Assouad","start":129,"end":136,"id":23},{"text":"dimension","start":137,"end":146,"id":24},{"text":".","start":146,"end":147,"id":25}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":21,"end":41,"token_start":4,"token_end":7,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"The regressor uses the RPtree partitioning procedure, a simple randomized variant of k-d trees.","_input_hash":641765247,"_task_hash":715431368,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"regressor","start":4,"end":13,"id":1},{"text":"uses","start":14,"end":18,"id":2},{"text":"the","start":19,"end":22,"id":3},{"text":"RPtree","start":23,"end":29,"id":4},{"text":"partitioning","start":30,"end":42,"id":5},{"text":"procedure","start":43,"end":52,"id":6},{"text":",","start":52,"end":53,"id":7},{"text":"a","start":54,"end":55,"id":8},{"text":"simple","start":56,"end":62,"id":9},{"text":"randomized","start":63,"end":73,"id":10},{"text":"variant","start":74,"end":81,"id":11},{"text":"of","start":82,"end":84,"id":12},{"text":"k","start":85,"end":86,"id":13},{"text":"-","start":86,"end":87,"id":14},{"text":"d","start":87,"end":88,"id":15},{"text":"trees","start":89,"end":94,"id":16},{"text":".","start":94,"end":95,"id":17}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":23,"end":42,"token_start":4,"token_end":5,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"The group lasso is a penalized regression method, used in regression problems where the covariates are partitioned into groups to promote sparsity at the group level.","_input_hash":-1363626500,"_task_hash":542497997,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"group","start":4,"end":9,"id":1},{"text":"lasso","start":10,"end":15,"id":2},{"text":"is","start":16,"end":18,"id":3},{"text":"a","start":19,"end":20,"id":4},{"text":"penalized","start":21,"end":30,"id":5},{"text":"regression","start":31,"end":41,"id":6},{"text":"method","start":42,"end":48,"id":7},{"text":",","start":48,"end":49,"id":8},{"text":"used","start":50,"end":54,"id":9},{"text":"in","start":55,"end":57,"id":10},{"text":"regression","start":58,"end":68,"id":11},{"text":"problems","start":69,"end":77,"id":12},{"text":"where","start":78,"end":83,"id":13},{"text":"the","start":84,"end":87,"id":14},{"text":"covariates","start":88,"end":98,"id":15},{"text":"are","start":99,"end":102,"id":16},{"text":"partitioned","start":103,"end":114,"id":17},{"text":"into","start":115,"end":119,"id":18},{"text":"groups","start":120,"end":126,"id":19},{"text":"to","start":127,"end":129,"id":20},{"text":"promote","start":130,"end":137,"id":21},{"text":"sparsity","start":138,"end":146,"id":22},{"text":"at","start":147,"end":149,"id":23},{"text":"the","start":150,"end":153,"id":24},{"text":"group","start":154,"end":159,"id":25},{"text":"level","start":160,"end":165,"id":26},{"text":".","start":165,"end":166,"id":27}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":21,"end":41,"token_start":5,"token_end":6,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"Existing methods for finding the group lasso estimator either use gradient projection methods to update the entire coefficient vector simultaneously at each step, or update one group of coefficients at a time using an inexact line search to approximate the optimal value for the group of coefficients when all other groups' coefficients are fixed.","_input_hash":847640769,"_task_hash":1609291463,"tokens":[{"text":"Existing","start":0,"end":8,"id":0},{"text":"methods","start":9,"end":16,"id":1},{"text":"for","start":17,"end":20,"id":2},{"text":"finding","start":21,"end":28,"id":3},{"text":"the","start":29,"end":32,"id":4},{"text":"group","start":33,"end":38,"id":5},{"text":"lasso","start":39,"end":44,"id":6},{"text":"estimator","start":45,"end":54,"id":7},{"text":"either","start":55,"end":61,"id":8},{"text":"use","start":62,"end":65,"id":9},{"text":"gradient","start":66,"end":74,"id":10},{"text":"projection","start":75,"end":85,"id":11},{"text":"methods","start":86,"end":93,"id":12},{"text":"to","start":94,"end":96,"id":13},{"text":"update","start":97,"end":103,"id":14},{"text":"the","start":104,"end":107,"id":15},{"text":"entire","start":108,"end":114,"id":16},{"text":"coefficient","start":115,"end":126,"id":17},{"text":"vector","start":127,"end":133,"id":18},{"text":"simultaneously","start":134,"end":148,"id":19},{"text":"at","start":149,"end":151,"id":20},{"text":"each","start":152,"end":156,"id":21},{"text":"step","start":157,"end":161,"id":22},{"text":",","start":161,"end":162,"id":23},{"text":"or","start":163,"end":165,"id":24},{"text":"update","start":166,"end":172,"id":25},{"text":"one","start":173,"end":176,"id":26},{"text":"group","start":177,"end":182,"id":27},{"text":"of","start":183,"end":185,"id":28},{"text":"coefficients","start":186,"end":198,"id":29},{"text":"at","start":199,"end":201,"id":30},{"text":"a","start":202,"end":203,"id":31},{"text":"time","start":204,"end":208,"id":32},{"text":"using","start":209,"end":214,"id":33},{"text":"an","start":215,"end":217,"id":34},{"text":"inexact","start":218,"end":225,"id":35},{"text":"line","start":226,"end":230,"id":36},{"text":"search","start":231,"end":237,"id":37},{"text":"to","start":238,"end":240,"id":38},{"text":"approximate","start":241,"end":252,"id":39},{"text":"the","start":253,"end":256,"id":40},{"text":"optimal","start":257,"end":264,"id":41},{"text":"value","start":265,"end":270,"id":42},{"text":"for","start":271,"end":274,"id":43},{"text":"the","start":275,"end":278,"id":44},{"text":"group","start":279,"end":284,"id":45},{"text":"of","start":285,"end":287,"id":46},{"text":"coefficients","start":288,"end":300,"id":47},{"text":"when","start":301,"end":305,"id":48},{"text":"all","start":306,"end":309,"id":49},{"text":"other","start":310,"end":315,"id":50},{"text":"groups","start":316,"end":322,"id":51},{"text":"'","start":322,"end":323,"id":52},{"text":"coefficients","start":324,"end":336,"id":53},{"text":"are","start":337,"end":340,"id":54},{"text":"fixed","start":341,"end":346,"id":55},{"text":".","start":346,"end":347,"id":56}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We present a new method of computation for the group lasso in the linear regression case, the Single Line Search (SLS) algorithm, which operates by computing the exact optimal value for each group (when all other coefficients are fixed) with one univariate line search.","_input_hash":1701680259,"_task_hash":1137345322,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"present","start":3,"end":10,"id":1},{"text":"a","start":11,"end":12,"id":2},{"text":"new","start":13,"end":16,"id":3},{"text":"method","start":17,"end":23,"id":4},{"text":"of","start":24,"end":26,"id":5},{"text":"computation","start":27,"end":38,"id":6},{"text":"for","start":39,"end":42,"id":7},{"text":"the","start":43,"end":46,"id":8},{"text":"group","start":47,"end":52,"id":9},{"text":"lasso","start":53,"end":58,"id":10},{"text":"in","start":59,"end":61,"id":11},{"text":"the","start":62,"end":65,"id":12},{"text":"linear","start":66,"end":72,"id":13},{"text":"regression","start":73,"end":83,"id":14},{"text":"case","start":84,"end":88,"id":15},{"text":",","start":88,"end":89,"id":16},{"text":"the","start":90,"end":93,"id":17},{"text":"Single","start":94,"end":100,"id":18},{"text":"Line","start":101,"end":105,"id":19},{"text":"Search","start":106,"end":112,"id":20},{"text":"(","start":113,"end":114,"id":21},{"text":"SLS","start":114,"end":117,"id":22},{"text":")","start":117,"end":118,"id":23},{"text":"algorithm","start":119,"end":128,"id":24},{"text":",","start":128,"end":129,"id":25},{"text":"which","start":130,"end":135,"id":26},{"text":"operates","start":136,"end":144,"id":27},{"text":"by","start":145,"end":147,"id":28},{"text":"computing","start":148,"end":157,"id":29},{"text":"the","start":158,"end":161,"id":30},{"text":"exact","start":162,"end":167,"id":31},{"text":"optimal","start":168,"end":175,"id":32},{"text":"value","start":176,"end":181,"id":33},{"text":"for","start":182,"end":185,"id":34},{"text":"each","start":186,"end":190,"id":35},{"text":"group","start":191,"end":196,"id":36},{"text":"(","start":197,"end":198,"id":37},{"text":"when","start":198,"end":202,"id":38},{"text":"all","start":203,"end":206,"id":39},{"text":"other","start":207,"end":212,"id":40},{"text":"coefficients","start":213,"end":225,"id":41},{"text":"are","start":226,"end":229,"id":42},{"text":"fixed","start":230,"end":235,"id":43},{"text":")","start":235,"end":236,"id":44},{"text":"with","start":237,"end":241,"id":45},{"text":"one","start":242,"end":245,"id":46},{"text":"univariate","start":246,"end":256,"id":47},{"text":"line","start":257,"end":261,"id":48},{"text":"search","start":262,"end":268,"id":49},{"text":".","start":268,"end":269,"id":50}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":94,"end":112,"token_start":18,"token_end":20,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"We perform simulations demonstrating that the SLS algorithm is often more efficient than existing computational methods.","_input_hash":937001547,"_task_hash":-419266207,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"perform","start":3,"end":10,"id":1},{"text":"simulations","start":11,"end":22,"id":2},{"text":"demonstrating","start":23,"end":36,"id":3},{"text":"that","start":37,"end":41,"id":4},{"text":"the","start":42,"end":45,"id":5},{"text":"SLS","start":46,"end":49,"id":6},{"text":"algorithm","start":50,"end":59,"id":7},{"text":"is","start":60,"end":62,"id":8},{"text":"often","start":63,"end":68,"id":9},{"text":"more","start":69,"end":73,"id":10},{"text":"efficient","start":74,"end":83,"id":11},{"text":"than","start":84,"end":88,"id":12},{"text":"existing","start":89,"end":97,"id":13},{"text":"computational","start":98,"end":111,"id":14},{"text":"methods","start":112,"end":119,"id":15},{"text":".","start":119,"end":120,"id":16}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We also extend the SLS algorithm to the sparse group lasso problem via the Signed Single Line Search (SSLS) algorithm, and give theoretical results to support both algorithms.","_input_hash":-515706185,"_task_hash":587751946,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"also","start":3,"end":7,"id":1},{"text":"extend","start":8,"end":14,"id":2},{"text":"the","start":15,"end":18,"id":3},{"text":"SLS","start":19,"end":22,"id":4},{"text":"algorithm","start":23,"end":32,"id":5},{"text":"to","start":33,"end":35,"id":6},{"text":"the","start":36,"end":39,"id":7},{"text":"sparse","start":40,"end":46,"id":8},{"text":"group","start":47,"end":52,"id":9},{"text":"lasso","start":53,"end":58,"id":10},{"text":"problem","start":59,"end":66,"id":11},{"text":"via","start":67,"end":70,"id":12},{"text":"the","start":71,"end":74,"id":13},{"text":"Signed","start":75,"end":81,"id":14},{"text":"Single","start":82,"end":88,"id":15},{"text":"Line","start":89,"end":93,"id":16},{"text":"Search","start":94,"end":100,"id":17},{"text":"(","start":101,"end":102,"id":18},{"text":"SSLS","start":102,"end":106,"id":19},{"text":")","start":106,"end":107,"id":20},{"text":"algorithm","start":108,"end":117,"id":21},{"text":",","start":117,"end":118,"id":22},{"text":"and","start":119,"end":122,"id":23},{"text":"give","start":123,"end":127,"id":24},{"text":"theoretical","start":128,"end":139,"id":25},{"text":"results","start":140,"end":147,"id":26},{"text":"to","start":148,"end":150,"id":27},{"text":"support","start":151,"end":158,"id":28},{"text":"both","start":159,"end":163,"id":29},{"text":"algorithms","start":164,"end":174,"id":30},{"text":".","start":174,"end":175,"id":31}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":75,"end":100,"token_start":14,"token_end":17,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"While Gaussian probability densities are omnipresent in applied mathematics, Gaussian cumulative probabilities are hard to calculate in any but the univariate case.","_input_hash":-551129427,"_task_hash":786672683,"tokens":[{"text":"While","start":0,"end":5,"id":0},{"text":"Gaussian","start":6,"end":14,"id":1},{"text":"probability","start":15,"end":26,"id":2},{"text":"densities","start":27,"end":36,"id":3},{"text":"are","start":37,"end":40,"id":4},{"text":"omnipresent","start":41,"end":52,"id":5},{"text":"in","start":53,"end":55,"id":6},{"text":"applied","start":56,"end":63,"id":7},{"text":"mathematics","start":64,"end":75,"id":8},{"text":",","start":75,"end":76,"id":9},{"text":"Gaussian","start":77,"end":85,"id":10},{"text":"cumulative","start":86,"end":96,"id":11},{"text":"probabilities","start":97,"end":110,"id":12},{"text":"are","start":111,"end":114,"id":13},{"text":"hard","start":115,"end":119,"id":14},{"text":"to","start":120,"end":122,"id":15},{"text":"calculate","start":123,"end":132,"id":16},{"text":"in","start":133,"end":135,"id":17},{"text":"any","start":136,"end":139,"id":18},{"text":"but","start":140,"end":143,"id":19},{"text":"the","start":144,"end":147,"id":20},{"text":"univariate","start":148,"end":158,"id":21},{"text":"case","start":159,"end":163,"id":22},{"text":".","start":163,"end":164,"id":23}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We study the utility of Expectation Propagation (EP) as an approximate integration method for this problem.","_input_hash":1221988460,"_task_hash":380541743,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"study","start":3,"end":8,"id":1},{"text":"the","start":9,"end":12,"id":2},{"text":"utility","start":13,"end":20,"id":3},{"text":"of","start":21,"end":23,"id":4},{"text":"Expectation","start":24,"end":35,"id":5},{"text":"Propagation","start":36,"end":47,"id":6},{"text":"(","start":48,"end":49,"id":7},{"text":"EP","start":49,"end":51,"id":8},{"text":")","start":51,"end":52,"id":9},{"text":"as","start":53,"end":55,"id":10},{"text":"an","start":56,"end":58,"id":11},{"text":"approximate","start":59,"end":70,"id":12},{"text":"integration","start":71,"end":82,"id":13},{"text":"method","start":83,"end":89,"id":14},{"text":"for","start":90,"end":93,"id":15},{"text":"this","start":94,"end":98,"id":16},{"text":"problem","start":99,"end":106,"id":17},{"text":".","start":106,"end":107,"id":18}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":24,"end":47,"token_start":5,"token_end":6,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"For rectangular integration regions, the approximation is highly accurate.","_input_hash":-1840298008,"_task_hash":834710342,"tokens":[{"text":"For","start":0,"end":3,"id":0},{"text":"rectangular","start":4,"end":15,"id":1},{"text":"integration","start":16,"end":27,"id":2},{"text":"regions","start":28,"end":35,"id":3},{"text":",","start":35,"end":36,"id":4},{"text":"the","start":37,"end":40,"id":5},{"text":"approximation","start":41,"end":54,"id":6},{"text":"is","start":55,"end":57,"id":7},{"text":"highly","start":58,"end":64,"id":8},{"text":"accurate","start":65,"end":73,"id":9},{"text":".","start":73,"end":74,"id":10}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We also extend the derivations to the more general case of polyhedral integration regions.","_input_hash":-202669824,"_task_hash":8827691,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"also","start":3,"end":7,"id":1},{"text":"extend","start":8,"end":14,"id":2},{"text":"the","start":15,"end":18,"id":3},{"text":"derivations","start":19,"end":30,"id":4},{"text":"to","start":31,"end":33,"id":5},{"text":"the","start":34,"end":37,"id":6},{"text":"more","start":38,"end":42,"id":7},{"text":"general","start":43,"end":50,"id":8},{"text":"case","start":51,"end":55,"id":9},{"text":"of","start":56,"end":58,"id":10},{"text":"polyhedral","start":59,"end":69,"id":11},{"text":"integration","start":70,"end":81,"id":12},{"text":"regions","start":82,"end":89,"id":13},{"text":".","start":89,"end":90,"id":14}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"However, we find that in this polyhedral case, EP's answer, though often accurate, can be almost arbitrarily wrong.","_input_hash":-1126795336,"_task_hash":-1536734966,"tokens":[{"text":"However","start":0,"end":7,"id":0},{"text":",","start":7,"end":8,"id":1},{"text":"we","start":9,"end":11,"id":2},{"text":"find","start":12,"end":16,"id":3},{"text":"that","start":17,"end":21,"id":4},{"text":"in","start":22,"end":24,"id":5},{"text":"this","start":25,"end":29,"id":6},{"text":"polyhedral","start":30,"end":40,"id":7},{"text":"case","start":41,"end":45,"id":8},{"text":",","start":45,"end":46,"id":9},{"text":"EP","start":47,"end":49,"id":10},{"text":"'s","start":49,"end":51,"id":11},{"text":"answer","start":52,"end":58,"id":12},{"text":",","start":58,"end":59,"id":13},{"text":"though","start":60,"end":66,"id":14},{"text":"often","start":67,"end":72,"id":15},{"text":"accurate","start":73,"end":81,"id":16},{"text":",","start":81,"end":82,"id":17},{"text":"can","start":83,"end":86,"id":18},{"text":"be","start":87,"end":89,"id":19},{"text":"almost","start":90,"end":96,"id":20},{"text":"arbitrarily","start":97,"end":108,"id":21},{"text":"wrong","start":109,"end":114,"id":22},{"text":".","start":114,"end":115,"id":23}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We consider these unexpected results empirically and theoretically, both for the problem of Gaussian probabilities and for EP more generally.","_input_hash":-1538307085,"_task_hash":-986271374,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"consider","start":3,"end":11,"id":1},{"text":"these","start":12,"end":17,"id":2},{"text":"unexpected","start":18,"end":28,"id":3},{"text":"results","start":29,"end":36,"id":4},{"text":"empirically","start":37,"end":48,"id":5},{"text":"and","start":49,"end":52,"id":6},{"text":"theoretically","start":53,"end":66,"id":7},{"text":",","start":66,"end":67,"id":8},{"text":"both","start":68,"end":72,"id":9},{"text":"for","start":73,"end":76,"id":10},{"text":"the","start":77,"end":80,"id":11},{"text":"problem","start":81,"end":88,"id":12},{"text":"of","start":89,"end":91,"id":13},{"text":"Gaussian","start":92,"end":100,"id":14},{"text":"probabilities","start":101,"end":114,"id":15},{"text":"and","start":115,"end":118,"id":16},{"text":"for","start":119,"end":122,"id":17},{"text":"EP","start":123,"end":125,"id":18},{"text":"more","start":126,"end":130,"id":19},{"text":"generally","start":131,"end":140,"id":20},{"text":".","start":140,"end":141,"id":21}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"These results elucidate an interesting and non-obvious feature of EP not yet studied in detail.","_input_hash":-758188468,"_task_hash":553900017,"tokens":[{"text":"These","start":0,"end":5,"id":0},{"text":"results","start":6,"end":13,"id":1},{"text":"elucidate","start":14,"end":23,"id":2},{"text":"an","start":24,"end":26,"id":3},{"text":"interesting","start":27,"end":38,"id":4},{"text":"and","start":39,"end":42,"id":5},{"text":"non","start":43,"end":46,"id":6},{"text":"-","start":46,"end":47,"id":7},{"text":"obvious","start":47,"end":54,"id":8},{"text":"feature","start":55,"end":62,"id":9},{"text":"of","start":63,"end":65,"id":10},{"text":"EP","start":66,"end":68,"id":11},{"text":"not","start":69,"end":72,"id":12},{"text":"yet","start":73,"end":76,"id":13},{"text":"studied","start":77,"end":84,"id":14},{"text":"in","start":85,"end":87,"id":15},{"text":"detail","start":88,"end":94,"id":16},{"text":".","start":94,"end":95,"id":17}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"This paper addresses the problem of inferring sparse causal networks modeled by multivariate auto-regressive (MAR) processes.","_input_hash":305414504,"_task_hash":-1552868109,"tokens":[{"text":"This","start":0,"end":4,"id":0},{"text":"paper","start":5,"end":10,"id":1},{"text":"addresses","start":11,"end":20,"id":2},{"text":"the","start":21,"end":24,"id":3},{"text":"problem","start":25,"end":32,"id":4},{"text":"of","start":33,"end":35,"id":5},{"text":"inferring","start":36,"end":45,"id":6},{"text":"sparse","start":46,"end":52,"id":7},{"text":"causal","start":53,"end":59,"id":8},{"text":"networks","start":60,"end":68,"id":9},{"text":"modeled","start":69,"end":76,"id":10},{"text":"by","start":77,"end":79,"id":11},{"text":"multivariate","start":80,"end":92,"id":12},{"text":"auto","start":93,"end":97,"id":13},{"text":"-","start":97,"end":98,"id":14},{"text":"regressive","start":98,"end":108,"id":15},{"text":"(","start":109,"end":110,"id":16},{"text":"MAR","start":110,"end":113,"id":17},{"text":")","start":113,"end":114,"id":18},{"text":"processes","start":115,"end":124,"id":19},{"text":".","start":124,"end":125,"id":20}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":80,"end":108,"token_start":12,"token_end":15,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"Conditions are derived under which the Group Lasso (gLasso) procedure consistently estimates sparse network structure.","_input_hash":683925385,"_task_hash":272139281,"tokens":[{"text":"Conditions","start":0,"end":10,"id":0},{"text":"are","start":11,"end":14,"id":1},{"text":"derived","start":15,"end":22,"id":2},{"text":"under","start":23,"end":28,"id":3},{"text":"which","start":29,"end":34,"id":4},{"text":"the","start":35,"end":38,"id":5},{"text":"Group","start":39,"end":44,"id":6},{"text":"Lasso","start":45,"end":50,"id":7},{"text":"(","start":51,"end":52,"id":8},{"text":"gLasso","start":52,"end":58,"id":9},{"text":")","start":58,"end":59,"id":10},{"text":"procedure","start":60,"end":69,"id":11},{"text":"consistently","start":70,"end":82,"id":12},{"text":"estimates","start":83,"end":92,"id":13},{"text":"sparse","start":93,"end":99,"id":14},{"text":"network","start":100,"end":107,"id":15},{"text":"structure","start":108,"end":117,"id":16},{"text":".","start":117,"end":118,"id":17}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":39,"end":50,"token_start":6,"token_end":7,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"The key condition involves a \"false connection score.\"","_input_hash":-1370745132,"_task_hash":2052763109,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"key","start":4,"end":7,"id":1},{"text":"condition","start":8,"end":17,"id":2},{"text":"involves","start":18,"end":26,"id":3},{"text":"a","start":27,"end":28,"id":4},{"text":"\"","start":29,"end":30,"id":5},{"text":"false","start":30,"end":35,"id":6},{"text":"connection","start":36,"end":46,"id":7},{"text":"score","start":47,"end":52,"id":8},{"text":".","start":52,"end":53,"id":9},{"text":"\"","start":53,"end":54,"id":10}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"In particular, we show that consistent recovery is possible even when the number of observations of the network is far less than the number of parameters describing the network, provided that the false connection score is less than one.","_input_hash":-1673897756,"_task_hash":28047924,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"particular","start":3,"end":13,"id":1},{"text":",","start":13,"end":14,"id":2},{"text":"we","start":15,"end":17,"id":3},{"text":"show","start":18,"end":22,"id":4},{"text":"that","start":23,"end":27,"id":5},{"text":"consistent","start":28,"end":38,"id":6},{"text":"recovery","start":39,"end":47,"id":7},{"text":"is","start":48,"end":50,"id":8},{"text":"possible","start":51,"end":59,"id":9},{"text":"even","start":60,"end":64,"id":10},{"text":"when","start":65,"end":69,"id":11},{"text":"the","start":70,"end":73,"id":12},{"text":"number","start":74,"end":80,"id":13},{"text":"of","start":81,"end":83,"id":14},{"text":"observations","start":84,"end":96,"id":15},{"text":"of","start":97,"end":99,"id":16},{"text":"the","start":100,"end":103,"id":17},{"text":"network","start":104,"end":111,"id":18},{"text":"is","start":112,"end":114,"id":19},{"text":"far","start":115,"end":118,"id":20},{"text":"less","start":119,"end":123,"id":21},{"text":"than","start":124,"end":128,"id":22},{"text":"the","start":129,"end":132,"id":23},{"text":"number","start":133,"end":139,"id":24},{"text":"of","start":140,"end":142,"id":25},{"text":"parameters","start":143,"end":153,"id":26},{"text":"describing","start":154,"end":164,"id":27},{"text":"the","start":165,"end":168,"id":28},{"text":"network","start":169,"end":176,"id":29},{"text":",","start":176,"end":177,"id":30},{"text":"provided","start":178,"end":186,"id":31},{"text":"that","start":187,"end":191,"id":32},{"text":"the","start":192,"end":195,"id":33},{"text":"false","start":196,"end":201,"id":34},{"text":"connection","start":202,"end":212,"id":35},{"text":"score","start":213,"end":218,"id":36},{"text":"is","start":219,"end":221,"id":37},{"text":"less","start":222,"end":226,"id":38},{"text":"than","start":227,"end":231,"id":39},{"text":"one","start":232,"end":235,"id":40},{"text":".","start":235,"end":236,"id":41}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"The false connection score is also demonstrated to be a useful metric of recovery in non-asymptotic regimes.","_input_hash":-202491473,"_task_hash":593103164,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"false","start":4,"end":9,"id":1},{"text":"connection","start":10,"end":20,"id":2},{"text":"score","start":21,"end":26,"id":3},{"text":"is","start":27,"end":29,"id":4},{"text":"also","start":30,"end":34,"id":5},{"text":"demonstrated","start":35,"end":47,"id":6},{"text":"to","start":48,"end":50,"id":7},{"text":"be","start":51,"end":53,"id":8},{"text":"a","start":54,"end":55,"id":9},{"text":"useful","start":56,"end":62,"id":10},{"text":"metric","start":63,"end":69,"id":11},{"text":"of","start":70,"end":72,"id":12},{"text":"recovery","start":73,"end":81,"id":13},{"text":"in","start":82,"end":84,"id":14},{"text":"non","start":85,"end":88,"id":15},{"text":"-","start":88,"end":89,"id":16},{"text":"asymptotic","start":89,"end":99,"id":17},{"text":"regimes","start":100,"end":107,"id":18},{"text":".","start":107,"end":108,"id":19}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"The conditions suggest a modified gLasso procedure which tends to improve the false connection score and reduce the chances of reversing the direction of causal influence.","_input_hash":-1148285021,"_task_hash":-753559489,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"conditions","start":4,"end":14,"id":1},{"text":"suggest","start":15,"end":22,"id":2},{"text":"a","start":23,"end":24,"id":3},{"text":"modified","start":25,"end":33,"id":4},{"text":"gLasso","start":34,"end":40,"id":5},{"text":"procedure","start":41,"end":50,"id":6},{"text":"which","start":51,"end":56,"id":7},{"text":"tends","start":57,"end":62,"id":8},{"text":"to","start":63,"end":65,"id":9},{"text":"improve","start":66,"end":73,"id":10},{"text":"the","start":74,"end":77,"id":11},{"text":"false","start":78,"end":83,"id":12},{"text":"connection","start":84,"end":94,"id":13},{"text":"score","start":95,"end":100,"id":14},{"text":"and","start":101,"end":104,"id":15},{"text":"reduce","start":105,"end":111,"id":16},{"text":"the","start":112,"end":115,"id":17},{"text":"chances","start":116,"end":123,"id":18},{"text":"of","start":124,"end":126,"id":19},{"text":"reversing","start":127,"end":136,"id":20},{"text":"the","start":137,"end":140,"id":21},{"text":"direction","start":141,"end":150,"id":22},{"text":"of","start":151,"end":153,"id":23},{"text":"causal","start":154,"end":160,"id":24},{"text":"influence","start":161,"end":170,"id":25},{"text":".","start":170,"end":171,"id":26}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Computational experiments and a real network based electrocorticogram (ECoG) simulation study demonstrate the effectiveness of the approach.","_input_hash":886949257,"_task_hash":1945001663,"tokens":[{"text":"Computational","start":0,"end":13,"id":0},{"text":"experiments","start":14,"end":25,"id":1},{"text":"and","start":26,"end":29,"id":2},{"text":"a","start":30,"end":31,"id":3},{"text":"real","start":32,"end":36,"id":4},{"text":"network","start":37,"end":44,"id":5},{"text":"based","start":45,"end":50,"id":6},{"text":"electrocorticogram","start":51,"end":69,"id":7},{"text":"(","start":70,"end":71,"id":8},{"text":"ECoG","start":71,"end":75,"id":9},{"text":")","start":75,"end":76,"id":10},{"text":"simulation","start":77,"end":87,"id":11},{"text":"study","start":88,"end":93,"id":12},{"text":"demonstrate","start":94,"end":105,"id":13},{"text":"the","start":106,"end":109,"id":14},{"text":"effectiveness","start":110,"end":123,"id":15},{"text":"of","start":124,"end":126,"id":16},{"text":"the","start":127,"end":130,"id":17},{"text":"approach","start":131,"end":139,"id":18},{"text":".","start":139,"end":140,"id":19}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"In this article, we derive concentration inequalities for the cross-validation estimate of the generalization error for stable predictors in the context of risk assessment.","_input_hash":-1655939788,"_task_hash":-1249975282,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"this","start":3,"end":7,"id":1},{"text":"article","start":8,"end":15,"id":2},{"text":",","start":15,"end":16,"id":3},{"text":"we","start":17,"end":19,"id":4},{"text":"derive","start":20,"end":26,"id":5},{"text":"concentration","start":27,"end":40,"id":6},{"text":"inequalities","start":41,"end":53,"id":7},{"text":"for","start":54,"end":57,"id":8},{"text":"the","start":58,"end":61,"id":9},{"text":"cross","start":62,"end":67,"id":10},{"text":"-","start":67,"end":68,"id":11},{"text":"validation","start":68,"end":78,"id":12},{"text":"estimate","start":79,"end":87,"id":13},{"text":"of","start":88,"end":90,"id":14},{"text":"the","start":91,"end":94,"id":15},{"text":"generalization","start":95,"end":109,"id":16},{"text":"error","start":110,"end":115,"id":17},{"text":"for","start":116,"end":119,"id":18},{"text":"stable","start":120,"end":126,"id":19},{"text":"predictors","start":127,"end":137,"id":20},{"text":"in","start":138,"end":140,"id":21},{"text":"the","start":141,"end":144,"id":22},{"text":"context","start":145,"end":152,"id":23},{"text":"of","start":153,"end":155,"id":24},{"text":"risk","start":156,"end":160,"id":25},{"text":"assessment","start":161,"end":171,"id":26},{"text":".","start":171,"end":172,"id":27}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"The notion of stability has been first introduced by \\cite{DEWA79} and extended by \\cite{KEA95}, \\cite{BE01} and \\cite{KUNIY02} to characterize class of predictors with infinite VC dimension.","_input_hash":474033043,"_task_hash":238500727,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"notion","start":4,"end":10,"id":1},{"text":"of","start":11,"end":13,"id":2},{"text":"stability","start":14,"end":23,"id":3},{"text":"has","start":24,"end":27,"id":4},{"text":"been","start":28,"end":32,"id":5},{"text":"first","start":33,"end":38,"id":6},{"text":"introduced","start":39,"end":49,"id":7},{"text":"by","start":50,"end":52,"id":8},{"text":"\\cite{DEWA79","start":53,"end":65,"id":9},{"text":"}","start":65,"end":66,"id":10},{"text":"and","start":67,"end":70,"id":11},{"text":"extended","start":71,"end":79,"id":12},{"text":"by","start":80,"end":82,"id":13},{"text":"\\cite{KEA95","start":83,"end":94,"id":14},{"text":"}","start":94,"end":95,"id":15},{"text":",","start":95,"end":96,"id":16},{"text":"\\cite{BE01","start":97,"end":107,"id":17},{"text":"}","start":107,"end":108,"id":18},{"text":"and","start":109,"end":112,"id":19},{"text":"\\cite{KUNIY02","start":113,"end":126,"id":20},{"text":"}","start":126,"end":127,"id":21},{"text":"to","start":128,"end":130,"id":22},{"text":"characterize","start":131,"end":143,"id":23},{"text":"class","start":144,"end":149,"id":24},{"text":"of","start":150,"end":152,"id":25},{"text":"predictors","start":153,"end":163,"id":26},{"text":"with","start":164,"end":168,"id":27},{"text":"infinite","start":169,"end":177,"id":28},{"text":"VC","start":178,"end":180,"id":29},{"text":"dimension","start":181,"end":190,"id":30},{"text":".","start":190,"end":191,"id":31}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"In particular, this covers $k$-nearest neighbors rules, bayesian algorithm (\\cite{KEA95}), boosting,... General loss functions and class of predictors are considered.","_input_hash":2092124762,"_task_hash":-244910506,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"particular","start":3,"end":13,"id":1},{"text":",","start":13,"end":14,"id":2},{"text":"this","start":15,"end":19,"id":3},{"text":"covers","start":20,"end":26,"id":4},{"text":"$","start":27,"end":28,"id":5},{"text":"k$-nearest","start":28,"end":38,"id":6},{"text":"neighbors","start":39,"end":48,"id":7},{"text":"rules","start":49,"end":54,"id":8},{"text":",","start":54,"end":55,"id":9},{"text":"bayesian","start":56,"end":64,"id":10},{"text":"algorithm","start":65,"end":74,"id":11},{"text":"(","start":75,"end":76,"id":12},{"text":"\\cite{KEA95","start":76,"end":87,"id":13},{"text":"}","start":87,"end":88,"id":14},{"text":")","start":88,"end":89,"id":15},{"text":",","start":89,"end":90,"id":16},{"text":"boosting","start":91,"end":99,"id":17},{"text":",","start":99,"end":100,"id":18},{"text":"...","start":100,"end":103,"id":19},{"text":"General","start":104,"end":111,"id":20},{"text":"loss","start":112,"end":116,"id":21},{"text":"functions","start":117,"end":126,"id":22},{"text":"and","start":127,"end":130,"id":23},{"text":"class","start":131,"end":136,"id":24},{"text":"of","start":137,"end":139,"id":25},{"text":"predictors","start":140,"end":150,"id":26},{"text":"are","start":151,"end":154,"id":27},{"text":"considered","start":155,"end":165,"id":28},{"text":".","start":165,"end":166,"id":29}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":27,"end":48,"token_start":5,"token_end":7,"label":"ALGO","answer":"accept"},{"start":56,"end":64,"token_start":10,"token_end":10,"label":"ALGO","answer":"accept"},{"start":91,"end":99,"token_start":17,"token_end":17,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"We use the formalism introduced by \\cite{DUD03} to cover a large variety of cross-validation procedures including leave-one-out cross-validation, $k$-fold cross-validation, hold-out cross-validation (or split sample), and the leave-$\\upsilon$-out cross-validation.","_input_hash":-1200915465,"_task_hash":1963391095,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"use","start":3,"end":6,"id":1},{"text":"the","start":7,"end":10,"id":2},{"text":"formalism","start":11,"end":20,"id":3},{"text":"introduced","start":21,"end":31,"id":4},{"text":"by","start":32,"end":34,"id":5},{"text":"\\cite{DUD03","start":35,"end":46,"id":6},{"text":"}","start":46,"end":47,"id":7},{"text":"to","start":48,"end":50,"id":8},{"text":"cover","start":51,"end":56,"id":9},{"text":"a","start":57,"end":58,"id":10},{"text":"large","start":59,"end":64,"id":11},{"text":"variety","start":65,"end":72,"id":12},{"text":"of","start":73,"end":75,"id":13},{"text":"cross","start":76,"end":81,"id":14},{"text":"-","start":81,"end":82,"id":15},{"text":"validation","start":82,"end":92,"id":16},{"text":"procedures","start":93,"end":103,"id":17},{"text":"including","start":104,"end":113,"id":18},{"text":"leave","start":114,"end":119,"id":19},{"text":"-","start":119,"end":120,"id":20},{"text":"one","start":120,"end":123,"id":21},{"text":"-","start":123,"end":124,"id":22},{"text":"out","start":124,"end":127,"id":23},{"text":"cross","start":128,"end":133,"id":24},{"text":"-","start":133,"end":134,"id":25},{"text":"validation","start":134,"end":144,"id":26},{"text":",","start":144,"end":145,"id":27},{"text":"$","start":146,"end":147,"id":28},{"text":"k$-fold","start":147,"end":154,"id":29},{"text":"cross","start":155,"end":160,"id":30},{"text":"-","start":160,"end":161,"id":31},{"text":"validation","start":161,"end":171,"id":32},{"text":",","start":171,"end":172,"id":33},{"text":"hold","start":173,"end":177,"id":34},{"text":"-","start":177,"end":178,"id":35},{"text":"out","start":178,"end":181,"id":36},{"text":"cross","start":182,"end":187,"id":37},{"text":"-","start":187,"end":188,"id":38},{"text":"validation","start":188,"end":198,"id":39},{"text":"(","start":199,"end":200,"id":40},{"text":"or","start":200,"end":202,"id":41},{"text":"split","start":203,"end":208,"id":42},{"text":"sample","start":209,"end":215,"id":43},{"text":")","start":215,"end":216,"id":44},{"text":",","start":216,"end":217,"id":45},{"text":"and","start":218,"end":221,"id":46},{"text":"the","start":222,"end":225,"id":47},{"text":"leave-$\\upsilon$-out","start":226,"end":246,"id":48},{"text":"cross","start":247,"end":252,"id":49},{"text":"-","start":252,"end":253,"id":50},{"text":"validation","start":253,"end":263,"id":51},{"text":".","start":263,"end":264,"id":52}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":120,"end":144,"token_start":21,"token_end":26,"label":"ALGO","answer":"accept"},{"start":146,"end":171,"token_start":28,"token_end":32,"label":"ALGO","answer":"accept"},{"start":173,"end":198,"token_start":34,"token_end":39,"label":"ALGO","answer":"accept"},{"start":226,"end":263,"token_start":48,"token_end":51,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"  In particular, we give a simple rule on how to choose the cross-validation, depending on the stability of the class of predictors.","_input_hash":1134394892,"_task_hash":-1594325097,"tokens":[{"text":"  ","start":0,"end":2,"id":0},{"text":"In","start":2,"end":4,"id":1},{"text":"particular","start":5,"end":15,"id":2},{"text":",","start":15,"end":16,"id":3},{"text":"we","start":17,"end":19,"id":4},{"text":"give","start":20,"end":24,"id":5},{"text":"a","start":25,"end":26,"id":6},{"text":"simple","start":27,"end":33,"id":7},{"text":"rule","start":34,"end":38,"id":8},{"text":"on","start":39,"end":41,"id":9},{"text":"how","start":42,"end":45,"id":10},{"text":"to","start":46,"end":48,"id":11},{"text":"choose","start":49,"end":55,"id":12},{"text":"the","start":56,"end":59,"id":13},{"text":"cross","start":60,"end":65,"id":14},{"text":"-","start":65,"end":66,"id":15},{"text":"validation","start":66,"end":76,"id":16},{"text":",","start":76,"end":77,"id":17},{"text":"depending","start":78,"end":87,"id":18},{"text":"on","start":88,"end":90,"id":19},{"text":"the","start":91,"end":94,"id":20},{"text":"stability","start":95,"end":104,"id":21},{"text":"of","start":105,"end":107,"id":22},{"text":"the","start":108,"end":111,"id":23},{"text":"class","start":112,"end":117,"id":24},{"text":"of","start":118,"end":120,"id":25},{"text":"predictors","start":121,"end":131,"id":26},{"text":".","start":131,"end":132,"id":27}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"In the special case of uniform stability, an interesting consequence is that the number of elements in the test set is not required to grow to infinity for the consistency of the cross-validation procedure.","_input_hash":-47412698,"_task_hash":674560111,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"the","start":3,"end":6,"id":1},{"text":"special","start":7,"end":14,"id":2},{"text":"case","start":15,"end":19,"id":3},{"text":"of","start":20,"end":22,"id":4},{"text":"uniform","start":23,"end":30,"id":5},{"text":"stability","start":31,"end":40,"id":6},{"text":",","start":40,"end":41,"id":7},{"text":"an","start":42,"end":44,"id":8},{"text":"interesting","start":45,"end":56,"id":9},{"text":"consequence","start":57,"end":68,"id":10},{"text":"is","start":69,"end":71,"id":11},{"text":"that","start":72,"end":76,"id":12},{"text":"the","start":77,"end":80,"id":13},{"text":"number","start":81,"end":87,"id":14},{"text":"of","start":88,"end":90,"id":15},{"text":"elements","start":91,"end":99,"id":16},{"text":"in","start":100,"end":102,"id":17},{"text":"the","start":103,"end":106,"id":18},{"text":"test","start":107,"end":111,"id":19},{"text":"set","start":112,"end":115,"id":20},{"text":"is","start":116,"end":118,"id":21},{"text":"not","start":119,"end":122,"id":22},{"text":"required","start":123,"end":131,"id":23},{"text":"to","start":132,"end":134,"id":24},{"text":"grow","start":135,"end":139,"id":25},{"text":"to","start":140,"end":142,"id":26},{"text":"infinity","start":143,"end":151,"id":27},{"text":"for","start":152,"end":155,"id":28},{"text":"the","start":156,"end":159,"id":29},{"text":"consistency","start":160,"end":171,"id":30},{"text":"of","start":172,"end":174,"id":31},{"text":"the","start":175,"end":178,"id":32},{"text":"cross","start":179,"end":184,"id":33},{"text":"-","start":184,"end":185,"id":34},{"text":"validation","start":185,"end":195,"id":35},{"text":"procedure","start":196,"end":205,"id":36},{"text":".","start":205,"end":206,"id":37}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"In this special case, the particular interest of leave-one-out cross-validation is emphasized.","_input_hash":1687676903,"_task_hash":1125153122,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"this","start":3,"end":7,"id":1},{"text":"special","start":8,"end":15,"id":2},{"text":"case","start":16,"end":20,"id":3},{"text":",","start":20,"end":21,"id":4},{"text":"the","start":22,"end":25,"id":5},{"text":"particular","start":26,"end":36,"id":6},{"text":"interest","start":37,"end":45,"id":7},{"text":"of","start":46,"end":48,"id":8},{"text":"leave","start":49,"end":54,"id":9},{"text":"-","start":54,"end":55,"id":10},{"text":"one","start":55,"end":58,"id":11},{"text":"-","start":58,"end":59,"id":12},{"text":"out","start":59,"end":62,"id":13},{"text":"cross","start":63,"end":68,"id":14},{"text":"-","start":68,"end":69,"id":15},{"text":"validation","start":69,"end":79,"id":16},{"text":"is","start":80,"end":82,"id":17},{"text":"emphasized","start":83,"end":93,"id":18},{"text":".","start":93,"end":94,"id":19}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Since learning is typically very slow in Boltzmann machines, there is a need to restrict connections within hidden layers.","_input_hash":1867951622,"_task_hash":344600058,"tokens":[{"text":"Since","start":0,"end":5,"id":0},{"text":"learning","start":6,"end":14,"id":1},{"text":"is","start":15,"end":17,"id":2},{"text":"typically","start":18,"end":27,"id":3},{"text":"very","start":28,"end":32,"id":4},{"text":"slow","start":33,"end":37,"id":5},{"text":"in","start":38,"end":40,"id":6},{"text":"Boltzmann","start":41,"end":50,"id":7},{"text":"machines","start":51,"end":59,"id":8},{"text":",","start":59,"end":60,"id":9},{"text":"there","start":61,"end":66,"id":10},{"text":"is","start":67,"end":69,"id":11},{"text":"a","start":70,"end":71,"id":12},{"text":"need","start":72,"end":76,"id":13},{"text":"to","start":77,"end":79,"id":14},{"text":"restrict","start":80,"end":88,"id":15},{"text":"connections","start":89,"end":100,"id":16},{"text":"within","start":101,"end":107,"id":17},{"text":"hidden","start":108,"end":114,"id":18},{"text":"layers","start":115,"end":121,"id":19},{"text":".","start":121,"end":122,"id":20}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":41,"end":59,"token_start":7,"token_end":8,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"However, the resulting states of hidden units exhibit statistical dependencies.","_input_hash":256103734,"_task_hash":358219503,"tokens":[{"text":"However","start":0,"end":7,"id":0},{"text":",","start":7,"end":8,"id":1},{"text":"the","start":9,"end":12,"id":2},{"text":"resulting","start":13,"end":22,"id":3},{"text":"states","start":23,"end":29,"id":4},{"text":"of","start":30,"end":32,"id":5},{"text":"hidden","start":33,"end":39,"id":6},{"text":"units","start":40,"end":45,"id":7},{"text":"exhibit","start":46,"end":53,"id":8},{"text":"statistical","start":54,"end":65,"id":9},{"text":"dependencies","start":66,"end":78,"id":10},{"text":".","start":78,"end":79,"id":11}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Based on this observation, we propose using $l_1/l_2$ regularization upon the activation possibilities of hidden units in restricted Boltzmann machines to capture the loacal dependencies among hidden units.","_input_hash":-779051655,"_task_hash":-748010239,"tokens":[{"text":"Based","start":0,"end":5,"id":0},{"text":"on","start":6,"end":8,"id":1},{"text":"this","start":9,"end":13,"id":2},{"text":"observation","start":14,"end":25,"id":3},{"text":",","start":25,"end":26,"id":4},{"text":"we","start":27,"end":29,"id":5},{"text":"propose","start":30,"end":37,"id":6},{"text":"using","start":38,"end":43,"id":7},{"text":"$","start":44,"end":45,"id":8},{"text":"l_1","start":45,"end":48,"id":9},{"text":"/","start":48,"end":49,"id":10},{"text":"l_2","start":49,"end":52,"id":11},{"text":"$","start":52,"end":53,"id":12},{"text":"regularization","start":54,"end":68,"id":13},{"text":"upon","start":69,"end":73,"id":14},{"text":"the","start":74,"end":77,"id":15},{"text":"activation","start":78,"end":88,"id":16},{"text":"possibilities","start":89,"end":102,"id":17},{"text":"of","start":103,"end":105,"id":18},{"text":"hidden","start":106,"end":112,"id":19},{"text":"units","start":113,"end":118,"id":20},{"text":"in","start":119,"end":121,"id":21},{"text":"restricted","start":122,"end":132,"id":22},{"text":"Boltzmann","start":133,"end":142,"id":23},{"text":"machines","start":143,"end":151,"id":24},{"text":"to","start":152,"end":154,"id":25},{"text":"capture","start":155,"end":162,"id":26},{"text":"the","start":163,"end":166,"id":27},{"text":"loacal","start":167,"end":173,"id":28},{"text":"dependencies","start":174,"end":186,"id":29},{"text":"among","start":187,"end":192,"id":30},{"text":"hidden","start":193,"end":199,"id":31},{"text":"units","start":200,"end":205,"id":32},{"text":".","start":205,"end":206,"id":33}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":122,"end":151,"token_start":22,"token_end":24,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"This regularization not only encourages hidden units of many groups to be inactive given observed data but also makes hidden units within a group compete with each other for modeling observed data.","_input_hash":146966403,"_task_hash":-1646911325,"tokens":[{"text":"This","start":0,"end":4,"id":0},{"text":"regularization","start":5,"end":19,"id":1},{"text":"not","start":20,"end":23,"id":2},{"text":"only","start":24,"end":28,"id":3},{"text":"encourages","start":29,"end":39,"id":4},{"text":"hidden","start":40,"end":46,"id":5},{"text":"units","start":47,"end":52,"id":6},{"text":"of","start":53,"end":55,"id":7},{"text":"many","start":56,"end":60,"id":8},{"text":"groups","start":61,"end":67,"id":9},{"text":"to","start":68,"end":70,"id":10},{"text":"be","start":71,"end":73,"id":11},{"text":"inactive","start":74,"end":82,"id":12},{"text":"given","start":83,"end":88,"id":13},{"text":"observed","start":89,"end":97,"id":14},{"text":"data","start":98,"end":102,"id":15},{"text":"but","start":103,"end":106,"id":16},{"text":"also","start":107,"end":111,"id":17},{"text":"makes","start":112,"end":117,"id":18},{"text":"hidden","start":118,"end":124,"id":19},{"text":"units","start":125,"end":130,"id":20},{"text":"within","start":131,"end":137,"id":21},{"text":"a","start":138,"end":139,"id":22},{"text":"group","start":140,"end":145,"id":23},{"text":"compete","start":146,"end":153,"id":24},{"text":"with","start":154,"end":158,"id":25},{"text":"each","start":159,"end":163,"id":26},{"text":"other","start":164,"end":169,"id":27},{"text":"for","start":170,"end":173,"id":28},{"text":"modeling","start":174,"end":182,"id":29},{"text":"observed","start":183,"end":191,"id":30},{"text":"data","start":192,"end":196,"id":31},{"text":".","start":196,"end":197,"id":32}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Thus, the $l_1/l_2$ regularization on RBMs yields sparsity at both the group and the hidden unit levels.","_input_hash":-115310504,"_task_hash":631214118,"tokens":[{"text":"Thus","start":0,"end":4,"id":0},{"text":",","start":4,"end":5,"id":1},{"text":"the","start":6,"end":9,"id":2},{"text":"$","start":10,"end":11,"id":3},{"text":"l_1","start":11,"end":14,"id":4},{"text":"/","start":14,"end":15,"id":5},{"text":"l_2","start":15,"end":18,"id":6},{"text":"$","start":18,"end":19,"id":7},{"text":"regularization","start":20,"end":34,"id":8},{"text":"on","start":35,"end":37,"id":9},{"text":"RBMs","start":38,"end":42,"id":10},{"text":"yields","start":43,"end":49,"id":11},{"text":"sparsity","start":50,"end":58,"id":12},{"text":"at","start":59,"end":61,"id":13},{"text":"both","start":62,"end":66,"id":14},{"text":"the","start":67,"end":70,"id":15},{"text":"group","start":71,"end":76,"id":16},{"text":"and","start":77,"end":80,"id":17},{"text":"the","start":81,"end":84,"id":18},{"text":"hidden","start":85,"end":91,"id":19},{"text":"unit","start":92,"end":96,"id":20},{"text":"levels","start":97,"end":103,"id":21},{"text":".","start":103,"end":104,"id":22}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We call RBMs trained with the regularizer \\emph{sparse group} RBMs.","_input_hash":184226534,"_task_hash":88774851,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"call","start":3,"end":7,"id":1},{"text":"RBMs","start":8,"end":12,"id":2},{"text":"trained","start":13,"end":20,"id":3},{"text":"with","start":21,"end":25,"id":4},{"text":"the","start":26,"end":29,"id":5},{"text":"regularizer","start":30,"end":41,"id":6},{"text":"\\emph{sparse","start":42,"end":54,"id":7},{"text":"group","start":55,"end":60,"id":8},{"text":"}","start":60,"end":61,"id":9},{"text":"RBMs","start":62,"end":66,"id":10},{"text":".","start":66,"end":67,"id":11}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"The proposed sparse group RBMs are applied to three tasks:","_input_hash":1504587923,"_task_hash":343018655,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"proposed","start":4,"end":12,"id":1},{"text":"sparse","start":13,"end":19,"id":2},{"text":"group","start":20,"end":25,"id":3},{"text":"RBMs","start":26,"end":30,"id":4},{"text":"are","start":31,"end":34,"id":5},{"text":"applied","start":35,"end":42,"id":6},{"text":"to","start":43,"end":45,"id":7},{"text":"three","start":46,"end":51,"id":8},{"text":"tasks","start":52,"end":57,"id":9},{"text":":","start":57,"end":58,"id":10}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"modeling patches of natural images, modeling handwritten digits and pretaining a deep networks for a classification task.","_input_hash":-508554862,"_task_hash":1344676569,"tokens":[{"text":"modeling","start":0,"end":8,"id":0},{"text":"patches","start":9,"end":16,"id":1},{"text":"of","start":17,"end":19,"id":2},{"text":"natural","start":20,"end":27,"id":3},{"text":"images","start":28,"end":34,"id":4},{"text":",","start":34,"end":35,"id":5},{"text":"modeling","start":36,"end":44,"id":6},{"text":"handwritten","start":45,"end":56,"id":7},{"text":"digits","start":57,"end":63,"id":8},{"text":"and","start":64,"end":67,"id":9},{"text":"pretaining","start":68,"end":78,"id":10},{"text":"a","start":79,"end":80,"id":11},{"text":"deep","start":81,"end":85,"id":12},{"text":"networks","start":86,"end":94,"id":13},{"text":"for","start":95,"end":98,"id":14},{"text":"a","start":99,"end":100,"id":15},{"text":"classification","start":101,"end":115,"id":16},{"text":"task","start":116,"end":120,"id":17},{"text":".","start":120,"end":121,"id":18}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":81,"end":94,"token_start":12,"token_end":13,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"Furthermore, we illustrate the regularizer can also be applied to deep Boltzmann machines, which lead to sparse group deep Boltzmann machines.","_input_hash":-1701629641,"_task_hash":-1674442890,"tokens":[{"text":"Furthermore","start":0,"end":11,"id":0},{"text":",","start":11,"end":12,"id":1},{"text":"we","start":13,"end":15,"id":2},{"text":"illustrate","start":16,"end":26,"id":3},{"text":"the","start":27,"end":30,"id":4},{"text":"regularizer","start":31,"end":42,"id":5},{"text":"can","start":43,"end":46,"id":6},{"text":"also","start":47,"end":51,"id":7},{"text":"be","start":52,"end":54,"id":8},{"text":"applied","start":55,"end":62,"id":9},{"text":"to","start":63,"end":65,"id":10},{"text":"deep","start":66,"end":70,"id":11},{"text":"Boltzmann","start":71,"end":80,"id":12},{"text":"machines","start":81,"end":89,"id":13},{"text":",","start":89,"end":90,"id":14},{"text":"which","start":91,"end":96,"id":15},{"text":"lead","start":97,"end":101,"id":16},{"text":"to","start":102,"end":104,"id":17},{"text":"sparse","start":105,"end":111,"id":18},{"text":"group","start":112,"end":117,"id":19},{"text":"deep","start":118,"end":122,"id":20},{"text":"Boltzmann","start":123,"end":132,"id":21},{"text":"machines","start":133,"end":141,"id":22},{"text":".","start":141,"end":142,"id":23}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":66,"end":89,"token_start":11,"token_end":13,"label":"ALGO","answer":"accept"},{"start":118,"end":141,"token_start":20,"token_end":22,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"When adapted to the MNIST data set, a two-layer sparse group Boltzmann machine achieves an error rate of $0.84\\%$, which is, to our knowledge, the best published result on the permutation-invariant version of the MNIST task.","_input_hash":-648323920,"_task_hash":-253503525,"tokens":[{"text":"When","start":0,"end":4,"id":0},{"text":"adapted","start":5,"end":12,"id":1},{"text":"to","start":13,"end":15,"id":2},{"text":"the","start":16,"end":19,"id":3},{"text":"MNIST","start":20,"end":25,"id":4},{"text":"data","start":26,"end":30,"id":5},{"text":"set","start":31,"end":34,"id":6},{"text":",","start":34,"end":35,"id":7},{"text":"a","start":36,"end":37,"id":8},{"text":"two","start":38,"end":41,"id":9},{"text":"-","start":41,"end":42,"id":10},{"text":"layer","start":42,"end":47,"id":11},{"text":"sparse","start":48,"end":54,"id":12},{"text":"group","start":55,"end":60,"id":13},{"text":"Boltzmann","start":61,"end":70,"id":14},{"text":"machine","start":71,"end":78,"id":15},{"text":"achieves","start":79,"end":87,"id":16},{"text":"an","start":88,"end":90,"id":17},{"text":"error","start":91,"end":96,"id":18},{"text":"rate","start":97,"end":101,"id":19},{"text":"of","start":102,"end":104,"id":20},{"text":"$","start":105,"end":106,"id":21},{"text":"0.84\\%$","start":106,"end":113,"id":22},{"text":",","start":113,"end":114,"id":23},{"text":"which","start":115,"end":120,"id":24},{"text":"is","start":121,"end":123,"id":25},{"text":",","start":123,"end":124,"id":26},{"text":"to","start":125,"end":127,"id":27},{"text":"our","start":128,"end":131,"id":28},{"text":"knowledge","start":132,"end":141,"id":29},{"text":",","start":141,"end":142,"id":30},{"text":"the","start":143,"end":146,"id":31},{"text":"best","start":147,"end":151,"id":32},{"text":"published","start":152,"end":161,"id":33},{"text":"result","start":162,"end":168,"id":34},{"text":"on","start":169,"end":171,"id":35},{"text":"the","start":172,"end":175,"id":36},{"text":"permutation","start":176,"end":187,"id":37},{"text":"-","start":187,"end":188,"id":38},{"text":"invariant","start":188,"end":197,"id":39},{"text":"version","start":198,"end":205,"id":40},{"text":"of","start":206,"end":208,"id":41},{"text":"the","start":209,"end":212,"id":42},{"text":"MNIST","start":213,"end":218,"id":43},{"text":"task","start":219,"end":223,"id":44},{"text":".","start":223,"end":224,"id":45}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":38,"end":78,"token_start":9,"token_end":15,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"In this paper, auto-associative models are proposed as candidates to the generalization of Principal Component Analysis.","_input_hash":128657657,"_task_hash":-1368359341,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"this","start":3,"end":7,"id":1},{"text":"paper","start":8,"end":13,"id":2},{"text":",","start":13,"end":14,"id":3},{"text":"auto","start":15,"end":19,"id":4},{"text":"-","start":19,"end":20,"id":5},{"text":"associative","start":20,"end":31,"id":6},{"text":"models","start":32,"end":38,"id":7},{"text":"are","start":39,"end":42,"id":8},{"text":"proposed","start":43,"end":51,"id":9},{"text":"as","start":52,"end":54,"id":10},{"text":"candidates","start":55,"end":65,"id":11},{"text":"to","start":66,"end":68,"id":12},{"text":"the","start":69,"end":72,"id":13},{"text":"generalization","start":73,"end":87,"id":14},{"text":"of","start":88,"end":90,"id":15},{"text":"Principal","start":91,"end":100,"id":16},{"text":"Component","start":101,"end":110,"id":17},{"text":"Analysis","start":111,"end":119,"id":18},{"text":".","start":119,"end":120,"id":19}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":15,"end":31,"token_start":4,"token_end":6,"label":"ALGO","answer":"accept"},{"start":91,"end":119,"token_start":16,"token_end":18,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"We show that these models are dedicated to the approximation of the dataset by a manifold.","_input_hash":1731379445,"_task_hash":254219600,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"show","start":3,"end":7,"id":1},{"text":"that","start":8,"end":12,"id":2},{"text":"these","start":13,"end":18,"id":3},{"text":"models","start":19,"end":25,"id":4},{"text":"are","start":26,"end":29,"id":5},{"text":"dedicated","start":30,"end":39,"id":6},{"text":"to","start":40,"end":42,"id":7},{"text":"the","start":43,"end":46,"id":8},{"text":"approximation","start":47,"end":60,"id":9},{"text":"of","start":61,"end":63,"id":10},{"text":"the","start":64,"end":67,"id":11},{"text":"dataset","start":68,"end":75,"id":12},{"text":"by","start":76,"end":78,"id":13},{"text":"a","start":79,"end":80,"id":14},{"text":"manifold","start":81,"end":89,"id":15},{"text":".","start":89,"end":90,"id":16}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Here, the word \"manifold\" refers to the topology properties of the structure.","_input_hash":1430752071,"_task_hash":409071371,"tokens":[{"text":"Here","start":0,"end":4,"id":0},{"text":",","start":4,"end":5,"id":1},{"text":"the","start":6,"end":9,"id":2},{"text":"word","start":10,"end":14,"id":3},{"text":"\"","start":15,"end":16,"id":4},{"text":"manifold","start":16,"end":24,"id":5},{"text":"\"","start":24,"end":25,"id":6},{"text":"refers","start":26,"end":32,"id":7},{"text":"to","start":33,"end":35,"id":8},{"text":"the","start":36,"end":39,"id":9},{"text":"topology","start":40,"end":48,"id":10},{"text":"properties","start":49,"end":59,"id":11},{"text":"of","start":60,"end":62,"id":12},{"text":"the","start":63,"end":66,"id":13},{"text":"structure","start":67,"end":76,"id":14},{"text":".","start":76,"end":77,"id":15}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"The approximating manifold is built by a projection pursuit algorithm.","_input_hash":-1144076703,"_task_hash":-586275235,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"approximating","start":4,"end":17,"id":1},{"text":"manifold","start":18,"end":26,"id":2},{"text":"is","start":27,"end":29,"id":3},{"text":"built","start":30,"end":35,"id":4},{"text":"by","start":36,"end":38,"id":5},{"text":"a","start":39,"end":40,"id":6},{"text":"projection","start":41,"end":51,"id":7},{"text":"pursuit","start":52,"end":59,"id":8},{"text":"algorithm","start":60,"end":69,"id":9},{"text":".","start":69,"end":70,"id":10}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":41,"end":59,"token_start":7,"token_end":8,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"At each step of the algorithm, the dimension of the manifold is incremented.","_input_hash":-1277404522,"_task_hash":-1499944899,"tokens":[{"text":"At","start":0,"end":2,"id":0},{"text":"each","start":3,"end":7,"id":1},{"text":"step","start":8,"end":12,"id":2},{"text":"of","start":13,"end":15,"id":3},{"text":"the","start":16,"end":19,"id":4},{"text":"algorithm","start":20,"end":29,"id":5},{"text":",","start":29,"end":30,"id":6},{"text":"the","start":31,"end":34,"id":7},{"text":"dimension","start":35,"end":44,"id":8},{"text":"of","start":45,"end":47,"id":9},{"text":"the","start":48,"end":51,"id":10},{"text":"manifold","start":52,"end":60,"id":11},{"text":"is","start":61,"end":63,"id":12},{"text":"incremented","start":64,"end":75,"id":13},{"text":".","start":75,"end":76,"id":14}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Some theoretical properties are provided.","_input_hash":-1985472592,"_task_hash":-447357712,"tokens":[{"text":"Some","start":0,"end":4,"id":0},{"text":"theoretical","start":5,"end":16,"id":1},{"text":"properties","start":17,"end":27,"id":2},{"text":"are","start":28,"end":31,"id":3},{"text":"provided","start":32,"end":40,"id":4},{"text":".","start":40,"end":41,"id":5}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"In particular, we can show that, at each step of the algorithm, the mean residuals norm is not increased.","_input_hash":863333549,"_task_hash":2130671631,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"particular","start":3,"end":13,"id":1},{"text":",","start":13,"end":14,"id":2},{"text":"we","start":15,"end":17,"id":3},{"text":"can","start":18,"end":21,"id":4},{"text":"show","start":22,"end":26,"id":5},{"text":"that","start":27,"end":31,"id":6},{"text":",","start":31,"end":32,"id":7},{"text":"at","start":33,"end":35,"id":8},{"text":"each","start":36,"end":40,"id":9},{"text":"step","start":41,"end":45,"id":10},{"text":"of","start":46,"end":48,"id":11},{"text":"the","start":49,"end":52,"id":12},{"text":"algorithm","start":53,"end":62,"id":13},{"text":",","start":62,"end":63,"id":14},{"text":"the","start":64,"end":67,"id":15},{"text":"mean","start":68,"end":72,"id":16},{"text":"residuals","start":73,"end":82,"id":17},{"text":"norm","start":83,"end":87,"id":18},{"text":"is","start":88,"end":90,"id":19},{"text":"not","start":91,"end":94,"id":20},{"text":"increased","start":95,"end":104,"id":21},{"text":".","start":104,"end":105,"id":22}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Moreover, it is also established that the algorithm converges in a finite number of steps.","_input_hash":-1560019928,"_task_hash":1827434766,"tokens":[{"text":"Moreover","start":0,"end":8,"id":0},{"text":",","start":8,"end":9,"id":1},{"text":"it","start":10,"end":12,"id":2},{"text":"is","start":13,"end":15,"id":3},{"text":"also","start":16,"end":20,"id":4},{"text":"established","start":21,"end":32,"id":5},{"text":"that","start":33,"end":37,"id":6},{"text":"the","start":38,"end":41,"id":7},{"text":"algorithm","start":42,"end":51,"id":8},{"text":"converges","start":52,"end":61,"id":9},{"text":"in","start":62,"end":64,"id":10},{"text":"a","start":65,"end":66,"id":11},{"text":"finite","start":67,"end":73,"id":12},{"text":"number","start":74,"end":80,"id":13},{"text":"of","start":81,"end":83,"id":14},{"text":"steps","start":84,"end":89,"id":15},{"text":".","start":89,"end":90,"id":16}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Some particular auto-associative models are exhibited and compared to the classical PCA and some neural networks models.","_input_hash":-1472052724,"_task_hash":-1129077473,"tokens":[{"text":"Some","start":0,"end":4,"id":0},{"text":"particular","start":5,"end":15,"id":1},{"text":"auto","start":16,"end":20,"id":2},{"text":"-","start":20,"end":21,"id":3},{"text":"associative","start":21,"end":32,"id":4},{"text":"models","start":33,"end":39,"id":5},{"text":"are","start":40,"end":43,"id":6},{"text":"exhibited","start":44,"end":53,"id":7},{"text":"and","start":54,"end":57,"id":8},{"text":"compared","start":58,"end":66,"id":9},{"text":"to","start":67,"end":69,"id":10},{"text":"the","start":70,"end":73,"id":11},{"text":"classical","start":74,"end":83,"id":12},{"text":"PCA","start":84,"end":87,"id":13},{"text":"and","start":88,"end":91,"id":14},{"text":"some","start":92,"end":96,"id":15},{"text":"neural","start":97,"end":103,"id":16},{"text":"networks","start":104,"end":112,"id":17},{"text":"models","start":113,"end":119,"id":18},{"text":".","start":119,"end":120,"id":19}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":16,"end":32,"token_start":2,"token_end":4,"label":"ALGO","answer":"accept"},{"start":84,"end":87,"token_start":13,"token_end":13,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"Implementation aspects are discussed.","_input_hash":-899021151,"_task_hash":1158090936,"tokens":[{"text":"Implementation","start":0,"end":14,"id":0},{"text":"aspects","start":15,"end":22,"id":1},{"text":"are","start":23,"end":26,"id":2},{"text":"discussed","start":27,"end":36,"id":3},{"text":".","start":36,"end":37,"id":4}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We show that, in numerous cases, no optimization procedure is required.","_input_hash":-1449578794,"_task_hash":1095388890,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"show","start":3,"end":7,"id":1},{"text":"that","start":8,"end":12,"id":2},{"text":",","start":12,"end":13,"id":3},{"text":"in","start":14,"end":16,"id":4},{"text":"numerous","start":17,"end":25,"id":5},{"text":"cases","start":26,"end":31,"id":6},{"text":",","start":31,"end":32,"id":7},{"text":"no","start":33,"end":35,"id":8},{"text":"optimization","start":36,"end":48,"id":9},{"text":"procedure","start":49,"end":58,"id":10},{"text":"is","start":59,"end":61,"id":11},{"text":"required","start":62,"end":70,"id":12},{"text":".","start":70,"end":71,"id":13}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Some illustrations on simulated and real data are presented.","_input_hash":1389003867,"_task_hash":-1489498496,"tokens":[{"text":"Some","start":0,"end":4,"id":0},{"text":"illustrations","start":5,"end":18,"id":1},{"text":"on","start":19,"end":21,"id":2},{"text":"simulated","start":22,"end":31,"id":3},{"text":"and","start":32,"end":35,"id":4},{"text":"real","start":36,"end":40,"id":5},{"text":"data","start":41,"end":45,"id":6},{"text":"are","start":46,"end":49,"id":7},{"text":"presented","start":50,"end":59,"id":8},{"text":".","start":59,"end":60,"id":9}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Most accurate predictions are typically obtained by learning machines with complex feature spaces (as e.g. induced by kernels).","_input_hash":886146820,"_task_hash":924847000,"tokens":[{"text":"Most","start":0,"end":4,"id":0},{"text":"accurate","start":5,"end":13,"id":1},{"text":"predictions","start":14,"end":25,"id":2},{"text":"are","start":26,"end":29,"id":3},{"text":"typically","start":30,"end":39,"id":4},{"text":"obtained","start":40,"end":48,"id":5},{"text":"by","start":49,"end":51,"id":6},{"text":"learning","start":52,"end":60,"id":7},{"text":"machines","start":61,"end":69,"id":8},{"text":"with","start":70,"end":74,"id":9},{"text":"complex","start":75,"end":82,"id":10},{"text":"feature","start":83,"end":90,"id":11},{"text":"spaces","start":91,"end":97,"id":12},{"text":"(","start":98,"end":99,"id":13},{"text":"as","start":99,"end":101,"id":14},{"text":"e.g.","start":102,"end":106,"id":15},{"text":"induced","start":107,"end":114,"id":16},{"text":"by","start":115,"end":117,"id":17},{"text":"kernels","start":118,"end":125,"id":18},{"text":")","start":125,"end":126,"id":19},{"text":".","start":126,"end":127,"id":20}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"Unfortunately, such decision rules are hardly accessible to humans and cannot easily be used to gain insights about the application domain.","_input_hash":-2093767764,"_task_hash":627266201,"tokens":[{"text":"Unfortunately","start":0,"end":13,"id":0},{"text":",","start":13,"end":14,"id":1},{"text":"such","start":15,"end":19,"id":2},{"text":"decision","start":20,"end":28,"id":3},{"text":"rules","start":29,"end":34,"id":4},{"text":"are","start":35,"end":38,"id":5},{"text":"hardly","start":39,"end":45,"id":6},{"text":"accessible","start":46,"end":56,"id":7},{"text":"to","start":57,"end":59,"id":8},{"text":"humans","start":60,"end":66,"id":9},{"text":"and","start":67,"end":70,"id":10},{"text":"can","start":71,"end":74,"id":11},{"text":"not","start":74,"end":77,"id":12},{"text":"easily","start":78,"end":84,"id":13},{"text":"be","start":85,"end":87,"id":14},{"text":"used","start":88,"end":92,"id":15},{"text":"to","start":93,"end":95,"id":16},{"text":"gain","start":96,"end":100,"id":17},{"text":"insights","start":101,"end":109,"id":18},{"text":"about","start":110,"end":115,"id":19},{"text":"the","start":116,"end":119,"id":20},{"text":"application","start":120,"end":131,"id":21},{"text":"domain","start":132,"end":138,"id":22},{"text":".","start":138,"end":139,"id":23}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"Therefore, one often resorts to linear models in combination with variable selection, thereby sacrificing some predictive power for presumptive interpretability.","_input_hash":-1652173087,"_task_hash":248702778,"tokens":[{"text":"Therefore","start":0,"end":9,"id":0},{"text":",","start":9,"end":10,"id":1},{"text":"one","start":11,"end":14,"id":2},{"text":"often","start":15,"end":20,"id":3},{"text":"resorts","start":21,"end":28,"id":4},{"text":"to","start":29,"end":31,"id":5},{"text":"linear","start":32,"end":38,"id":6},{"text":"models","start":39,"end":45,"id":7},{"text":"in","start":46,"end":48,"id":8},{"text":"combination","start":49,"end":60,"id":9},{"text":"with","start":61,"end":65,"id":10},{"text":"variable","start":66,"end":74,"id":11},{"text":"selection","start":75,"end":84,"id":12},{"text":",","start":84,"end":85,"id":13},{"text":"thereby","start":86,"end":93,"id":14},{"text":"sacrificing","start":94,"end":105,"id":15},{"text":"some","start":106,"end":110,"id":16},{"text":"predictive","start":111,"end":121,"id":17},{"text":"power","start":122,"end":127,"id":18},{"text":"for","start":128,"end":131,"id":19},{"text":"presumptive","start":132,"end":143,"id":20},{"text":"interpretability","start":144,"end":160,"id":21},{"text":".","start":160,"end":161,"id":22}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"Here, we introduce the Feature Importance Ranking Measure (FIRM), which by retrospective analysis of arbitrary learning machines allows to achieve both excellent predictive performance and superior interpretation.","_input_hash":1541985135,"_task_hash":-2034018295,"tokens":[{"text":"Here","start":0,"end":4,"id":0},{"text":",","start":4,"end":5,"id":1},{"text":"we","start":6,"end":8,"id":2},{"text":"introduce","start":9,"end":18,"id":3},{"text":"the","start":19,"end":22,"id":4},{"text":"Feature","start":23,"end":30,"id":5},{"text":"Importance","start":31,"end":41,"id":6},{"text":"Ranking","start":42,"end":49,"id":7},{"text":"Measure","start":50,"end":57,"id":8},{"text":"(","start":58,"end":59,"id":9},{"text":"FIRM","start":59,"end":63,"id":10},{"text":")","start":63,"end":64,"id":11},{"text":",","start":64,"end":65,"id":12},{"text":"which","start":66,"end":71,"id":13},{"text":"by","start":72,"end":74,"id":14},{"text":"retrospective","start":75,"end":88,"id":15},{"text":"analysis","start":89,"end":97,"id":16},{"text":"of","start":98,"end":100,"id":17},{"text":"arbitrary","start":101,"end":110,"id":18},{"text":"learning","start":111,"end":119,"id":19},{"text":"machines","start":120,"end":128,"id":20},{"text":"allows","start":129,"end":135,"id":21},{"text":"to","start":136,"end":138,"id":22},{"text":"achieve","start":139,"end":146,"id":23},{"text":"both","start":147,"end":151,"id":24},{"text":"excellent","start":152,"end":161,"id":25},{"text":"predictive","start":162,"end":172,"id":26},{"text":"performance","start":173,"end":184,"id":27},{"text":"and","start":185,"end":188,"id":28},{"text":"superior","start":189,"end":197,"id":29},{"text":"interpretation","start":198,"end":212,"id":30},{"text":".","start":212,"end":213,"id":31}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"In contrast to standard raw feature weighting, FIRM takes the underlying correlation structure of the features into account.","_input_hash":2114874348,"_task_hash":794646834,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"contrast","start":3,"end":11,"id":1},{"text":"to","start":12,"end":14,"id":2},{"text":"standard","start":15,"end":23,"id":3},{"text":"raw","start":24,"end":27,"id":4},{"text":"feature","start":28,"end":35,"id":5},{"text":"weighting","start":36,"end":45,"id":6},{"text":",","start":45,"end":46,"id":7},{"text":"FIRM","start":47,"end":51,"id":8},{"text":"takes","start":52,"end":57,"id":9},{"text":"the","start":58,"end":61,"id":10},{"text":"underlying","start":62,"end":72,"id":11},{"text":"correlation","start":73,"end":84,"id":12},{"text":"structure","start":85,"end":94,"id":13},{"text":"of","start":95,"end":97,"id":14},{"text":"the","start":98,"end":101,"id":15},{"text":"features","start":102,"end":110,"id":16},{"text":"into","start":111,"end":115,"id":17},{"text":"account","start":116,"end":123,"id":18},{"text":".","start":123,"end":124,"id":19}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"Thereby, it is able to discover the most relevant features, even if their appearance in the training data is entirely prevented by noise.","_input_hash":836817907,"_task_hash":167990887,"tokens":[{"text":"Thereby","start":0,"end":7,"id":0},{"text":",","start":7,"end":8,"id":1},{"text":"it","start":9,"end":11,"id":2},{"text":"is","start":12,"end":14,"id":3},{"text":"able","start":15,"end":19,"id":4},{"text":"to","start":20,"end":22,"id":5},{"text":"discover","start":23,"end":31,"id":6},{"text":"the","start":32,"end":35,"id":7},{"text":"most","start":36,"end":40,"id":8},{"text":"relevant","start":41,"end":49,"id":9},{"text":"features","start":50,"end":58,"id":10},{"text":",","start":58,"end":59,"id":11},{"text":"even","start":60,"end":64,"id":12},{"text":"if","start":65,"end":67,"id":13},{"text":"their","start":68,"end":73,"id":14},{"text":"appearance","start":74,"end":84,"id":15},{"text":"in","start":85,"end":87,"id":16},{"text":"the","start":88,"end":91,"id":17},{"text":"training","start":92,"end":100,"id":18},{"text":"data","start":101,"end":105,"id":19},{"text":"is","start":106,"end":108,"id":20},{"text":"entirely","start":109,"end":117,"id":21},{"text":"prevented","start":118,"end":127,"id":22},{"text":"by","start":128,"end":130,"id":23},{"text":"noise","start":131,"end":136,"id":24},{"text":".","start":136,"end":137,"id":25}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"The desirable properties of FIRM are investigated analytically and illustrated in simulations.","_input_hash":-1728202811,"_task_hash":1898366464,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"desirable","start":4,"end":13,"id":1},{"text":"properties","start":14,"end":24,"id":2},{"text":"of","start":25,"end":27,"id":3},{"text":"FIRM","start":28,"end":32,"id":4},{"text":"are","start":33,"end":36,"id":5},{"text":"investigated","start":37,"end":49,"id":6},{"text":"analytically","start":50,"end":62,"id":7},{"text":"and","start":63,"end":66,"id":8},{"text":"illustrated","start":67,"end":78,"id":9},{"text":"in","start":79,"end":81,"id":10},{"text":"simulations","start":82,"end":93,"id":11},{"text":".","start":93,"end":94,"id":12}],"_session_id":null,"_view_id":"ner_manual","answer":"accept","spans":[]}
{"text":"In many data mining applications collection of sufficiently large datasets is the most time consuming and expensive.","_input_hash":-648768567,"_task_hash":1416568041,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"many","start":3,"end":7,"id":1},{"text":"data","start":8,"end":12,"id":2},{"text":"mining","start":13,"end":19,"id":3},{"text":"applications","start":20,"end":32,"id":4},{"text":"collection","start":33,"end":43,"id":5},{"text":"of","start":44,"end":46,"id":6},{"text":"sufficiently","start":47,"end":59,"id":7},{"text":"large","start":60,"end":65,"id":8},{"text":"datasets","start":66,"end":74,"id":9},{"text":"is","start":75,"end":77,"id":10},{"text":"the","start":78,"end":81,"id":11},{"text":"most","start":82,"end":86,"id":12},{"text":"time","start":87,"end":91,"id":13},{"text":"consuming","start":92,"end":101,"id":14},{"text":"and","start":102,"end":105,"id":15},{"text":"expensive","start":106,"end":115,"id":16},{"text":".","start":115,"end":116,"id":17}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"reject"}
{"text":"On the other hand, industrial methods of data collection create huge databases, and make difficult direct applications of the advanced machine learning algorithms.","_input_hash":-1101036043,"_task_hash":424266198,"tokens":[{"text":"On","start":0,"end":2,"id":0},{"text":"the","start":3,"end":6,"id":1},{"text":"other","start":7,"end":12,"id":2},{"text":"hand","start":13,"end":17,"id":3},{"text":",","start":17,"end":18,"id":4},{"text":"industrial","start":19,"end":29,"id":5},{"text":"methods","start":30,"end":37,"id":6},{"text":"of","start":38,"end":40,"id":7},{"text":"data","start":41,"end":45,"id":8},{"text":"collection","start":46,"end":56,"id":9},{"text":"create","start":57,"end":63,"id":10},{"text":"huge","start":64,"end":68,"id":11},{"text":"databases","start":69,"end":78,"id":12},{"text":",","start":78,"end":79,"id":13},{"text":"and","start":80,"end":83,"id":14},{"text":"make","start":84,"end":88,"id":15},{"text":"difficult","start":89,"end":98,"id":16},{"text":"direct","start":99,"end":105,"id":17},{"text":"applications","start":106,"end":118,"id":18},{"text":"of","start":119,"end":121,"id":19},{"text":"the","start":122,"end":125,"id":20},{"text":"advanced","start":126,"end":134,"id":21},{"text":"machine","start":135,"end":142,"id":22},{"text":"learning","start":143,"end":151,"id":23},{"text":"algorithms","start":152,"end":162,"id":24},{"text":".","start":162,"end":163,"id":25}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":135,"end":151,"token_start":22,"token_end":23,"label":"ALGO","answer":"reject"}],"answer":"reject"}
{"text":"To address the above problems, we consider active learning (AL), which may be very efficient either for the experimental design or for the data filtering.","_input_hash":934877804,"_task_hash":-1613368043,"tokens":[{"text":"To","start":0,"end":2,"id":0},{"text":"address","start":3,"end":10,"id":1},{"text":"the","start":11,"end":14,"id":2},{"text":"above","start":15,"end":20,"id":3},{"text":"problems","start":21,"end":29,"id":4},{"text":",","start":29,"end":30,"id":5},{"text":"we","start":31,"end":33,"id":6},{"text":"consider","start":34,"end":42,"id":7},{"text":"active","start":43,"end":49,"id":8},{"text":"learning","start":50,"end":58,"id":9},{"text":"(","start":59,"end":60,"id":10},{"text":"AL","start":60,"end":62,"id":11},{"text":")","start":62,"end":63,"id":12},{"text":",","start":63,"end":64,"id":13},{"text":"which","start":65,"end":70,"id":14},{"text":"may","start":71,"end":74,"id":15},{"text":"be","start":75,"end":77,"id":16},{"text":"very","start":78,"end":82,"id":17},{"text":"efficient","start":83,"end":92,"id":18},{"text":"either","start":93,"end":99,"id":19},{"text":"for","start":100,"end":103,"id":20},{"text":"the","start":104,"end":107,"id":21},{"text":"experimental","start":108,"end":120,"id":22},{"text":"design","start":121,"end":127,"id":23},{"text":"or","start":128,"end":130,"id":24},{"text":"for","start":131,"end":134,"id":25},{"text":"the","start":135,"end":138,"id":26},{"text":"data","start":139,"end":143,"id":27},{"text":"filtering","start":144,"end":153,"id":28},{"text":".","start":153,"end":154,"id":29}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"reject"}
{"text":"In this paper we demonstrate using the online evaluation opportunity provided by the AL Challenge that quite competitive results may be produced using a small percentage of the available data.","_input_hash":-589299463,"_task_hash":-277888677,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"this","start":3,"end":7,"id":1},{"text":"paper","start":8,"end":13,"id":2},{"text":"we","start":14,"end":16,"id":3},{"text":"demonstrate","start":17,"end":28,"id":4},{"text":"using","start":29,"end":34,"id":5},{"text":"the","start":35,"end":38,"id":6},{"text":"online","start":39,"end":45,"id":7},{"text":"evaluation","start":46,"end":56,"id":8},{"text":"opportunity","start":57,"end":68,"id":9},{"text":"provided","start":69,"end":77,"id":10},{"text":"by","start":78,"end":80,"id":11},{"text":"the","start":81,"end":84,"id":12},{"text":"AL","start":85,"end":87,"id":13},{"text":"Challenge","start":88,"end":97,"id":14},{"text":"that","start":98,"end":102,"id":15},{"text":"quite","start":103,"end":108,"id":16},{"text":"competitive","start":109,"end":120,"id":17},{"text":"results","start":121,"end":128,"id":18},{"text":"may","start":129,"end":132,"id":19},{"text":"be","start":133,"end":135,"id":20},{"text":"produced","start":136,"end":144,"id":21},{"text":"using","start":145,"end":150,"id":22},{"text":"a","start":151,"end":152,"id":23},{"text":"small","start":153,"end":158,"id":24},{"text":"percentage","start":159,"end":169,"id":25},{"text":"of","start":170,"end":172,"id":26},{"text":"the","start":173,"end":176,"id":27},{"text":"available","start":177,"end":186,"id":28},{"text":"data","start":187,"end":191,"id":29},{"text":".","start":191,"end":192,"id":30}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":39,"end":45,"token_start":7,"token_end":7,"label":"ALGO","answer":"reject"},{"start":85,"end":87,"token_start":13,"token_end":13,"label":"ALGO","answer":"reject"},{"start":88,"end":97,"token_start":14,"token_end":14,"label":"ALGO","answer":"reject"}],"answer":"reject"}
{"text":"Also, we present several alternative criteria, which may be useful for the evaluation of the active learning processes.","_input_hash":-239855965,"_task_hash":-36486631,"tokens":[{"text":"Also","start":0,"end":4,"id":0},{"text":",","start":4,"end":5,"id":1},{"text":"we","start":6,"end":8,"id":2},{"text":"present","start":9,"end":16,"id":3},{"text":"several","start":17,"end":24,"id":4},{"text":"alternative","start":25,"end":36,"id":5},{"text":"criteria","start":37,"end":45,"id":6},{"text":",","start":45,"end":46,"id":7},{"text":"which","start":47,"end":52,"id":8},{"text":"may","start":53,"end":56,"id":9},{"text":"be","start":57,"end":59,"id":10},{"text":"useful","start":60,"end":66,"id":11},{"text":"for","start":67,"end":70,"id":12},{"text":"the","start":71,"end":74,"id":13},{"text":"evaluation","start":75,"end":85,"id":14},{"text":"of","start":86,"end":88,"id":15},{"text":"the","start":89,"end":92,"id":16},{"text":"active","start":93,"end":99,"id":17},{"text":"learning","start":100,"end":108,"id":18},{"text":"processes","start":109,"end":118,"id":19},{"text":".","start":118,"end":119,"id":20}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"reject"}
{"text":"The author of this paper attended special presentation in Barcelona, where results of the WCCI 2010 AL Challenge were discussed.","_input_hash":-245737860,"_task_hash":-1283483071,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"author","start":4,"end":10,"id":1},{"text":"of","start":11,"end":13,"id":2},{"text":"this","start":14,"end":18,"id":3},{"text":"paper","start":19,"end":24,"id":4},{"text":"attended","start":25,"end":33,"id":5},{"text":"special","start":34,"end":41,"id":6},{"text":"presentation","start":42,"end":54,"id":7},{"text":"in","start":55,"end":57,"id":8},{"text":"Barcelona","start":58,"end":67,"id":9},{"text":",","start":67,"end":68,"id":10},{"text":"where","start":69,"end":74,"id":11},{"text":"results","start":75,"end":82,"id":12},{"text":"of","start":83,"end":85,"id":13},{"text":"the","start":86,"end":89,"id":14},{"text":"WCCI","start":90,"end":94,"id":15},{"text":"2010","start":95,"end":99,"id":16},{"text":"AL","start":100,"end":102,"id":17},{"text":"Challenge","start":103,"end":112,"id":18},{"text":"were","start":113,"end":117,"id":19},{"text":"discussed","start":118,"end":127,"id":20},{"text":".","start":127,"end":128,"id":21}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":58,"end":67,"token_start":9,"token_end":9,"label":"ALGO","answer":"reject"},{"start":90,"end":112,"token_start":15,"token_end":18,"label":"ALGO","answer":"reject"}],"answer":"reject"}
{"text":"The performance of Orthogonal Matching Pursuit (OMP) for variable selection is analyzed for random designs.","_input_hash":-918334276,"_task_hash":-1093372333,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"performance","start":4,"end":15,"id":1},{"text":"of","start":16,"end":18,"id":2},{"text":"Orthogonal","start":19,"end":29,"id":3},{"text":"Matching","start":30,"end":38,"id":4},{"text":"Pursuit","start":39,"end":46,"id":5},{"text":"(","start":47,"end":48,"id":6},{"text":"OMP","start":48,"end":51,"id":7},{"text":")","start":51,"end":52,"id":8},{"text":"for","start":53,"end":56,"id":9},{"text":"variable","start":57,"end":65,"id":10},{"text":"selection","start":66,"end":75,"id":11},{"text":"is","start":76,"end":78,"id":12},{"text":"analyzed","start":79,"end":87,"id":13},{"text":"for","start":88,"end":91,"id":14},{"text":"random","start":92,"end":98,"id":15},{"text":"designs","start":99,"end":106,"id":16},{"text":".","start":106,"end":107,"id":17}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":19,"end":46,"token_start":3,"token_end":5,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"When contrasted with the deterministic case, since the performance is here measured after averaging over the distribution of the design matrix, one can have far less stringent sparsity constraints on the coefficient vector.","_input_hash":1292808360,"_task_hash":-561971502,"tokens":[{"text":"When","start":0,"end":4,"id":0},{"text":"contrasted","start":5,"end":15,"id":1},{"text":"with","start":16,"end":20,"id":2},{"text":"the","start":21,"end":24,"id":3},{"text":"deterministic","start":25,"end":38,"id":4},{"text":"case","start":39,"end":43,"id":5},{"text":",","start":43,"end":44,"id":6},{"text":"since","start":45,"end":50,"id":7},{"text":"the","start":51,"end":54,"id":8},{"text":"performance","start":55,"end":66,"id":9},{"text":"is","start":67,"end":69,"id":10},{"text":"here","start":70,"end":74,"id":11},{"text":"measured","start":75,"end":83,"id":12},{"text":"after","start":84,"end":89,"id":13},{"text":"averaging","start":90,"end":99,"id":14},{"text":"over","start":100,"end":104,"id":15},{"text":"the","start":105,"end":108,"id":16},{"text":"distribution","start":109,"end":121,"id":17},{"text":"of","start":122,"end":124,"id":18},{"text":"the","start":125,"end":128,"id":19},{"text":"design","start":129,"end":135,"id":20},{"text":"matrix","start":136,"end":142,"id":21},{"text":",","start":142,"end":143,"id":22},{"text":"one","start":144,"end":147,"id":23},{"text":"can","start":148,"end":151,"id":24},{"text":"have","start":152,"end":156,"id":25},{"text":"far","start":157,"end":160,"id":26},{"text":"less","start":161,"end":165,"id":27},{"text":"stringent","start":166,"end":175,"id":28},{"text":"sparsity","start":176,"end":184,"id":29},{"text":"constraints","start":185,"end":196,"id":30},{"text":"on","start":197,"end":199,"id":31},{"text":"the","start":200,"end":203,"id":32},{"text":"coefficient","start":204,"end":215,"id":33},{"text":"vector","start":216,"end":222,"id":34},{"text":".","start":222,"end":223,"id":35}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"We demonstrate that for exact sparse vectors, the performance of the OMP is similar to known results on the Lasso algorithm [\\textit{IEEE Trans.","_input_hash":-1446637233,"_task_hash":1116902746,"tokens":[{"text":"We","start":0,"end":2,"id":0},{"text":"demonstrate","start":3,"end":14,"id":1},{"text":"that","start":15,"end":19,"id":2},{"text":"for","start":20,"end":23,"id":3},{"text":"exact","start":24,"end":29,"id":4},{"text":"sparse","start":30,"end":36,"id":5},{"text":"vectors","start":37,"end":44,"id":6},{"text":",","start":44,"end":45,"id":7},{"text":"the","start":46,"end":49,"id":8},{"text":"performance","start":50,"end":61,"id":9},{"text":"of","start":62,"end":64,"id":10},{"text":"the","start":65,"end":68,"id":11},{"text":"OMP","start":69,"end":72,"id":12},{"text":"is","start":73,"end":75,"id":13},{"text":"similar","start":76,"end":83,"id":14},{"text":"to","start":84,"end":86,"id":15},{"text":"known","start":87,"end":92,"id":16},{"text":"results","start":93,"end":100,"id":17},{"text":"on","start":101,"end":103,"id":18},{"text":"the","start":104,"end":107,"id":19},{"text":"Lasso","start":108,"end":113,"id":20},{"text":"algorithm","start":114,"end":123,"id":21},{"text":"[","start":124,"end":125,"id":22},{"text":"\\textit{IEEE","start":125,"end":137,"id":23},{"text":"Trans","start":138,"end":143,"id":24},{"text":".","start":143,"end":144,"id":25}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Inform.","_input_hash":-1425232106,"_task_hash":-30061618,"tokens":[{"text":"Inform","start":0,"end":6,"id":0},{"text":".","start":6,"end":7,"id":1}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Theory} \\textbf{55} (2009) 2183--2202].","_input_hash":-455922479,"_task_hash":477672113,"tokens":[{"text":"Theory","start":0,"end":6,"id":0},{"text":"}","start":6,"end":7,"id":1},{"text":"\\textbf{55","start":8,"end":18,"id":2},{"text":"}","start":18,"end":19,"id":3},{"text":"(","start":20,"end":21,"id":4},{"text":"2009","start":21,"end":25,"id":5},{"text":")","start":25,"end":26,"id":6},{"text":"2183","start":27,"end":31,"id":7},{"text":"-","start":31,"end":32,"id":8},{"text":"-2202","start":32,"end":37,"id":9},{"text":"]","start":37,"end":38,"id":10},{"text":".","start":38,"end":39,"id":11}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"Moreover, variable selection under a more relaxed sparsity assumption on the coefficient vector, whereby one has only control on the $\\ell_1$ norm of the smaller coefficients, is also analyzed.","_input_hash":467122190,"_task_hash":1726707844,"tokens":[{"text":"Moreover","start":0,"end":8,"id":0},{"text":",","start":8,"end":9,"id":1},{"text":"variable","start":10,"end":18,"id":2},{"text":"selection","start":19,"end":28,"id":3},{"text":"under","start":29,"end":34,"id":4},{"text":"a","start":35,"end":36,"id":5},{"text":"more","start":37,"end":41,"id":6},{"text":"relaxed","start":42,"end":49,"id":7},{"text":"sparsity","start":50,"end":58,"id":8},{"text":"assumption","start":59,"end":69,"id":9},{"text":"on","start":70,"end":72,"id":10},{"text":"the","start":73,"end":76,"id":11},{"text":"coefficient","start":77,"end":88,"id":12},{"text":"vector","start":89,"end":95,"id":13},{"text":",","start":95,"end":96,"id":14},{"text":"whereby","start":97,"end":104,"id":15},{"text":"one","start":105,"end":108,"id":16},{"text":"has","start":109,"end":112,"id":17},{"text":"only","start":113,"end":117,"id":18},{"text":"control","start":118,"end":125,"id":19},{"text":"on","start":126,"end":128,"id":20},{"text":"the","start":129,"end":132,"id":21},{"text":"$","start":133,"end":134,"id":22},{"text":"\\ell_1","start":134,"end":140,"id":23},{"text":"$","start":140,"end":141,"id":24},{"text":"norm","start":142,"end":146,"id":25},{"text":"of","start":147,"end":149,"id":26},{"text":"the","start":150,"end":153,"id":27},{"text":"smaller","start":154,"end":161,"id":28},{"text":"coefficients","start":162,"end":174,"id":29},{"text":",","start":174,"end":175,"id":30},{"text":"is","start":176,"end":178,"id":31},{"text":"also","start":179,"end":183,"id":32},{"text":"analyzed","start":184,"end":192,"id":33},{"text":".","start":192,"end":193,"id":34}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"As a consequence of these results, we also show that the coefficient estimate satisfies strong oracle type inequalities.","_input_hash":-915149916,"_task_hash":1324701762,"tokens":[{"text":"As","start":0,"end":2,"id":0},{"text":"a","start":3,"end":4,"id":1},{"text":"consequence","start":5,"end":16,"id":2},{"text":"of","start":17,"end":19,"id":3},{"text":"these","start":20,"end":25,"id":4},{"text":"results","start":26,"end":33,"id":5},{"text":",","start":33,"end":34,"id":6},{"text":"we","start":35,"end":37,"id":7},{"text":"also","start":38,"end":42,"id":8},{"text":"show","start":43,"end":47,"id":9},{"text":"that","start":48,"end":52,"id":10},{"text":"the","start":53,"end":56,"id":11},{"text":"coefficient","start":57,"end":68,"id":12},{"text":"estimate","start":69,"end":77,"id":13},{"text":"satisfies","start":78,"end":87,"id":14},{"text":"strong","start":88,"end":94,"id":15},{"text":"oracle","start":95,"end":101,"id":16},{"text":"type","start":102,"end":106,"id":17},{"text":"inequalities","start":107,"end":119,"id":18},{"text":".","start":119,"end":120,"id":19}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"In nonparametric classification and regression problems, regularized kernel methods, in particular support vector machines, attract much attention in theoretical and in applied statistics.","_input_hash":-318180059,"_task_hash":-1272742509,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"nonparametric","start":3,"end":16,"id":1},{"text":"classification","start":17,"end":31,"id":2},{"text":"and","start":32,"end":35,"id":3},{"text":"regression","start":36,"end":46,"id":4},{"text":"problems","start":47,"end":55,"id":5},{"text":",","start":55,"end":56,"id":6},{"text":"regularized","start":57,"end":68,"id":7},{"text":"kernel","start":69,"end":75,"id":8},{"text":"methods","start":76,"end":83,"id":9},{"text":",","start":83,"end":84,"id":10},{"text":"in","start":85,"end":87,"id":11},{"text":"particular","start":88,"end":98,"id":12},{"text":"support","start":99,"end":106,"id":13},{"text":"vector","start":107,"end":113,"id":14},{"text":"machines","start":114,"end":122,"id":15},{"text":",","start":122,"end":123,"id":16},{"text":"attract","start":124,"end":131,"id":17},{"text":"much","start":132,"end":136,"id":18},{"text":"attention","start":137,"end":146,"id":19},{"text":"in","start":147,"end":149,"id":20},{"text":"theoretical","start":150,"end":161,"id":21},{"text":"and","start":162,"end":165,"id":22},{"text":"in","start":166,"end":168,"id":23},{"text":"applied","start":169,"end":176,"id":24},{"text":"statistics","start":177,"end":187,"id":25},{"text":".","start":187,"end":188,"id":26}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":3,"end":31,"token_start":1,"token_end":2,"label":"ALGO","answer":"accept"},{"start":57,"end":75,"token_start":7,"token_end":8,"label":"ALGO","answer":"accept"},{"start":99,"end":122,"token_start":13,"token_end":15,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"In an abstract sense, regularized kernel methods (simply called SVMs here) can be seen as regularized M-estimators for a parameter in a (typically infinite dimensional) reproducing kernel Hilbert space.","_input_hash":-690500307,"_task_hash":2063725906,"tokens":[{"text":"In","start":0,"end":2,"id":0},{"text":"an","start":3,"end":5,"id":1},{"text":"abstract","start":6,"end":14,"id":2},{"text":"sense","start":15,"end":20,"id":3},{"text":",","start":20,"end":21,"id":4},{"text":"regularized","start":22,"end":33,"id":5},{"text":"kernel","start":34,"end":40,"id":6},{"text":"methods","start":41,"end":48,"id":7},{"text":"(","start":49,"end":50,"id":8},{"text":"simply","start":50,"end":56,"id":9},{"text":"called","start":57,"end":63,"id":10},{"text":"SVMs","start":64,"end":68,"id":11},{"text":"here","start":69,"end":73,"id":12},{"text":")","start":73,"end":74,"id":13},{"text":"can","start":75,"end":78,"id":14},{"text":"be","start":79,"end":81,"id":15},{"text":"seen","start":82,"end":86,"id":16},{"text":"as","start":87,"end":89,"id":17},{"text":"regularized","start":90,"end":101,"id":18},{"text":"M","start":102,"end":103,"id":19},{"text":"-","start":103,"end":104,"id":20},{"text":"estimators","start":104,"end":114,"id":21},{"text":"for","start":115,"end":118,"id":22},{"text":"a","start":119,"end":120,"id":23},{"text":"parameter","start":121,"end":130,"id":24},{"text":"in","start":131,"end":133,"id":25},{"text":"a","start":134,"end":135,"id":26},{"text":"(","start":136,"end":137,"id":27},{"text":"typically","start":137,"end":146,"id":28},{"text":"infinite","start":147,"end":155,"id":29},{"text":"dimensional","start":156,"end":167,"id":30},{"text":")","start":167,"end":168,"id":31},{"text":"reproducing","start":169,"end":180,"id":32},{"text":"kernel","start":181,"end":187,"id":33},{"text":"Hilbert","start":188,"end":195,"id":34},{"text":"space","start":196,"end":201,"id":35},{"text":".","start":201,"end":202,"id":36}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":22,"end":40,"token_start":5,"token_end":6,"label":"ALGO","answer":"accept"},{"start":64,"end":68,"token_start":11,"token_end":11,"label":"ALGO","answer":"accept"},{"start":181,"end":201,"token_start":33,"token_end":35,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"For smooth loss functions, it is shown that the difference between the estimator, i.e.\\ the empirical SVM, and the theoretical SVM is asymptotically normal with rate $\\sqrt{n}$. That is, the standardized difference converges weakly to a Gaussian process in the reproducing kernel Hilbert space.","_input_hash":187094571,"_task_hash":2093377596,"tokens":[{"text":"For","start":0,"end":3,"id":0},{"text":"smooth","start":4,"end":10,"id":1},{"text":"loss","start":11,"end":15,"id":2},{"text":"functions","start":16,"end":25,"id":3},{"text":",","start":25,"end":26,"id":4},{"text":"it","start":27,"end":29,"id":5},{"text":"is","start":30,"end":32,"id":6},{"text":"shown","start":33,"end":38,"id":7},{"text":"that","start":39,"end":43,"id":8},{"text":"the","start":44,"end":47,"id":9},{"text":"difference","start":48,"end":58,"id":10},{"text":"between","start":59,"end":66,"id":11},{"text":"the","start":67,"end":70,"id":12},{"text":"estimator","start":71,"end":80,"id":13},{"text":",","start":80,"end":81,"id":14},{"text":"i.e.\\","start":82,"end":87,"id":15},{"text":"the","start":88,"end":91,"id":16},{"text":"empirical","start":92,"end":101,"id":17},{"text":"SVM","start":102,"end":105,"id":18},{"text":",","start":105,"end":106,"id":19},{"text":"and","start":107,"end":110,"id":20},{"text":"the","start":111,"end":114,"id":21},{"text":"theoretical","start":115,"end":126,"id":22},{"text":"SVM","start":127,"end":130,"id":23},{"text":"is","start":131,"end":133,"id":24},{"text":"asymptotically","start":134,"end":148,"id":25},{"text":"normal","start":149,"end":155,"id":26},{"text":"with","start":156,"end":160,"id":27},{"text":"rate","start":161,"end":165,"id":28},{"text":"$","start":166,"end":167,"id":29},{"text":"\\sqrt{n}$.","start":167,"end":177,"id":30},{"text":"That","start":178,"end":182,"id":31},{"text":"is","start":183,"end":185,"id":32},{"text":",","start":185,"end":186,"id":33},{"text":"the","start":187,"end":190,"id":34},{"text":"standardized","start":191,"end":203,"id":35},{"text":"difference","start":204,"end":214,"id":36},{"text":"converges","start":215,"end":224,"id":37},{"text":"weakly","start":225,"end":231,"id":38},{"text":"to","start":232,"end":234,"id":39},{"text":"a","start":235,"end":236,"id":40},{"text":"Gaussian","start":237,"end":245,"id":41},{"text":"process","start":246,"end":253,"id":42},{"text":"in","start":254,"end":256,"id":43},{"text":"the","start":257,"end":260,"id":44},{"text":"reproducing","start":261,"end":272,"id":45},{"text":"kernel","start":273,"end":279,"id":46},{"text":"Hilbert","start":280,"end":287,"id":47},{"text":"space","start":288,"end":293,"id":48},{"text":".","start":293,"end":294,"id":49}],"_session_id":null,"_view_id":"ner_manual","spans":[{"start":102,"end":105,"token_start":18,"token_end":18,"label":"ALGO","answer":"accept"},{"start":127,"end":130,"token_start":23,"token_end":23,"label":"ALGO","answer":"accept"},{"start":273,"end":293,"token_start":46,"token_end":48,"label":"ALGO","answer":"accept"}],"answer":"accept"}
{"text":"As common in real applications, the choice of the regularization parameter may depend on the data.","_input_hash":-548434850,"_task_hash":-1935574815,"tokens":[{"text":"As","start":0,"end":2,"id":0},{"text":"common","start":3,"end":9,"id":1},{"text":"in","start":10,"end":12,"id":2},{"text":"real","start":13,"end":17,"id":3},{"text":"applications","start":18,"end":30,"id":4},{"text":",","start":30,"end":31,"id":5},{"text":"the","start":32,"end":35,"id":6},{"text":"choice","start":36,"end":42,"id":7},{"text":"of","start":43,"end":45,"id":8},{"text":"the","start":46,"end":49,"id":9},{"text":"regularization","start":50,"end":64,"id":10},{"text":"parameter","start":65,"end":74,"id":11},{"text":"may","start":75,"end":78,"id":12},{"text":"depend","start":79,"end":85,"id":13},{"text":"on","start":86,"end":88,"id":14},{"text":"the","start":89,"end":92,"id":15},{"text":"data","start":93,"end":97,"id":16},{"text":".","start":97,"end":98,"id":17}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
{"text":"The proof is done by an application of the functional delta-method and by showing that the SVM-functional is suitably Hadamard-differentiable.","_input_hash":540185100,"_task_hash":-1879019576,"tokens":[{"text":"The","start":0,"end":3,"id":0},{"text":"proof","start":4,"end":9,"id":1},{"text":"is","start":10,"end":12,"id":2},{"text":"done","start":13,"end":17,"id":3},{"text":"by","start":18,"end":20,"id":4},{"text":"an","start":21,"end":23,"id":5},{"text":"application","start":24,"end":35,"id":6},{"text":"of","start":36,"end":38,"id":7},{"text":"the","start":39,"end":42,"id":8},{"text":"functional","start":43,"end":53,"id":9},{"text":"delta","start":54,"end":59,"id":10},{"text":"-","start":59,"end":60,"id":11},{"text":"method","start":60,"end":66,"id":12},{"text":"and","start":67,"end":70,"id":13},{"text":"by","start":71,"end":73,"id":14},{"text":"showing","start":74,"end":81,"id":15},{"text":"that","start":82,"end":86,"id":16},{"text":"the","start":87,"end":90,"id":17},{"text":"SVM","start":91,"end":94,"id":18},{"text":"-","start":94,"end":95,"id":19},{"text":"functional","start":95,"end":105,"id":20},{"text":"is","start":106,"end":108,"id":21},{"text":"suitably","start":109,"end":117,"id":22},{"text":"Hadamard","start":118,"end":126,"id":23},{"text":"-","start":126,"end":127,"id":24},{"text":"differentiable","start":127,"end":141,"id":25},{"text":".","start":141,"end":142,"id":26}],"_session_id":null,"_view_id":"ner_manual","spans":[],"answer":"accept"}
